{"config":{"lang":["en"],"separator":"[\\s\\-]+","pipeline":["stopWordFilter"]},"docs":[{"location":"index.html","title":"About","text":"<p>Hi, I\u2019m Wojciech Adamczyk - a PhD student in Jonathan Home\u2019s group @ ETH Zurich, working on calcium Rydberg atoms in tweezer arrays. Previously, I worked with Didier Queloz @ University of Cambridge on measuring precipitable water vapor via remote sensing, and with Hartmut Schlums @ Rolls\u2011Royce Deutschland on multiaxial fatigue of Allvac 718Plus. </p> <p>I\u2019m currently interested in:</p> <ul> <li>atomic physics and motional state control</li> <li>off\u2011diagonal Hamiltonian elements</li> <li>optical aberrations</li> <li>maximum likelihood estimation methods</li> <li>AI safety research</li> </ul> <p>I enjoy hacking, writing, and playing the violin.</p>"},{"location":"index.html#supervision-contact","title":"Supervision &amp; contact","text":"<p>I deeply enjoy supervising Master\u2019s and semester projects. And also random projects.</p> <ul> <li>Master\u2019s students: apply via email to the TIQI application list: tiqi-application@lists.phys.ethz.ch. Please mention my name in the application.</li> <li>If you want to work on something together: wadamczyk@phys.ethz.ch</li> </ul>"},{"location":"index.html#blogs-i-like","title":"Blogs I like:","text":"<p>This website was created because of the immense joy I got from reading other people's websites such as:</p> <ul> <li>Daniel Steck</li> <li>Maciej Malinowski</li> <li>Piotr Migdal</li> <li>David Tong</li> <li>Neel Nanda</li> <li>Pete Shadbolt</li> <li>Scott Aaronson</li> <li>Paul Graham</li> <li>Dario Amodei</li> <li>Andrej Karpathy</li> </ul>"},{"location":"courses/scientific_writing_workshop/scienfitic_writing_workshop.html","title":"Scientific Writing Workshop","text":"<p>This summary is based on the workshop on Scientific Writing given by Gaia Doneti. It is a paraphrased note, written together with Moritz Fontbot\u00e9 Schmidt, and extended with additional thoughts. Feel free to contribute directly via GitLab or contact wadamczyk@phys.ethz.ch.</p>"},{"location":"courses/scientific_writing_workshop/scienfitic_writing_workshop.html#chapter-1-why-write-about-your-research","title":"Chapter 1: Why write about your research?","text":"<p>Before starting with the course, it is important to reflect on why writing matters. As humans, and especially as scientists, our role is to deeply understand ideas, experiment with them, and share them with others. Writing enables us to:</p> <ol> <li>Help others understand ideas quicker than we did.</li> <li>Allow others to verify and correct our understanding.</li> <li>Enable others to make more educated guesses about the future direction of research.</li> </ol>"},{"location":"courses/scientific_writing_workshop/scienfitic_writing_workshop.html#writing-with-intent","title":"Writing with Intent","text":"<p>Writing should always be intentional and aligned with the specific goal. To achieve this, ask yourself:</p> <ul> <li>What is my main message? What do I want the reader to understand after reading my text?</li> <li>Who is my audience? How do I deliver the message effectively to this audience?</li> <li>What do I want the reader to take home? How should their understanding of the topic change?</li> <li>What misconceptions do I want to avoid? Identify potential misunderstandings or overstatements to ensure clarity.</li> </ul>"},{"location":"courses/scientific_writing_workshop/scienfitic_writing_workshop.html#additional-questions","title":"Additional Questions","text":"<ul> <li>What type of paper am I writing? Understand the common types of papers (e.g., review, technical) and align your writing to the expectations of that category.</li> </ul>"},{"location":"courses/scientific_writing_workshop/scienfitic_writing_workshop.html#chapter-2-what-makes-a-good-paper","title":"Chapter 2: What Makes a 'Good' Paper?","text":""},{"location":"courses/scientific_writing_workshop/scienfitic_writing_workshop.html#characteristics-of-a-bad-paper","title":"Characteristics of a \"Bad\" Paper","text":"<p>A \"bad\" paper is one that the reader struggles to follow. This often happens when:</p> <ul> <li>Too much prior knowledge is assumed, making the paper inaccessible.</li> <li>Ambiguities obscure the message.</li> <li>The focus is on \"selling\" rather than \"communicating\" the research.</li> </ul>"},{"location":"courses/scientific_writing_workshop/scienfitic_writing_workshop.html#characteristics-of-a-good-paper","title":"Characteristics of a \"Good\" Paper","text":"<p>A \"good\" paper avoids these pitfalls. Instead:</p> <ul> <li>Notation: Use notation consistent with the standard literature.</li> <li>Clarity: Ensure that the writing is unambiguous.</li> <li>Communication: Focus on conveying ideas clearly, not on overselling them.</li> </ul>"},{"location":"courses/scientific_writing_workshop/scienfitic_writing_workshop.html#chapter-3-structure","title":"Chapter 3: Structure","text":"<p>Initially when writing a paper it is useful to follow some sort of structure. One commonly used framework is IMRaD (Introduction, Methods, Results, and Discussion), which follows the inverted-vase model:</p> <ul> <li>Introduction: Broad context narrowing to the specific research question.</li> <li>Methods: Detailed explanation of the approach.</li> <li>Results: Presentation of findings guided by key figures.</li> <li>Discussion: Recap findings, discuss limitations, and connect to the broader field.</li> </ul>"},{"location":"courses/scientific_writing_workshop/scienfitic_writing_workshop.html#tips-for-each-section","title":"Tips for Each Section","text":""},{"location":"courses/scientific_writing_workshop/scienfitic_writing_workshop.html#introduction","title":"Introduction","text":"<ul> <li>should give a context of the written work, but also general context for the whole field. It should be specific to the work, so don't try to introduce the whole field if its not relevant to the work. It also should also briefly introduce the findings of the work and how can they relate to the field. </li> <li>Introduction should start with broad context and then go more specific:</li> <li>Context: What is known, and what isn't. Where your study comes in?</li> <li>Focus: Literature review, rationale and objectives of your work?</li> <li>Findings: A preview (optional)</li> <li>If you're stuck, a useful trick is to start off by plagiarizing (if others do work very similar to yours). You can collect the patches, and then you can be inspired by them to write your own introduction. But here you need to be very careful about it. It is easy to forget what you have copied and then you can end up plagarising other people's work. It is useful to mark what you have copied and what you have written yourself.</li> </ul>"},{"location":"courses/scientific_writing_workshop/scienfitic_writing_workshop.html#methods","title":"Methods","text":"<ul> <li>Key Questions to ask:<ul> <li>What details help the reader understand how you obtained your results?</li> <li>Methods section are very varied depending on the journal and the field. Therefore if you are writing a method section, you should ask yourself about how are the methods written in both of those two contexts. It might be that the journal has a separate section for methods, or it might be that it is added as a supplement. You should also ask yourself what a common person in your field would expect to see in the methods section.</li> </ul> </li> <li>It is common for people to by accident self-plagarise if they are including methods that are featured in other papers of theirs. Be careful about it.</li> <li>If there is not enough material for a methods section - exclude it - many journals do not require it.</li> </ul>"},{"location":"courses/scientific_writing_workshop/scienfitic_writing_workshop.html#results","title":"Results","text":"<ul> <li>Key Questions to ask:<ul> <li>What conclusions do I want to draw?</li> <li>What data is crucial to draw those conclusions?</li> <li>What figures do I need to present the data?</li> </ul> </li> <li>Often quite easy way to write results section is to be guided by the plots. Think about what do you want to show and how in terms of the plots that should create a story line, and then work with text around the plots. </li> <li>It is important to note that now it is customatory to allow the reader to read the plot and fully understand it without the need to read the text (Figures need to be independently understandable.)</li> <li>In the results when you are including a lot of numerical data - read it aloud - is it easy to read? If not, think how you can change it. </li> <li>Quite often people are scared to comment on the data in the results section, as they want to include it in the discussion. But then it somehow creates gaps in the results section. It is fine to comment on the data in both section. In general repetition is fine as soon as it is not overdone. Feel free to comment on the data in both sections.</li> </ul>"},{"location":"courses/scientific_writing_workshop/scienfitic_writing_workshop.html#discussion","title":"Discussion","text":"<ul> <li>Discussion should be opposite to the introduction, it should start more specific and then go more broadly. </li> <li>Recap the findings, </li> <li>Then focus on the most important findings, what are puzzling outcomes, limitations, open questions</li> <li>Outlook</li> <li>Similarily to the results section you can follow the inverted-vase model (by first doing a recap, then focus on the most important findings, and then talk more generally about the outlook).</li> <li>Include the limitations of the work in the discussion.</li> </ul> <p>General tips:</p> <ul> <li>Repetition in papers is good quite often it makes the paper more readable.</li> <li>Storytelling - Galia argues we overuse the concept. By focusing too much on the story-telling it makes us less scientists and more a seller. </li> </ul>"},{"location":"courses/scientific_writing_workshop/scienfitic_writing_workshop.html#chapter-4-zoom-paragraphs","title":"Chapter 4: Zoom - Paragraphs:","text":"<p>Tips:</p> <ul> <li>Paragraph should correspond to one idea. The idea should be clear and distinct from other paragraphs. To make sure that the paragraph corresponds to one idea it is useful to use topic sentences, and then during the revision ponder whether you are convaying the idea.</li> <li>It is common in readers that they put the most attention to the beginning and the end of the paragraph. Gaia compared the beggining and the end of the paragraph to a most expensive real estate. Use it wisely. This is where the reader's attention is.</li> <li>Parallelism / repetition can help with coherence (don't overdo).</li> <li>Use topic sentences to guide you during revision. (Highlight them?)</li> <li>Organisational scheme: It is useful to use some sort of organisational scheme when writing paragraphs. It can be spatial or temporal, general to specific, expected to un-expected, familiar to unfamiliar. By having some sort of structure it is easier for the reader to follow the text. You are in the same boat as the reader, both of you want the reader to understand the text.</li> </ul> <p>Red flags:</p> <ul> <li>Paragraphs that widely vary in length</li> <li>Paragraphs that start with however, despite</li> <li>Redundancies</li> </ul>"},{"location":"courses/scientific_writing_workshop/scienfitic_writing_workshop.html#chapter-5-zoom-sentences","title":"Chapter 5: Zoom - Sentences:","text":"<p>Tips:</p> <ul> <li>\"Expensive real estate\" - Similarly to paragraphs, the beggining and the end of the sentence are the most important part of it. Readers often skip the middle of the sentences. Therefore one should put the most important information in the beggining and the end of the sentence.</li> <li>\"Old before new\" - Start sentence with something familiar (make a connection to the previous sentence), and then end with emphasis on known information or introduce a new information (this rule is more for reviews, when you are re-writting sentences)</li> <li>Prioritise clarity of a message of a sentence:<ul> <li>Can you identify sentences' subject-verb-object core? Is it obscured or is it visible?</li> <li>How long is the sentence? Don't be scared to use long sentences, but sometimes it can reduce the clarity of the sentence.</li> </ul> </li> <li>\"Lullaby effect\" - Connection between sentences:<ul> <li>\"Compared to\", \"Moreover\"...</li> <li>What kind of verbs are you using. And here one has to be careful not to use always the same verb, as it can cause something called lullaby effect.</li> </ul> </li> <li>Tenses and voice:<ul> <li>Different tenses may be used, but frequent changes will confuse the reader.</li> <li>Tenses have meaning: </li> <li>Too much future tense in outlook = unrealistic. </li> <li>Too much present tense = i'm certain </li> <li>Active vs Passive Voice: Be moderate, both are OK, but use passive only with good reason.</li> </ul> </li> </ul>"},{"location":"courses/scientific_writing_workshop/scienfitic_writing_workshop.html#chapter-51-sentences-unecessary-complexity","title":"Chapter 5.1. Sentences - unecessary complexity","text":"<ul> <li>Confusion verbs:<ul> <li>It is common for people to use ambiguous verbs, such as 'novel' or 'utilize'. It is better to use more specific verbs, such as 'new' or 'use'.</li> </ul> </li> <li>Misplaced modifiers:<ul> <li>Very common mistake in papers</li> <li>\"Rising 24000 meters into the atmosphere in only 15 minutes, scientists estimated the height of the ash cloud.\" vs \"As scientists estimated, the ash cloud rose 24000 meters into the atmosphere in only 15 minutes.\"</li> </ul> </li> <li>Nominalisations:<ul> <li>\"The stripping of the rainforests\" vs \"If the rainforest is stripped\"</li> </ul> </li> <li>This and that:<ul> <li>Because people are really scared of reperitions, they often use this and that. This quite often causes confusion, as the text is then not refering clearly to one thing. When you use this, you need to make sure that it is clear what you are referring to.</li> </ul> </li> <li>Technical words vs jargon:<ul> <li>Jargon is a unjustified use of technical words. It is useful to use technical words when they are justified.</li> </ul> </li> </ul>"},{"location":"courses/scientific_writing_workshop/scienfitic_writing_workshop.html#chapter-6-best-practices","title":"Chapter 6: Best Practices:","text":"<ul> <li>There is no need for hype and firsts:<ul> <li>Avoid: breakthrough, holy grail, smoking gun, paradigm shift</li> <li>Make sure to hedge claims to enhance your credibility (To the best of our knowledge, this is the first demonstration...) - objectivelly you are never sure if you are the first to do something.</li> </ul> </li> <li>Acronyms:<ul> <li>Shouldn't be used too densely</li> <li>Use the common ones from the field</li> </ul> </li> <li>Figures<ul> <li>Refer to them in right order</li> <li>Caption needs to be exhaustive: you shouldn't need to read the text</li> </ul> </li> <li>References<ul> <li>cite papers that are usefull - recent vs older?</li> <li>context dependent - cite an idea vs cite the explanation</li> <li>I liked how Gaia was talking about being very mindfull what we refer to. The trick is somehow to be a curator that curates the best references for the others to use</li> </ul> </li> <li>Beyond the main text - dont use suplementary material as a dump</li> </ul>"},{"location":"courses/scientific_writing_workshop/scienfitic_writing_workshop.html#random-tips","title":"Random Tips:","text":"<ul> <li>Blank page fear - copy random things</li> <li>clarity of citations - which one should i cite</li> <li>repetition of points is fine</li> </ul>"},{"location":"projects/atomphys/index.html","title":"Atomphys","text":"<p>Co-authors: Carmelo Mordini, Matt Grau</p> <p>Atomphys is a library to interface with the various databases of atomic data. It can be used to calculate properties of the atoms interacting with light, and construct all required elements for simulating the quantum dynamics of the electron in an atom through Master Equation.</p> <p>External resource: https://github.com/tiqi-group/atomphys/tree/tiqi-main</p>"},{"location":"projects/ekoacademic/index.html","title":"ekoAcademic","text":"<p>Co-authors: Aidan McConnel, Shaan Amin link: https://www.echoecho.org</p> <p>Aidan, Shaan and I wanted to have an interactive-audio version of the arXiv to listen and discuss papers during our commute. </p> <p>ekoAcademic is a small tool that generates short, accessible audio summaries of recent academic papers. It's a simple idea: you don't always have time to dive into a full paper, but you can listen to short summaries while walking, commuting or doing chores, and then decide if you want to dig deeper. We've also added a functionality for conversations and verbal Q&amp;A so you can ask questions and understand recent literature in a conversational way. This works in many languages. This means that when you interact with the audio summary, you can ask it questions in your own language, and it should automatically answer in the same language.</p> <p></p>"},{"location":"projects/ekoacademic/index.html#how-it-works","title":"How it works","text":"<ul> <li>We extract newly released papers (mirroring the arXiv categories), process/summarise them and then generate a short audio clip for each paper.</li> <li>We then have several GPT-realtime sessions designed for Q&amp;A, or summarisation of sets of papers. By allowing microphone access you can always stop it and ask questions (in any language!).</li> <li>Non-interactive podcasts are stored, so once one person listens to one, they no longer need to be generated again for anyone else.</li> <li>This means that it is relatively cheap for us to generate new podcasts, and we can do it in real-time.</li> <li>We right now work mostly with the arxiv, but if people would find it useful to have it for other databases, we can add it.</li> </ul>"},{"location":"projects/ekoacademic/index.html#feedback","title":"Feedback","text":"<p>We'd love to receive any feedback from this community:</p> <ul> <li>Does this solve a pain you have?</li> <li>What subject areas are missing (if yours isn\u2019t covered yet)?</li> <li>Could the other language options for interactive discussion be useful for you? Should we translate more of the site?</li> <li>Any concerns (accuracy of summaries, missing context)?</li> <li>Do people actually like to do this on their commute? Or is that more of a time to unwind?</li> <li>How can we make it more useful for the community?</li> <li>Are there any features that you would like to see?</li> </ul> <p>Thanks for reading. We built this because we felt this need ourselves - if others feel it too, maybe this can be a small tool to help.</p> <p>Feel free to reach out to us at wojtekadamczyk3@gmail.com</p>"},{"location":"projects/ekoacademic/building.html","title":"Building ekoAcademic","text":"<p>Co-authors: Aidan McConnel, Shaan Amin</p> <p>It was a fun project to build, We used this project as an excuse to play around with vibe-coding, and managed to build a very useful draft quite quickly.</p>"},{"location":"projects/ekoacademic/building.html#principles-we-followed","title":"Principles we followed","text":"<ul> <li>Build for ourselves first: solve our own commute-use case end to end.</li> <li>Ship fast, iterate faster: vibe-coding sessions, thin slices, frequent testing.</li> <li>Audio-first UX: frictionless playback, hands-free control, short-form by default.</li> <li>Conversation at the core: realtime Q&amp;A to go beyond passive listening.</li> <li>Multilingual by default: speech and text in many languages.</li> <li>Cache and reuse: store generated podcasts to avoid recomputation.</li> <li>Mirror the literature: track new arXiv releases and sensible categories.</li> <li>Keep it simple: minimal clicks, clear flows, and low cognitive load.</li> </ul>"},{"location":"projects/ekoacademic/building.html#vibe-coding-principles-we-followed","title":"Vibe-coding principles we followed","text":""},{"location":"projects/mud/index.html","title":"MUD \u2014 Moisture Under Detection","text":"<p>Co-authors: Peter Phillman Pedersen, C\u00e9line Portenier</p> <p>As part of the HackEO Zurich 2024 \"Pixels for the planet\" we (Peter, Celine, and I) have build a mock-up of a product and designed a technology that explains the need for more accurate moisture detection in the soil. We believe that by constructing a synthetic dataset of the soil moisture we can train a machine learning model to predict the moisture content changes of the soil with accuracy better than 0.05 \\(\\frac{\\text{m}^3}{\\text{m}^3}\\) using publically available satellite data. This would allow to see the rainfall, and derive yield index for backcasting the yield of the crops.</p> <p>External resource: https://itsmud.com</p>"},{"location":"qip1_2024/ch0.html","title":"Chapter 0: Introduction","text":"<p>My plan is to share my edited notes that I made whilst preparing for the teaching. I am doing it mainly in order to make sure I understand the topics, and motivate myself to be clear with explanations. I hope to give different intuition, which perhaps will be useful to some. </p> <p>In case of any queries and feedback, don't hesitate to contact me (wadamczyk@phys.ethz.ch)</p> <p>Resources: Which I used to write my notes - There is a lot of re-writing and paraphrasing, which I havent cited next to the sentence (the nature of notes)</p> <ul> <li>Principles of Quantum Mechanics (David Skinner) [1]</li> <li>Quantum Information Processing (J.P.Home) [2]</li> <li>Quantum Information and Computation (Richard Jozsa) [3]</li> <li>Foundations of Computer Science (Anil Madhavapeddy, Jonathan Ludlam) [4]</li> <li>Quantum Information (C.H.W. Barnes) [5]</li> </ul>"},{"location":"qip1_2024/ch0.html#chapter-0-introduction","title":"Chapter 0: Introduction","text":"<p>Computation is about manipulation of information. Mathematically we can ponder on the different abstract schemes and systems to manipulate information, however, in practice we are very limited to what type of computation can we really do. \"Information is not a disembodied abstract entity; it is always tied to a physical representation\". [3] \"If information is represented in physical states or degrees of freedom of some physical system, then any possible act of computation, or information processing, must correspond to a physical evolution of that physical system.\" [3] This means that the rules of the computation must obey the laws of physics.</p> <p>Current paradigm of computing relies on classical physics, which in result constrains what operations can we perform on the computers. \"But that is not our World. To the best of our current experimental knowledge, our World is a quantum, not classical.\" [1] This gives us hope. If one carefully isolates and always consideres the whole system, we could enlarge the zoo of the operations we could perform. Extra tools could lead to different complexity classes of the algorithms that were previously not solvable by classical computers, and could aid in further understanding of the world. </p> <p>QIP-Implementation intends to show how can we build systems that can manipulate information using laws of quantum physics. QIP-Concepts intends to entertain the idea that we have the possibility of treating the information in a quantum way. We want to give you the grounding of exploring for yourself how does this change the paradigm of computation.</p> <p>In my notes I will largely \"ignore small formal subtleties, not because they're not interesting, but because they're a distraction from all the interesting physics we want to learn!\" [1]. I will actually skip some of the formalism introduced in the lecture if I feel like it hinders my own understanding of Quantum Mechanics. I am open to being criticised for it. </p>"},{"location":"qip1_2024/ch0.html#chapter-01-why-do-we-care-about-quantum-computing","title":"Chapter 0.1: Why do we care about Quantum Computing","text":"<p>...</p>"},{"location":"qip1_2024/ch1a.html","title":"Chapter 1a: Principles of Quantum Mechanics","text":""},{"location":"qip1_2024/ch1a.html#11-hilbert-spaces","title":"1.1. Hilbert spaces:","text":"<p>Hilbert Space:</p> <ul> <li>Hilbert space is a vector space \\(\\mathcal{H}\\) over \\(\\mathbb{C}\\) that is equipped with a complete inner product. </li> <li>This definition has 3 keywords: <ul> <li>Vector space - is well known, </li> <li>Complete - is just a hedge against infinite Hilbert Spaces (unimportant)</li> <li>Inner Product is a map \\((\\quad,\\quad): \\mathcal{H} \\times \\mathcal{H} \\rightarrow \\mathbb{C}\\) that obeys</li> </ul> </li> </ul> \\[ \\begin{aligned} \\text { conjugate symmetry } &amp; (\\phi, \\psi)=\\overline{(\\psi, \\phi)} \\\\ \\text { linearity } &amp; (\\phi, a \\psi)=a(\\phi, \\psi) \\\\ \\text { additivity } &amp; (\\phi, \\psi+\\chi)=(\\phi, \\psi)+(\\phi, \\chi) \\\\ \\text { positive-definiteness } &amp; (\\psi, \\psi) \\geq 0 \\forall \\psi \\in \\mathcal{H} \\end{aligned} \\] <ul> <li>Metric of \\(\\mathcal{H}\\) is defined by the norm \\(\\|\\psi\\| \\equiv \\sqrt{(\\psi, \\psi)}\\)</li> <li>Quantum states can be represented as a vectors \\(\\psi \\in \\mathcal{H}\\)</li> </ul> <p>Dual Spaces:</p> <ul> <li>Dual space \\(\\mathcal{H^*}\\) of a \\(\\mathcal{H}\\) is the space of linear maps \\(\\mathcal{H} \\rightarrow \\mathbb{C}\\). That is, an element \\(\\phi \\in \\mathcal{H^*}\\) defines a map \\(\\varphi: \\psi \\mapsto \\varphi(\\psi) \\in \\mathbb{C}\\) for every \\(\\psi \\in \\mathcal{H}\\), such that </li> </ul> \\[ \\varphi: a \\psi_1+b \\psi_2 \\mapsto a \\varphi\\left(\\psi_1\\right)+b \\varphi\\left(\\psi_2\\right) \\] <ul> <li>One of the dual space \\(\\mathcal{H^*}\\) is for instance the inner product \\((\\phi, \\quad) \\in \\mathcal{H}^*\\) for \\(\\phi \\in \\mathcal{H}\\), where </li> </ul> \\[ (\\phi, \\quad): \\psi \\mapsto(\\phi, \\psi) \\]"},{"location":"qip1_2024/ch1a.html#12-dirac-notation","title":"1.2. Dirac Notation:","text":"<p>In quantum mechanics quite often we often switch basis. This is because intrinsically any measurement causes a collapse onto the measurement basis. Because of this we want to have a notation that allows us to work with multiple basis at the same time, and not get confused. Dirac notation (empirically) provides this clarity. It is difficult to formally define the notation, and quite often when one does it, they get confused (unless they are deep down in theory). Therefore I would propose to learn it through learning the basic few properties and then trying things out. </p> <p>Dirac denotes element of \\(\\mathcal{H}\\) as \\(\\left|\\psi\\right&gt;\\) 'ket', and an element of the dual space is written as \\(\\mathcal{H^*}\\) as \\(\\left&lt;\\psi\\right|\\) 'bra'. The inner product between two states \\(\\left|\\psi\\right&gt;, \\left|\\phi\\right&gt; \\in \\mathcal{H}\\) is written as \\(\\left&lt;\\psi|\\phi\\right&gt;\\).</p> <p>In notes the bra-ket notation is introduced using homomorphisms (linear maps). I find it unecessary.</p> <ul> <li>The advantage of using bra-ket notation is:<ul> <li>We can talk about multiple things at the same time - Dirac notation is effectively just a label that points to an abstract object in the Hilbert space. We don't need to specify whether the variable is contineous, or if it is a vector or a function.</li> <li>Allows us to label states by their eigenvalues</li> <li>Somehow it is more natural and causes less confusion</li> </ul> </li> </ul>"},{"location":"qip1_2024/ch1a.html#13-operators","title":"1.3. Operators:","text":"<ul> <li>A linear operator A is a map \\(A : \\mathcal{H} \\rightarrow \\mathcal{H}\\) that is compatible with the vector space structure \\(A(c_1\\left|\\phi_1\\right&gt; + c_2\\left|\\phi_2\\right&gt;) = c_1A\\left|\\phi_1\\right&gt; + c_2A\\left|\\phi_2\\right&gt;\\)</li> <li>All operators in Quantum Mechanics are linear, hence we will call them just 'operators'</li> <li>Operators form algebra<ul> <li>Sum: \\((\\alpha A+\\beta B):\\left|\\phi\\right&gt; \\mapsto \\alpha A\\left|\\phi\\right&gt;+\\beta B\\left|\\phi\\right&gt;\\)</li> <li>Product: \\(A B: \\phi \\mapsto A \\circ B\\left|\\phi\\right&gt;=A(B\\left|\\phi\\right&gt;)\\)</li> <li>Commutator: \\([A, B]=A B-B A\\)</li> </ul> </li> <li>A state \\(\\psi \\in \\mathcal{H}\\) is said to be an eigenstate of an operator A if \\(A\\left|\\psi\\right&gt; = a_\\psi\\left|\\psi\\right&gt;\\) with an associated eigenvalue '\\(a_\\psi\\)'.</li> <li>Adjoint \\(A^\\dagger\\) of an operator \\(A\\) is defined as \\(\\left&lt;\\phi\\right|A^{\\dagger}\\left| \\psi\\right&gt;=\\overline{\\left&lt;\\psi\\right|A\\left| \\phi\\right&gt;} \\quad\\)</li> <li>An operator \\(Q\\) is called Hermitian if \\(Q^\\dagger=Q\\)</li> <li>An operator \\(U\\) is called Unitary if \\(U^\\dagger U= U U^\\dagger = \\mathbb{I}\\)</li> <li>An operator \\(\\Pi\\) is called Projector if \\(\\Pi\\Pi= \\Pi\\)</li> </ul>"},{"location":"qip1_2024/ch1a.html#14-composite-systems","title":"1.4. Composite systems:","text":"<p>Tensor Product</p> <ul> <li>Tensor product \\(\\mathcal{H}_1 \\otimes \\mathcal{H}_2\\) is a vector space over \\(\\mathbb{C}\\) spanned by all pairs of elements \\(\\left|e_a\\right&gt; \\otimes\\left|f_\\alpha\\right&gt;\\), where \\(\\left|e_a\\right&gt; \\in \\mathcal{H_1}\\), \\(\\left|f_\\alpha\\right&gt; \\in \\mathcal{H_2}\\)</li> <li>It is not true that a general element of \\(\\mathcal{H}_1 \\otimes \\mathcal{H}_2\\) necessarily takes the form \\(\\left|\\psi_1\\right&gt;\\otimes\\left|\\psi_2\\right&gt;\\)</li> <li>Rahter, a general element may be written as \\(\\left|\\Psi\\right&gt;=\\sum_{a, \\alpha} r_{a \\alpha}\\left|e_a\\right&gt; \\otimes\\left|f_\\alpha\\right&gt;\\)</li> <li>Elements of the form \\(\\left|\\psi_1\\right&gt;\\otimes\\left|\\psi_2\\right&gt;\\) are called simple, and the elements of the form \\(\\left|\\Psi\\right&gt;=\\sum_{a, \\alpha} r_{a \\alpha}\\left|e_a\\right&gt; \\otimes\\left|f_\\alpha\\right&gt;\\) are refered as entangled</li> <li>\\(\\left&lt;\\alpha\\otimes\\beta|\\alpha'\\otimes\\beta'\\right&gt; := \\left&lt;\\alpha|\\alpha'\\right&gt;\\left&lt;\\beta|\\beta'\\right&gt;\\)</li> <li>\\(\\left( S_\\alpha \\otimes T_\\beta \\right)\\left(\\alpha \\otimes \\beta\\right) = \\left(S_\\alpha\\alpha\\right)\\otimes\\left(T_\\beta\\beta\\right)\\) - apologies for being slightly sloppy - I think it is understandable what I mean though</li> </ul> <p>Tensor Product in action (states)</p> <ul> <li>Let's as an example consider that our states \\(\\left|\\alpha\\right&gt;_A \\text{ and } \\left|\\beta\\right&gt;_B\\) live both in \\(\\mathbb{C}^2_A\\) and \\(\\mathbb{C}^2_B\\) respectively. Then we can pick orthonormal basis of \\(\\mathbb{C}^2_A\\) to be \\(\\left\\{\\left|u_1\\right&gt;_A, \\left|u_2\\right&gt;_A \\right\\}\\), and of \\(\\mathbb{C}^2_B\\) to be \\(\\left\\{\\left|v_1\\right&gt;_B, \\left|v_2\\right&gt;_B \\right\\}\\)</li> <li>Then one can write \\(\\left|\\alpha\\right&gt;_A = a_1 \\left|u_1\\right&gt;_A + a_2 \\left|u_2\\right&gt;_A = a_1 \\begin{pmatrix} 1\\\\ 0 \\end{pmatrix}_A + a_2 \\begin{pmatrix} 0\\\\ 1 \\end{pmatrix}_A\\),</li> <li>and \\(\\left|\\beta\\right&gt;_B = b_1 \\left|v_1\\right&gt;_B + b_2 \\left|v_2\\right&gt;_B = b_1 \\begin{pmatrix} 1\\\\ 0 \\end{pmatrix}_B + b_2 \\begin{pmatrix} 0\\\\ 1 \\end{pmatrix}_B\\)</li> <li>This means that one can write </li> </ul> \\[ \\left|\\alpha\\right&gt;_A \\otimes \\left|\\beta\\right&gt;_B = \\begin{pmatrix} a_1\\\\ a_2 \\end{pmatrix}_A \\otimes \\begin{pmatrix} b_1\\\\ b_2 \\end{pmatrix}_B = \\begin{pmatrix} a_1b_1\\\\ a_1b_2\\\\ a_2b_1\\\\ a_2b_2 \\end{pmatrix} \\] <ul> <li>or sticking to the Dirac notation:</li> </ul> \\[ \\left|\\alpha\\right&gt;_A \\otimes \\left|\\beta\\right&gt;_B = \\sum_{i,j} a_i b_j \\left|u_i\\right&gt;_A \\otimes \\left|v_j\\right&gt;_B \\] <p>Tensor Product in action (operators)</p> <ul> <li>For operators \\(A\\) and \\(B\\) that live in \\(\\mathbb{C}^2_A\\) and \\(\\mathbb{C}^2_B\\) respectively, one can write \\(A = \\sum_{i,j} a_{ij} \\left|u_i\\right&gt;_A \\left&lt;u_j\\right|\\) and \\(B = \\sum_{i,j} b_{ij} \\left|v_i\\right&gt;_B \\left&lt;v_j\\right|\\)</li> <li>This means:</li> </ul> \\[ A \\otimes B = \\sum_{i,j,k,\\ell} a_{ij} b_{k\\ell} \\left|u_i\\right&gt;_A \\otimes \\left|v_k\\right&gt;_B \\left&lt;u_j\\right|\\otimes\\left&lt;v_\\ell\\right| \\] <ul> <li>or in a matrix form:</li> </ul> \\[ A \\otimes B = \\begin{pmatrix} a_{11}B &amp; a_{12}B\\\\ a_{21}B &amp; a_{22}B \\end{pmatrix} = \\begin{pmatrix} a_{11}b_{11} &amp; a_{11}b_{12} &amp; a_{12}b_{11} &amp; a_{12}b_{12}\\\\ a_{11}b_{21} &amp; a_{11}b_{22} &amp; a_{12}b_{21} &amp; a_{12}b_{22}\\\\ a_{21}b_{11} &amp; a_{21}b_{12} &amp; a_{22}b_{11} &amp; a_{22}b_{12}\\\\ a_{21}b_{21} &amp; a_{21}b_{22} &amp; a_{22}b_{21} &amp; a_{22}b_{22}\\\\ \\end{pmatrix} \\]"},{"location":"qip1_2024/ch1a.html#15-postulates-of-quantum-mechanics","title":"1.5. Postulates of Quantum Mechanics:","text":"<ul> <li>(1) A quantum system A is associated with complex Hilber space \\(\\mathcal{H}\\). A physical state of an isolated system is represented by a normalised vector \\(\\left|\\psi\\right&gt; \\in \\mathcal{H}\\), which is unique up to a phase factor</li> <li>(2) The evolution of an isolated quantum system is reversible. In this formalism this corresponds to unitary evolution of the form \\(\\left|\\psi\\right&gt; \\mapsto U\\left|\\psi\\right&gt;\\) for \\(U \\in \\mathcal{U}(\\mathcal{H})\\), i.e. \\(U^{\\dagger} U=U U^{\\dagger}=\\mathbb{I}\\). The unitary is unique up to a phase factor</li> <li>(3) Composite system - For two quantum system A, and B with associated Hilber spaces \\(\\mathcal{H_A}\\) and \\(\\mathcal{H_B}\\) the Hilbert space \\(\\mathcal{H_{AB}}\\) associated with the composite system AB is isomorphic to the tensor product \\(\\mathcal{H_A}\\otimes\\mathcal{H_B}\\). For unitary operation on the subsystem we use: \\(U_A \\otimes \\mathbb{I}_B\\left|i j\\right&gt;_{A B} \\equiv U_A\\left|i j\\right&gt;_{A B}\\)</li> <li>(4) Measurement - A projective measurement on a quantum system with outcomes labelled \\({x}_x\\) is associated with a set of projectors \\({\\Pi_x}x\\) satisfying \\(\\sum_x \\Pi_x = \\mathbb{I}\\). <ul> <li>Probability of getting outcome x when measuring state \\(\\left|\\psi\\right&gt;\\) is given by the Born rule: \\(Pr[x \\mid \\psi]=\\left\\langle\\psi\\left|\\Pi_x\\right| \\psi\\right\\rangle\\)</li> <li>Post-measurement state is given the outcome x is \\(\\left|\\psi_x^{\\prime}\\right&gt;=\\frac{1}{\\sqrt{\\operatorname{Pr}[x \\mid \\psi]}} \\Pi_x\\left|\\psi\\right&gt;=\\frac{\\Pi_x\\left|\\psi\\right&gt;}{\\sqrt{\\left\\langle\\psi\\left|\\Pi_x\\right| \\psi\\right\\rangle}}\\)</li> </ul> </li> </ul>"},{"location":"qip1_2024/ch1b.html","title":"Chapter 1b: Usefull Toolbox","text":""},{"location":"qip1_2024/ch1b.html#16-bloch-sphere","title":"1.6. Bloch Sphere:","text":"<ul> <li>Because in my class there are a lot of non-physicists I thought it would be useful to introduce the concept of the Bloch Sphere. </li> <li>Bloch Sphere is just a common representation of a two level system, which allows one to think about the states and operations in a more intuitive way</li> <li>Normally when one thinks about how many parameters one needs to define a two level system, they can naively thing 4. In the end two level system lives in \\(\\left|\\psi\\right&gt; \\in \\mathbb{C}^2\\). In different words, any pure state can be written as a superposition of the basis vectors \\(\\left|0\\right&gt;\\) and \\(\\left|1\\right&gt;\\), where the coefficient of each of the two basis vectors is a complex number. \\(\\left|\\psi\\right&gt; = a_1e^{i\\theta_1} \\left|0\\right&gt; +  a_2e^{i\\theta_2} \\left|1\\right&gt;\\). 4-parameters right?<ul> <li>We know, however, that the norm of a pure state must equal to 1, which means that $\\left&lt;\\psi|\\psi\\right&gt; = 1 $, and so \\(\\left|a_1\\right|^2 + \\left|a_2\\right|^2=1\\). This reduces the number of free parameters to 3</li> <li>We also know that we dont care about the global phase of a state, as it doesn't change anything about our measurement, and so we can also neglect one degree of freedom, which reduces the number of free parameters to 2</li> <li>This means that we can represent any 2-level quantum pure state on a unit sphere, which we will call Bloch Sphere</li> </ul> </li> <li>How does one parametrise something on a unit-sphere?<ul> <li>One can do it with angles, \\(\\theta \\text{ and } \\phi\\)</li> <li>\\(\\left|\\psi\\right&gt; = \\cos\\frac{\\theta}{2} \\left|0\\right&gt; +  e^{i\\phi}\\sin{\\frac{\\theta}{2}} \\left|1\\right&gt;\\)</li> <li>In such representation the probability of measuring state \\(\\left|0\\right&gt;\\) is: \\(\\left&lt;0|\\psi\\right&gt; = \\cos^2\\frac{\\theta}{2}\\), and to measure state \\(\\left|1\\right&gt;\\) is \\(\\sin^2\\frac{\\theta}{2}\\)</li> <li>\\(\\left|\\psi\\right&gt;\\) can be represented on a unit sphere as:</li> </ul> </li> </ul> <p>  - Any Unitary Operator then will be some sort of rotation of this state, mapping it from one point on this sphere to another point on this sphere - you will see it in the subchapter Quantum Circuits</p>"},{"location":"qip1_2024/ch1b.html#17-bell-basis","title":"1.7. Bell Basis","text":"<ul> <li>Let \\(\\mathcal{H}_{A B}=\\mathcal{H}_A \\otimes \\mathcal{H}_B \\cong \\mathbb{C}^4\\) be the bipartite Hilbert space of two qubits and consider the product basis of the computational bases of the qubit subsystems. For \\(\\mathcal{H_{AB}}\\) there exists a basis consisting of maximally entangled states denotes as:</li> </ul> \\[\\begin{array}{ll}\\left|\\psi^{00}\\right&gt;=\\frac{1}{\\sqrt{2}}(\\left|00\\right&gt;+\\left|11\\right&gt;) &amp; =\\left|\\Phi^{+}\\right&gt; \\\\ \\left|\\psi^{01}\\right&gt;=\\frac{1}{\\sqrt{2}}(\\left|00\\right&gt;-\\left|11\\right&gt;) &amp; =\\left|\\Phi^{-}\\right&gt; \\\\ \\left|\\psi^{10}\\right&gt;=\\frac{1}{\\sqrt{2}}(\\left|01\\right&gt;+\\left|10\\right&gt;) &amp; =\\left|\\Psi^{+}\\right&gt; \\\\ \\left|\\psi^{11}\\right&gt;=\\frac{1}{\\sqrt{2}}(\\left|01\\right&gt;-\\left|10\\right&gt;) &amp; =\\left|\\Psi^{-}\\right&gt;\\end{array}\\] <ul> <li>The first number stands for parity, the second number stands for phase. \\(\\left|\\psi^{10}\\right&gt;\\) has parity 1 (odd number of 1's), and relative phase \\((-1)^0=1\\)</li> <li>The maximally entangled states are locally convertible - there exist local operations on the subsystem B that transforms one Bell state into another Bell state. \\(\\(\\left|\\psi^{i j}\\right&gt;=\\left(\\mathbb{I}_A \\otimes X_B^i Z_B^j\\right)\\left|\\psi^{00}\\right&gt;\\)\\)</li> </ul>"},{"location":"qip1_2024/ch1b.html#18-quantum-circuits","title":"1.8. Quantum Circuits","text":"<p>Example Quantum circuit</p> <p> </p> <p>corresponds to unitary operator \\(\\left(V \\otimes \\mathbb{I}\\right)\\left(\\mathbb{I}\\otimes U\\right)\\left(H\\otimes\\mathbb{I}\\otimes Z\\right)\\) applied to three qubits followed by a Z-measurement of the first qubit</p> <p>Common Gates</p> <ul> <li>Haddamard Gate:<ul> <li>\\(H=\\frac{1}{\\sqrt{2}}\\left(\\begin{array}{cc}1 &amp; 1 \\\\ 1 &amp; -1\\end{array}\\right)=\\left|+\\right&gt;\\left&lt; 0\\right|+\\left|-\\right&gt; \\left&lt;1\\right|=\\left| 0\\right&gt;\\left&lt;+\\right|+\\left| 1\\right&gt;\\left&lt;-\\right|\\)</li> <li>As an orthogonal transformation in the real Euclidean plane \\(\\mathbb{R}^2\\), H is reflection in the mirror line at angle \\(\\frac{\\pi}{8}\\) to the x-axis  </li> </ul> </li> <li>X, Y, Z:<ul> <li>\\(X = \\left(\\begin{array}{ll} 0 &amp; 1 \\\\ 1 &amp; 0 \\end{array}\\right)\\), \\(Z = \\left(\\begin{array}{ll} 1 &amp; 0 \\\\ 0 &amp; -1 \\end{array}\\right)\\), \\(Y = \\left(\\begin{array}{ll} 0 &amp; 1 \\\\ -1 &amp; 0 \\end{array}\\right)\\)</li> <li>X-gate<ul> <li> </li> </ul> </li> <li>Y-gate<ul> <li> </li> </ul> </li> <li>Z-gate<ul> <li> </li> </ul> </li> </ul> </li> <li>Controlled-U Gate:<ul> <li>\\(\\mathrm{C} U=\\left|0\\right&gt;\\left&lt;0\\right|\\otimes \\mathrm{id}+\\left| 1\\right&gt;\\left&lt;1\\right| \\otimes U\\)</li> </ul> </li> <li>Controlled-Not Gate:<ul> <li>\\(\\mathrm{CNOT}=\\left(\\begin{array}{llll}1 &amp; 0 &amp; 0 &amp; 0 \\\\ 0 &amp; 1 &amp; 0 &amp; 0 \\\\ 0 &amp; 0 &amp; 0 &amp; 1 \\\\ 0 &amp; 0 &amp; 1 &amp; 0\\end{array}\\right)=\\left|0 \\right&gt;\\left&lt; 0\\right| \\otimes \\mathbb{I}+\\left|1\\right&gt;\\left&lt;1\\right| \\otimes X\\)</li> </ul> </li> </ul>"},{"location":"qip1_2024/ch2a.html","title":"Chapter 2a: Quantum Information","text":"<p>Initially I didn't want to talk much about quantum information theory. In my mind there is another course that deals with it in much more detail (Quantum Information Theory). However, because the lecture course covers these topics, I decided to include few ideas. I will try to keep them at a very high level and focus on their relevance to quantum algorithms.</p>"},{"location":"qip1_2024/ch2a.html#21-nature-of-quantum-information","title":"2.1. Nature of Quantum Information:","text":"<ul> <li>Quantum information is different from the classical information in a sense that the measurements corrupts the state itself</li> <li>We can prepare any desired pure state, but if we receive such pure state we cannot identify it with certainty (if we dont know how to measure it)</li> <li>Given a unknown quantum state \\(\\left|\\psi\\right&gt;\\) there are three basic operations that we can perform:<ul> <li>Ancilla - take a second, known, quantum system \\(\\left|A\\right&gt;\\) and join it with \\(\\left|\\psi\\right&gt;\\) and treat it as a composite system \\(\\left|\\psi\\right&gt; \\otimes \\left|A\\right&gt;\\)</li> <li>Unitary - we can perform a unitary on \\(\\left|\\psi\\right&gt;\\) and obtain \\(\\left|\\psi^{\\prime}\\right&gt; = U\\left|\\psi\\right&gt;\\) - i.e. all your gates</li> <li>Measurement - we can perform a measurement on \\(\\left|\\psi\\right&gt;\\), or sub-system of it, record the outcome and retain the post-measurement state for further processing</li> </ul> </li> <li>Any quantum operation can be described as a composition of these three operations. Quite often the algorithms used to manipulate information use all of those operations and not just gates</li> </ul>"},{"location":"qip1_2024/ch2a.html#22-no-cloning-theorem","title":"2.2. No-Cloning Theorem:","text":"<ul> <li>Cloning operation of a quantum state \\(\\left|\\psi\\right&gt;\\) is defined as a map \\(\\left|\\psi\\right&gt;_A \\left|0\\right&gt;_B \\rightarrow \\left|\\psi\\right&gt;_A \\left|\\psi\\right&gt;_B\\)</li> <li>We can extend it to a larger system, by adjoining ancilla to it. In this case the cloning operations can be defined as \\(\\left|\\psi\\right&gt;_A \\left|0\\right&gt;_B \\left|M_0\\right&gt;_M \\rightarrow \\left|\\psi\\right&gt;_A \\left|\\psi\\right&gt;_B \\left|M_\\psi\\right&gt;_M\\)</li> <li>No-Cloning Theorem: Let \\(\\mathcal{S}\\) be any set of states of A that contains at least one non-orthogonal state. Then there is no unitary cloning process that achieves cloning for all states in \\(\\mathcal{S}\\).</li> <li>Remark: I am only presenting a proof of 'no-cloning theorem' for the case where the agent is only allowed to perform unitary operations. There exists an extention of this theorem for any 3 basic operations (Ancilla, Unitary, Measurement).</li> </ul>"},{"location":"qip1_2024/ch2a.html#proof","title":"Proof:","text":"<p>Let \\(\\left|\\psi\\right&gt;\\) and \\(\\left|\\phi\\right&gt;\\) be two distinct non-orthogonal states in \\(\\mathcal{S}\\). Lets assume that there exist a unitary \\(U\\) that clone the states in \\(\\mathcal{S}\\).</p> <p>then</p> \\[ U\\left|\\psi\\right&gt;_A \\left|0\\right&gt;_B \\left|M_0\\right&gt;_M = \\left|\\psi\\right&gt;_A \\left|\\psi\\right&gt;_B \\left|M_\\psi\\right&gt;_M \\] \\[ U\\left|\\phi\\right&gt;_A \\left|0\\right&gt;_B \\left|M_0\\right&gt;_M = \\left|\\phi\\right&gt;_A \\left|\\phi\\right&gt;_B \\left|M_\\phi\\right&gt;_M \\] <p>then </p> \\[ \\left&lt;M_0\\right|_M\\left&lt;0\\right|_B\\left&lt;\\psi\\right|_A U^\\dagger U\\left|\\phi\\right&gt;_A \\left|0\\right&gt;_B \\left|M_0\\right&gt;_M = \\left&lt;M_\\psi\\right|_M \\left&lt;\\psi\\right|_B \\left&lt;\\psi\\right|_A \\left|\\phi\\right&gt;_A \\left|\\phi\\right&gt;_B \\left|M_\\phi\\right&gt;_M \\] \\[ \\left&lt;M_0|M_0\\right&gt;_M\\left&lt;0|0\\right&gt;_B\\left&lt;\\psi|\\phi\\right&gt;_A = \\left&lt;M_\\psi|M_\\psi\\right&gt;_M\\left&lt;\\psi|\\phi\\right&gt;_A\\left&lt;\\psi|\\phi\\right&gt;_B \\] \\[ \\left&lt;\\psi|\\phi\\right&gt;_A = \\left&lt;M_\\psi|M_\\phi\\right&gt;_M\\left&lt;\\psi|\\phi\\right&gt;_A\\left&lt;\\psi|\\phi\\right&gt;_B \\] <p>since \\(\\left|\\psi\\right&gt;\\) and \\(\\left|\\phi\\right&gt;\\) are non-orthogonal, we can divide both sides by \\(\\left&lt;\\psi|\\phi\\right&gt;_A\\) and get:</p> \\[ 1 = |\\left&lt;M_\\psi|M_\\phi\\right&gt;_M\\left&lt;\\psi|\\phi\\right&gt;_B| \\] <ul> <li>\\(M_\\psi\\) and \\(M_\\phi\\) are quantum states: \\(|\\left&lt;M_\\psi|M_\\phi\\right&gt;_M| \\leq 1\\),  </li> <li>\\(\\left|\\psi\\right&gt;\\) and \\(\\left|\\phi\\right&gt;\\) are distinct states and so: \\(|\\left&lt;\\psi|\\phi\\right&gt;_B| &lt; 1\\)</li> <li>Therefore we arrive to a contradiction, which completes the proof</li> </ul>"},{"location":"qip1_2024/ch2a.html#herberts-method-of-superluminal-communication","title":"Herbert's method of superluminal communication:","text":"<ul> <li>The no-cloning theorem was crucial for debugging the protocol of superluminal communication proposed by Herbert. See more in Richard's Jozsa notes [4].</li> </ul>"},{"location":"qip1_2024/ch2a.html#23-quantum-teleportation","title":"2.3. Quantum Teleportation:","text":"<p>Consider that Alice and Bob share an entangled Bell state \\(\\left|\\phi^{+}\\right&gt;_{23} = \\frac{1}{\\sqrt{2}}(\\left|00\\right&gt; + \\left|11\\right&gt;)_{23}\\), such that each of them has one qubit of the pair. Additionally Alice has a qubit in a state \\(\\left|\\alpha\\right&gt;_1 = a\\left|0\\right&gt; + b \\left|1\\right&gt;\\). </p> <p>This means that the combined state of the system is:</p> \\[ \\begin{aligned} \\left|\\psi\\right&gt;_{AB} &amp;= \\left|\\alpha\\right&gt;_1 \\left|\\phi^{+}\\right&gt;_{23} = \\left(a\\left|0\\right&gt; + b\\left|1\\right&gt;\\right)_1 \\frac{1}{\\sqrt{2}}(\\left|00\\right&gt; + \\left|11\\right&gt;)_{23} \\\\ &amp; = \\frac{a}{\\sqrt{2}}\\left|000\\right&gt; + \\frac{a}{\\sqrt{2}}\\left|011\\right&gt; + \\frac{b}{\\sqrt{2}}\\left|100\\right&gt; + \\frac{b}{\\sqrt{2}}\\left|111\\right&gt; \\end{aligned} \\] <p>Task: of the quantum teleportation is to transfer the state of \\(\\left|\\alpha\\right&gt;_1\\) to \\(\\left|\\beta\\right&gt;_3\\) by performing local operations and classical communication.</p>"},{"location":"qip1_2024/ch2a.html#algorithm","title":"Algorithm:","text":"<ol> <li>Alice performs a Bell measurement on the two qubits (Performs a projective measurement in the Bell basis)     &lt;!-- 1. Alice applies CX to her qubits 1 and 2<ol> <li>Alice applies H to her qubit 1</li> <li>Alice measures her two qbits to obtain a 2-bit string 00, 01, 10 or 11 --&gt;</li> </ol> </li> <li>Alice sends a 2-bit measurement outcome ij to Bob</li> <li>On receiving ij Bob applies the unitary operation \\(Z^iX^j\\) to his qubit, which is then guaranteed to be in the state \\(\\left|\\alpha\\right&gt;_3\\)</li> </ol> <p>Remark: No information about \\(\\left|\\alpha\\right&gt;_2\\) is left with Alice</p>"},{"location":"qip1_2024/ch2a.html#why-it-works","title":"Why it works:","text":""},{"location":"qip1_2024/ch2a.html#explanation-1","title":"Explanation 1:","text":"<p>(From explanation 1 we would like to learn about how local operations on single qubits can affect the measurement outcome of the measurement of the second qubit.)</p> <p>We can write \\(\\left|\\psi\\right&gt;_{AB}\\) as:</p> \\[ \\begin{aligned} \\left|\\psi\\right&gt;_{AB} &amp;= \\frac{a}{\\sqrt{2}}\\left|000\\right&gt;_{123} + \\frac{a}{\\sqrt{2}}\\left|011\\right&gt;_{123} + \\frac{b}{\\sqrt{2}}\\left|100\\right&gt;_{123} + \\frac{b}{\\sqrt{2}}\\left|111\\right&gt;_{123}\\\\ &amp;= \\frac{a}{2}\\left(\\left|\\psi_{00}\\right&gt;_{12} + \\left|\\psi_{01}\\right&gt;_{12}\\right)\\left|0\\right&gt;_{3} + \\frac{a}{2}\\left(\\left|\\psi_{10}\\right&gt;_{12} + \\left|\\psi_{11}\\right&gt;_{12}\\right)\\left|1\\right&gt;_{3} + \\frac{b}{2}\\left(\\left|\\psi_{10}\\right&gt;_{12} - \\left|\\psi_{11}\\right&gt;_{12}\\right)\\left|0\\right&gt;_{3} + \\frac{b}{2}\\left(\\left|\\psi_{00}\\right&gt;_{12} - \\left|\\psi_{01}\\right&gt;_{12}\\right)\\left|1\\right&gt;_{3} \\\\ &amp;= \\left|\\psi_{00}\\right&gt;_{12}\\left(\\frac{a}{2}\\left|0\\right&gt;_{3} + \\frac{b}{2}\\left|1\\right&gt;_{3}\\right) + \\left|\\psi_{01}\\right&gt;_{12}\\left(\\frac{a}{2}\\left|0\\right&gt;_{3} - \\frac{b}{2}\\left|1\\right&gt;_{3}\\right) + \\left|\\psi_{10}\\right&gt;_{12}\\left(\\frac{a}{2}\\left|1\\right&gt;_{3} + \\frac{b}{2}\\left|0\\right&gt;_{3}\\right) + \\left|\\psi_{11}\\right&gt;_{12}\\left(\\frac{a}{2}\\left|1\\right&gt;_{3} - \\frac{b}{2}\\left|0\\right&gt;_{3}\\right)\\\\ \\end{aligned} \\] <p>Therefore when we measure in which bell state the first two qubits are then we get the following post-measurement states:</p> \\[ \\begin{array}{cc} \\text { mmt outcome } &amp; \\text { post-mmt state } \\\\ 00 &amp; \\left|00\\right&gt;_{12}\\left|\\alpha\\right&gt;_3 \\\\ 01 &amp; \\left|01\\right&gt;_{12}X\\left|\\alpha\\right&gt;_3 \\\\ 10 &amp; \\left|10\\right&gt;_{12}Z\\left|\\alpha\\right&gt;_3 \\\\ 11 &amp; \\left|11\\right&gt;_{12}XZ\\left|\\alpha\\right&gt;_3 \\end{array} \\] <p>Therefore knowing the outcome of the measurement Alice can send a 2-bit string to Bob, who then applies the corresponding operation to his qubit and recovers the state \\(\\left|\\alpha\\right&gt;_3\\)</p>"},{"location":"qip1_2024/ch2a.html#explanation-2","title":"Explanation 2:","text":"<p>(From this explanation we would like to learn how to perform an operation that depends on the measurement outcome.)</p> <p>What I would like to do here is to provide slightly different explanation. I don't like Explanation 1 because it feels very brute forcy, and it doesn't provide any additional intuition about why things are, like they are. The following explanation is perhaps slightly more tricky to grasp, but I think it provides more insight.</p> <p>E.2.1.</p> <p>I would like to start with a simple observation. When we project the first two qubits into the state \\(\\left|\\psi_{00}\\right&gt;_{12}\\) then we get:</p> \\[ \\left&lt;\\psi_{00}\\right|_{12}\\left|\\alpha\\right&gt;_1\\left|\\psi_{00}\\right&gt;_{23} = \\left|\\alpha\\right&gt;_3 \\] <p>One might then ask is it true for more general case? Is this statement true for any state \\(\\left|\\psi_{ij}\\right&gt;_{23}\\):</p> \\[ \\left&lt;\\psi_{ij}\\right|_{12}\\left|\\alpha\\right&gt;_1\\left|\\psi_{ij}\\right&gt;_{23} \\stackrel{?}{=} \\left|\\alpha\\right&gt;_3 \\] <p>This must be true as we can write </p> \\[ \\left&lt;\\psi_{ij}\\right|_{12}\\left|\\alpha\\right&gt;_1\\left|\\psi_{ij}\\right&gt;_{23} = \\left(\\left&lt;\\psi_{00}\\right|_{12} X_2^i Z_2^j\\right)\\left|\\alpha\\right&gt;_1\\left(Z_2^i X_2^j\\left|\\psi_{00}\\right&gt;_{23}\\right) = \\left&lt;\\psi_{00}\\right|_{12}\\left|\\alpha\\right&gt;_1\\left|\\psi_{00}\\right&gt;_{23}= \\left|\\alpha\\right&gt;_3 \\] <p>Wow! This means that quantum teleportation is trivial. If we could perform a projection operation on the first two qubits onto the bell state in which we prepared the pair of second and third qubit, we would simply teleport the state from a qubit 1 to a qubit 3. However, the projection operation is non-unitary and we cannot do it in a unitary way. We need to find workaround. </p> <p>Something that performs a projection operation on the first two qubits is the Bell measurement. This will, however, perform a projective measurement to an arbitrary state and not just the \\(\\left|\\psi_{00}\\right&gt;_{12}\\). The measurement projects the first two qubits into {\\(\\left|\\psi_{00}\\right&gt;_{12}\\), \\(\\left|\\psi_{01}\\right&gt;_{12}\\), \\(\\left|\\psi_{10}\\right&gt;_{12}\\), \\(\\left|\\psi_{11}\\right&gt;_{12}\\)}. Can we somehow know into which state it will project and perform a corresponding operation on the third qubit prior to the measurement?</p> <p>We know it after the measurement, but not before. Before the measurement we cannot know the state into which the measurement will project us (no hidden-variables :)). </p> <p>E.2.2.</p> <p>And here comes the step two: perhaps it doesn't really matter whether we do the operation on the third qubit prior to the measurement or after the measurement. And this I am showing below.</p> \\[ \\left( \\left&lt;\\psi_{ij}\\right|_{12} \\otimes \\mathbb{I}_3\\right) \\left( \\mathbb{I}_{12} \\otimes X_3^i Z_3^j\\right) \\left|\\psi\\right&gt;_{AB} = \\left( \\mathbb{I}_{12} \\otimes X_3^i Z_3^j\\right) \\left( \\left&lt;\\psi_{ij}\\right|_{12} \\otimes \\mathbb{I}_3\\right) \\left|\\psi\\right&gt;_{AB}  = \\left|\\alpha\\right&gt;_3 \\] <p>Et voil\u00e0! It doesn't matter. This is great news, because after the measurement we know into which state we projected the Bell basis. And if we then can perform the unitaries on the qubit 3, we can achieve the same result as if we did it before the measurement.</p> <p>E.2.3.</p> <p>This completes the explanation. What I want to show with this explanation, that you can try to think how to build non-unitary operations on your quantum system if you include the measurement and ancilla as part of your allowed operations. This can quite often suprise you.</p> <p>Feedback: The explanation was coined by me through talking to others and thinking. I haven't seen it anywhere else, so I would love to refine it if you have any ideas how to improve the clarity of the delivery wadamczyk@phys.ethz.ch.</p>"},{"location":"qip1_2024/ch3a.html","title":"Chapter 3a: Computational Complexity:","text":"<p>I will start first by introducing the ideas from the classical computations, and then I will try to extend it to quantum computation and then try to observe the difference. </p> <p>Computational task is usually general i.e. 'given an n-bit string A (for any n), is A prime?'. Studying information theory, we are interested to know how efficient our computation is and whether allowing for some new quantum properties we will improve this computational efficiency. How efficient algorithm is can be measured though algorithm complexity.</p>"},{"location":"qip1_2024/ch3a.html#31-algorithm-complexity","title":"3.1. Algorithm Complexity:","text":"<p>How efficient an algorithm is, can be measured in the amount of resources that are needed to solve a problem of size n.</p> <ul> <li>Time complexity deals with the number of computational steps required for solving the problem</li> <li>Space complexity deals with the amount of RAM that is needed to solve the problem</li> </ul> <p>Big O-Notation is very handy in this case - to easily compare two algorithms</p>"},{"location":"qip1_2024/ch3a.html#32-big-o-notation","title":"3.2. Big O notation:","text":"<p>Below I included definitions from P.Kammerlander lecture, for more intuitive picture go directly to the grey box:</p> <ul> <li> <p>\\(f(n)=o(g(n))\\) and say that \\(f\\) grows slower than \\(g\\) if \\(\\forall c&gt;0 \\exists n_0&gt;0\\) such that for all \\(n \\geq n_0: f(n) \\leq c g(n)\\),</p> </li> <li> <p>\\(f(n)=O(g(n))\\) and say that \\(f\\) does not grow significantly faster than \\(g\\) if \\(\\exists c&gt;0\\) and \\(n_0&gt;0\\) such that for all \\(n \\geq n_0: f(n) \\leq c g(n)\\),</p> </li> <li> <p>\\(f(n)=\\Omega(g(n))\\) and say that \\(f\\) does not grow significantly slower than \\(g\\) if \\(\\exists c&gt;0\\) and \\(n_0&gt;0\\) such that for all \\(n \\geq n_0: c g(n) \\leq f(n)\\),</p> </li> <li> <p>\\(f(n)=\\Theta(g(n))\\) and say that \\(f\\) grows as fast as \\(g\\) if both \\(f(n)=O(g(n))\\) and \\(f(n)=\\Omega(g(n))\\).</p> </li> </ul> <p>Formally, define \\(f(n)=O(g(n))\\) provided \\(|f(n)| \\leq c|g(n)|\\) as \\(n \\rightarrow \\infty\\) - \\(|f(n)|\\) is bounded for some constant \ud835\udc50 and all su\ufb00iciently large \ud835\udc5b. - Intuitively, look at the most significant term. - Ignore constant factors as they seldom dominate and are often transitory</p> <p>For example: consider \\(\ud835\udc5b^2\\) instead of \\(3\ud835\udc5b^2 + 34\ud835\udc5b + 433\\): - The cost of a program is usually a complicated formula. Often we should consider only the most significant term. If the cost is \\(\ud835\udc5b^2 + 99\ud835\udc5b + 900\\) for an input of size \\(\ud835\udc5b\\), then the \\(\ud835\udc5b^2\\) term will eventually dominate, even though \\(99\ud835\udc5b\\) is bigger for \\(\ud835\udc5b &lt; 99\\). The constant term 900 may look big, but it is soon dominated by \\(\ud835\udc5b^2\\).</p> <p>i.e. We don't care in this case whether each time-step will take 1minute or 1ms, as for sufficiently large problem it wont matter. If we can make the algorithm more efficient, there will exist a n, for which the slow computer will be solving problem of size n faster.</p> <p>Simple Facts about O Notation:</p> <ul> <li>\\(\\begin{array}{r}O(2 g(n)) \\text { is the same as } O(g(n)) \\\\ O\\left(\\log _{10} n\\right) \\text { is the same as } O(\\ln n) \\\\ O\\left(n^2+50 n+36\\right) \\text { is the same as } O\\left(n^2\\right) \\\\ O\\left(n^2\\right) \\text { is contained in } O\\left(n^3\\right) \\\\ O\\left(2^n\\right) \\text { is contained in } O\\left(3^n\\right) \\\\ O(\\log n) \\text { is contained in } O(\\sqrt{n})\\end{array}\\)</li> </ul> <p>Above is taken from [4]</p>"},{"location":"qip1_2024/ch3a.html#33-complexity-classes","title":"3.3. Complexity Classes:","text":"<p>Decision Problem is a problem that can be formulated as a yes-no question of the input value. </p> <p>Zoo of Complexity Classes</p> <ul> <li>P: (Polynomial) The class of decision problems that can be solved in polynomial time on a classical computer.</li> <li>BPP: (Bounded-Error probabilistic polynomial time) The class of decision problems that can be solved by a probabilistic algorithm in polynomial time on a classical computer with failure probability at most \\(\\frac{1}{3}\\) for all possible inputs.</li> <li>NP: The class of decision problems such that, if the answer is \u2018yes\u2019, there is a proof of this which can be verified in polynomial time on a classical computer.</li> <li>PSPACE: (Space complexity polynomial) The class of decision problems that can be solved in polynomial space on a classical computer.</li> <li>NP-complete: A problem is said to be NP-complete if it is in NP and any other problem in NP can be reduced to it in polynomial time.</li> <li>BQP: The class of decision problems that can be solved in polynomial time on a quantum computer with failure probability at most \\(\\frac{1}{3}\\) for all possible inputs.</li> </ul> <p>Some facts:</p> <ul> <li>\\(\\mathbf{P} \\subset \\mathbf{B P P}\\)</li> <li>\\(\\mathbf{P} \\subset \\mathbf{N P} \\subset \\mathbf{P S P A C E}\\)</li> <li>It is not known whether \\(\\mathbf{B P P} \\subset \\mathbf{N P}\\)</li> <li>Factorisation is not known and not believed to be NP-complete</li> <li>We dont know whether \\(\\mathbf{P} = \\mathbf{B P P}\\), although many believe so</li> </ul>"},{"location":"qip1_2024/ch3a.html#34-quantum-complexity","title":"3.4. Quantum Complexity","text":"<p>For quantum computers we need to somehow define the operation. Quantum computation is simply application of some unitary operator \\(U \\in \\mathcal{U}(2^n)\\) to some initial state of n qubit (usually \\(\\left|0\\right&gt;=\\left|00 \\cdots 0\\right&gt;=\\left|0^n\\right&gt;=\\left|0\\right&gt;^{\\otimes n}\\)), followed by a measurement m of the qubits in the computational basis. Any \\(U \\in \\mathcal{U}(2^n)\\) is composed of an elementary gate from \\(\\mathcal{S}\\).</p> <ul> <li>circuit size is the number of elementary gates</li> <li>circuit width is the number of s-qubits that are involved in those elementary gates</li> <li>circuit depth is the number of actual time steps needed while allowing for parallel execution of elementary gates on di\u2000erent qubits. However, the depth di\u2000ers from the size at most by a constant factor of s and is hence not relevant for the asymptotic runtime.</li> </ul>"},{"location":"qip1_2024/ch3b.html","title":"Chapter 3b: Universal gates, Reversible irreversability, Oracle Functions","text":""},{"location":"qip1_2024/ch3b.html#35-universal-sets-of-gates","title":"3.5. Universal sets of gates","text":"<p>\\(\\mathcal{S}\\) is universal set of gates for quantum computing if for any \\(n \\in \\mathbb{N}\\) an arbitrary unitary operation \\(U \\in \\mathcal{U}(n)\\) can be implemented to arbitrary precision using only elementary gates from \\(\\mathcal{S}\\). Elementary gates are assumed to take \\(O(1)\\) time.</p> <ul> <li>Examples of the universal set of gates:<ul> <li>\\(\\{CNOT\\} \\cup \\mathcal{U}(2)\\)</li> <li>\\(\\{CNOT, H, T\\}\\)</li> <li>\\(\\{\\text{Toffoli}, H\\}\\)</li> </ul> </li> </ul> <p>For any fixed universal set \\(\\mathcal{S}\\), a generic unitary matrix on n qubits requires exponentially many elementary gates n to be implemented - this follows from the fact that an n-qubit unitary is determined by \\(O(4^n)\\) real parameters. Goal of quantum computing is to find efficient quantum circuits which use poly(n) qubits and poly(n) elementary gates to solve a problem on an input size n.</p>"},{"location":"qip1_2024/ch3b.html#36-simulating-classical-circuits-on-a-quantum-machine-leftmathbfb-p-p-subset-mathbfb-q-pright","title":"3.6. Simulating Classical Circuits on a Quantum Machine \\(\\left(\\mathbf{B P P} \\subset \\mathbf{B Q P}\\right)\\)","text":"<p>A classical circuit is a sequence of logical operations that act on a small number of bits (AND, OR, NOT). We claim that quantum computation is at least as powerfull as classical computation \\(\\mathbf{B P P} \\subset \\mathbf{B Q P}\\). However, the difficulty in proving it arise when we try to translate irreversible classical operations, such as AND or OR, to quantum gates.Quantum operations are unitary, hence reversible. This poses a problem:</p> <p>The crucial step in showing that one can simulate any classical circuit with a quantum circuit involves showing that any classical boolean operation (even irreversible) can be represented through reversible operation on larger hilbert space. The key point is that if we operate with unitaries on a larger space, but we only look at the subspace, it will look like the operation is non-unitary, (irreversible).</p> <p>Claim: If \\(f: B_m \\rightarrow B_n\\) is a Boolean function it can be expressed in an equivalent reversible form \\(\\tilde{f}: B_{m+n} \\rightarrow B_{m+n}\\).</p> <p>Remark: The claim by itself is simply logic and has nothing to do with quantum computing.</p> <p>Proof: Consider an binary addition operation \\(\\oplus\\) (adding mod 2). For any \\(f: B_m \\rightarrow B_n\\) define \\(\\tilde{f}:B_{m+n}\\rightarrow B_{m+n}\\), where \\(\\tilde{f}(b, c)=(b, c \\oplus f(b))\\). Such function is reversible, as applying the function twice results in \\((b, c \\oplus f(b) \\oplus f(b)) = (b, c \\oplus 0) = (b, c)\\). If we initialise the second register with \\(c=0...0\\), then \\(\\tilde{f}(b, c) = (b, f(b))\\).</p> <p>Conclusion: Through this we satisfied our requirement to represent an irreversible function \\(f\\) as a reversible function \\(\\tilde{f}\\). By replacing all (now reversible) classical gates with quantum gates, one can obtain quantum circuit that simulates the classical one.</p>"},{"location":"qip1_2024/ch3b.html#37-oracle-for-boolean-function","title":"3.7. Oracle for Boolean function:","text":""},{"location":"qip1_2024/ch3b.html#quantum-oracle","title":"Quantum Oracle","text":"<p>A quantum oracle for any Boolean function \\(f:B_n\\rightarrow B_m\\) will be the quantum gate denoted \\(O_f\\) on \\(n+m\\) qubits defined by its action on basis states as follows. Sometimes we refer to n-qubit register \\(\\left|x\\right&gt;\\) and the m-qubit register \\(\\left|y\\right&gt;\\) as the input and output registers respectively $$ O_f\\left|x\\right&gt;\\left|y\\right&gt;=\\left|x\\right&gt;\\left|y \\oplus f(x)\\right&gt; \\quad \\text { for all } x \\in B_n \\text { and } y \\in B_m $$</p>"},{"location":"qip1_2024/ch3b.html#phase-oracle","title":"Phase Oracle","text":"<p>A phase oracle will be quantum gate denoted \\(U_f\\) on \\(n+m\\) qubits defined by its action on basis states as follows  $$ U_f\\left|x\\right&gt;=(-1)^{f(x)}\\left|x\\right&gt; $$</p> <p>This can be achieved through \\(O_f\\) $$ O_f\\left|x\\right&gt;\\left|-\\right&gt;=O_f \\left|x\\right&gt; \\frac{1}{\\sqrt{2}}(\\left|0\\right&gt;-\\left|1\\right&gt;)=\\frac{1}{\\sqrt{2}}(\\left|x\\right&gt;\\left|f(x)\\right&gt;-\\left|x\\right&gt;\\left|1 \\oplus f(x)\\right&gt;)=(-1)^{f(x)}\\left|x\\right&gt;\\left|-\\right&gt; $$</p>"},{"location":"qip1_2024/ch3b.html#38-query-complexity","title":"3.8. Query Complexity:","text":"<p>Let us for a second come back to the complexity classes. In computation it is quite often tricky to consider all gates that are involved in the circuit. But in the end, quite often, we dont care what is the exact time complexity of the circuit. What we rather care about, is how does the complexity of the classical algorithm compares with the complexity of the quantum algorithm.</p> <p>And for this, we can group the gates into queries - both for classical computation and for quantum computation. For instance, an oracle function \\(O_f\\) is just a collection of gates. We also know that the complexity of the quantum oracle is at least as efficient as the classical oracle.</p> <p>This means that if we find that the quantum algorithm is more efficient in the number of queries than the classical algorithm, then the quantum time complexity is definitely better than the classical one.</p> <p>Query complexity is the number of times we need to apply the oracle to the circuit.</p>"},{"location":"qip1_2024/ch3b.html#39-computation-by-quantum-parallelism","title":"3.9. Computation by quantum parallelism:","text":"<p>Now we can talk about what happens when we apply the oracle to a state in a superposition. This is the heart of what makes quantum computers powerful. Consider we have a state in a superposition of all possible inputs \\(\\left|\\psi\\right&gt; = \\frac{1}{\\sqrt{2^n}}\\sum_x\\left|x\\right&gt;\\left|0\\right&gt;\\). Then if we apply the oracle to this state, we get:</p> \\[ O_f\\left|\\psi\\right&gt; = \\frac{1}{\\sqrt{2^n}}\\sum_x O_f\\left|x\\right&gt;\\left|0\\right&gt; = \\frac{1}{\\sqrt{2^n}}\\sum_x \\left|x\\right&gt;\\left|f(x)\\right&gt; \\] <p>This is what we call the computation by quantum parallelism. Fundamentally this is what differentiates quantum computing from classical computing. In classical computing we cannot have states that are in superposition of different inputs. In quantum computing we can, and this allows us to compute the function in parallel for all possible inputs.</p> <p>Problem however is that we dont have a conclusive result from this, if we don't do anything with the result. Consider we now perform a projective measurement on the first register. Then through measuring \\(\\left|x\\right&gt;\\), we can only learn the value of \\(f(x)\\) for a single \\(x\\). </p> <p>Therefore we need to be somewhat more smart what we do with the superposition. This is what you will learn in the next chapter, where we will show how to use the superposition to solve some problems. This is connected to the idea of using interference to solve problems.</p> <p>This subchapter needs some revision to get the point across</p>"},{"location":"qip1_2024/ch3b.html#notes","title":"Notes:","text":"<ul> <li>Things we havent talk about in detail is the concept of universal sets of quantum gates, and the approximately universal sets of gates.</li> </ul>"},{"location":"qip1_2024/ch4a.html","title":"Chapter 4a: DJ Style Algorithms:","text":""},{"location":"qip1_2024/ch4a.html#41-deutsch-josza-dj-algorithm","title":"4.1. Deutsch-Josza (DJ) algorithm:","text":"<p>Problem: Given a function \\(f : \\{0,1\\}^n \\rightarrow \\{0, 1\\}\\) with a promise that a function is either constant or balanced the goal is to find out whether \\(f\\) is constant or balanced. Balanced means that it outputs 0 half of the time and 1 the other half of the time. Constant means that it always outputs the same thing (either 1 or 0).</p> <p>Remark: We will show that classical algorithm will require exponentially many queries to \\(f\\), namely \\(2^{n-2}\\) on average. Quantum algorithm will be able to determine whether f is constant or balanced in a single query. Notice here, that we are comparing the query complexity of both classical and quantum algorithms, not the time complexity. But as discussed in the previous chapter this fundamentally means that the quantum algorithm time complexity will be more efficient than the classical equivalent.</p>"},{"location":"qip1_2024/ch4a.html#algorithm","title":"Algorithm:","text":"<p>This circuit corresponds to: 1. Applying \\(H^{\\otimes n} U_f H^{\\otimes n}\\left|0\\right&gt;^{\\otimes n}\\). 2. Evaluating the probability of \\(y = 0^n\\), which is equivalent to projecting the state onto \\(\\left|0\\right&gt;^{\\otimes n}\\) and taking the absolute value squared.</p> \\[ \\left|\\left&lt;0\\right|^{\\otimes n}H^{\\otimes n} U_f H^{\\otimes n}\\left|0\\right&gt;^{\\otimes n}\\right|^2 = \\begin{cases}1, &amp; \\text { if } f \\text { is constant } \\\\ 0, &amp; \\text { if } f \\text { is balanced }\\end{cases} \\]"},{"location":"qip1_2024/ch4a.html#why-it-works","title":"Why it works?:","text":"<p>There is an explanation in the </p> <p>Explanation 1:</p> <p>What I want you to understand from this explanation is that if we have some sort of symmetric situation due to the measurement - the problem massively simplifies.</p> <p>Here the trick is to realise that operator can act either to the right or to the left. Acting on the left massively simplifies the problem:</p> \\[ \\left&lt;0\\right|^{\\otimes n}H^{\\otimes n} U_f H^{\\otimes n}\\left|0\\right&gt;^{\\otimes n} = \\left(\\frac{1}{\\sqrt{2^n}} \\sum_{x \\in\\{0,1\\}^n}\\left&lt;x\\right|\\right) U_f \\left(\\frac{1}{\\sqrt{2^n}} \\sum_{x' \\in\\{0,1\\}^n}\\left|x'\\right&gt;\\right) = \\frac{1}{2^n} \\sum_{x \\in\\{0,1\\}^n}\\left&lt;x\\right| U_f \\left|x\\right&gt; = \\begin{cases}\\pm 1, &amp; \\text { if } f \\text { is constant } \\\\ 0, &amp; \\text { if } f \\text { is balanced }\\end{cases} \\] <p>Because we have equal superposition of all x-values, then if \\(U_f\\) is balanced then they will all add up to \\(0\\), and if they are constant, they will add up to \\(\\pm 1\\).</p> <p>Therefore we get:</p> \\[ \\left|\\left&lt;0\\right|^{\\otimes n}H^{\\otimes n} U_f H^{\\otimes n}\\left|0\\right&gt;^{\\otimes n}\\right|^2 = \\begin{cases}1, &amp; \\text { if } f \\text { is constant } \\\\ 0, &amp; \\text { if } f \\text { is balanced }\\end{cases} \\] <p>As promised</p> <p>Explanation 2:</p> <p>Second explanation is more visual approach to the problem. It requires us to think about the problem slightly differently, which initially might seem more complicated, but then it becomes easier and more natural - I think it is very useful in subsequent problems such as Grover's algorithm</p> <p>We can represent each n-qubit computational basis state as a number corresponding to its binary value  - \\(\\left|0\\right&gt;_C = \\left|00...0\\right&gt;=\\left|0\\right&gt;^{\\otimes n}\\),  - \\(\\left|1\\right&gt;_C = \\left|00...01\\right&gt;\\),  - \\(\\left|2\\right&gt;_C = \\left|00...10\\right&gt;\\) - \u22ee - \\(\\left|2^n-1\\right&gt; = \\left|11...1\\right&gt;\\)</p> <p>Each quantum state \\(\\left|x\\right&gt;_C\\) can be represented as a delta function \\(\\delta(x)\\) on the x-axis, where \\(x\\) ranges from 0 to \\(2^n-1\\).</p> <p>Then let's run through the algorithm step by step:</p> <ol> <li>Initially we have the state \\(\\left|0\\right&gt;_C\\)</li> </ol> <p></p> <ol> <li>Then we apply Haddamard on the \\(\\left|0\\right&gt;_C\\) state, which results in the equal superposition of all states in \\(\\left|x\\right&gt;_C\\) basis</li> </ol> <p></p> <ol> <li>Then we apply \\(U_f\\) operator, which effectively flips the phase of half of the \\(\\left|x\\right&gt;_C\\) states if its balanced, otherwise it flips either all or none of them</li> </ol> <p></p> <ol> <li>Finally we project it onto the equal superposition of all \\(\\left|x\\right&gt;_C\\) states</li> </ol> <p></p> <p>The result is that if half of the states are flipped, then when we project it onto the equal superposition of all \\(\\left|x\\right&gt;_C\\) states, we will measure it with probability 0, and if all the states are flipped, then we will measure it with probability 1</p>"},{"location":"qip1_2024/ch4b.html","title":"Chapter 4b: Grover's Style Algorithms:","text":""},{"location":"qip1_2024/ch4b.html#42-grovers-algorithm","title":"4.2. Grover's algorithm:","text":"<p>Grover's paper</p> <p>Problem - Unstructured search: Given an access to a computable function \\(f(x) : \\{0,1\\}^n \\rightarrow \\{0,1\\}\\) we want to find some \\(x\\) such that \\(f(x_0) = 1\\), for a unique 'marked' element \\(x_0\\in\\{1,...,N\\}\\).</p> <p>Grover's algorithm is an algorithm which has a large range of applications and is a beautiful example of how quantum mechanics allows us to speed up many problems. But, in words of Scott Aaronson,  the speed up is rather modest, as it is only quadratic. </p> <p>Consider above problem in the classical setting. On average one would have to query \\(N/2\\) elements to find the marked one, which means that the average time complexity is \\(O(N)\\). In contrast, quantum algorithm will be able to find the marked element in \\(O(\\sqrt{N})\\) time. In the chapter below we will try to see how it is achieved.</p>"},{"location":"qip1_2024/ch4b.html#algorithm","title":"Algorithm:","text":"<p>This circuit corresponds to: 1. Applying \\(\\left(-H^{\\otimes n} U_0 H^{\\otimes n} U_f\\right)^{N_{\\text {optimal }}} H^{\\otimes n} \\left|0\\right&gt;^{\\otimes n}\\) 2. Measuring the resulting state</p>"},{"location":"qip1_2024/ch4b.html#why-it-works","title":"Why it works?:","text":"<p>I would like to present here two geometric explanations why Grover's algorithm works. I would recommend you to think about both of them, as both of them allow you to understand different things about the algorithm. Explanation 2 is the standard one and is probably a way how to think about Grover's algorithm. However I think that when Grover was trying to come up with the algorithm he was thinking about Explanation 1, which then led to Explanation 2. You will see this smooth transition in the explanation (and not so smooth transition in my writing :) ).</p>"},{"location":"qip1_2024/ch4b.html#explanation-1-amplitude-amplification","title":"Explanation 1: Amplitude amplification:","text":"<p>Definitions:</p> <p>Before we start with the explanation, let's re-write the operators in Grover's algorithm in a slightly different way. </p> <ul> <li>Lets define good and bad states as:</li> <li>\\(\\left|g\\right&gt; = \\left|x_0\\right&gt;\\)</li> <li>\\(\\left|b\\right&gt; = \\frac{1}{\\sqrt{N-1}} \\sum_{x\\neq x_0} \\left|x\\right&gt; = \\frac{\\sqrt{N}}{\\sqrt{N-1}}\\left|+\\right&gt; - \\frac{1}{\\sqrt{N-1}} \\left|g\\right&gt;\\)</li> <li>And let's define plus and minus states as:</li> <li>\\(\\left|+\\right&gt; = \\frac{1}{\\sqrt{N}} \\sum_x \\left|x\\right&gt; = H^{\\otimes n} \\left|0\\right&gt;^{\\otimes n} = \\frac{1}{\\sqrt{N}}\\left|g\\right&gt; + \\frac{\\sqrt{N-1}}{\\sqrt{N}}\\left|b\\right&gt;\\)</li> <li>\\(\\left|-\\right&gt; = - \\frac{1}{\\sqrt{N}}\\left|g\\right&gt; + \\frac{\\sqrt{N-1}}{\\sqrt{N}}\\left|b\\right&gt;\\)</li> <li>\\(U_f\\) is just a phase oracle, which flips the phase of the marked element. We can rewrite it as \\(U_f = I - 2 \\left|x_0\\right&gt;\\left&lt;x_0\\right|\\)</li> <li>\\(U_0\\) flips the phase of the \\(\\left|0\\right&gt;^{\\otimes n}\\) state. This means that \\(H^{\\otimes n} U_0 H^{\\otimes n} = H^{\\otimes n} \\left(I - 2 \\left|0\\right&gt;\\left&lt;0\\right|^{\\otimes n}\\right) H^{\\otimes n} = I - 2 \\left|+\\right&gt;\\left&lt;+\\right|\\)</li> </ul> <p>Therefore the circuit can be re-writen as:</p> \\[ \\left(-\\underbrace{\\left(I - 2\\left|+\\right&gt;\\left&lt;+\\right|\\right)}_{H^{\\otimes n} U_0 H^{\\otimes n}}\\underbrace{\\left(I - 2\\left|g\\right&gt;\\left&lt;g\\right|\\right)}_{U_f}\\right)^{N_{\\text {optimal }}} \\left|+\\right&gt; \\] <p>Action of the operator on the plus state:</p> <p>Let's consider then the action of the operator on the plus state \\(\\left|+\\right&gt;\\):</p> \\[ \\begin{aligned} -\\left(I - 2\\left|+\\right&gt;\\left&lt;+\\right|\\right)\\left(I - 2\\left|g\\right&gt;\\left&lt;g\\right|\\right)\\left|+\\right&gt;  &amp;= -\\left(I - 2\\left|+\\right&gt;\\left&lt;+\\right|\\right)\\left(\\left|+\\right&gt; - \\frac{2}{\\sqrt{N}}\\left|g\\right&gt;\\right)  \\\\&amp;= -\\left(\\left|+\\right&gt; - \\frac{2}{\\sqrt{N}}\\left|g\\right&gt; - 2\\left|+\\right&gt; + \\frac{4}{N} \\left|+\\right&gt;\\right)  \\\\&amp;= \\left(\\left(1 - \\frac{4}{N}\\right)\\left|+\\right&gt; + \\frac{2}{\\sqrt{N}}\\left|g\\right&gt;\\right) \\end{aligned} \\] <p>This can be visualised as:</p> <p></p> <p>We can see how each step of the algorithm has a specific purpose.  - \\(U_f\\) is an operation that flips the phase of the target state.  - \\(H^{\\otimes n} U_0 H^{\\otimes n}\\) when applied to \\(\\left|\\psi\\right&gt;\\) performs interference between the wavefunction \\(\\left|\\psi\\right&gt;\\) and \\(-2\\left|+\\right&gt;\\left&lt;+|\\psi\\right&gt;\\), effectively shifting the whole wavefunction down by \\(2\\left|+\\right&gt;\\left&lt;+|\\psi\\right&gt;\\). - Minus sign inverts the amplitude of the wavefunction, and is done only for convenience of thinking about the algorithm, but has no real purpose. </p> <p>Can one infinitely amplify the amplitude?:</p> <p>Seeing how does Grover's step affect the \\(\\left|+\\right&gt;\\) state, we can see that the amplitude of the \\(\\left|+\\right&gt;\\) state is attenuated by a factor of \\(\\left(1 - \\frac{4}{N}\\right)\\). One could then get hopefull and think that we should just apply the Grover's step enough times to get rid of the amplitude completely. This is, however, not the case. One can spot now the problem with Grover's algorithm. The approach only works when the phase of marked element is the same as the phase of non-marked elements:</p> <p></p> <p>Then instead of the amplitude amplification we will get amplitude destruction. Will it ever occur? Yes it will! If we keep going with the algorithm for too long then we will first attenuate the amplitude of the \\(\\left|+\\right&gt;\\) state to zero, but we will not always decrease the amplitude of the bad state. Some amount of the amplitude in the good state \\(\\left|g\\right&gt;\\) will contribute to the shift introducted by \\(H^{\\otimes n} U_0 H^{\\otimes n}\\), introducing shift of \\(2\\left&lt;+|\\psi\\right&gt;\\). This will cause eventual overshoot and we will end up in the phase of the bad state being opposite to the phase of the good state. This will continue in a cycle.</p> <p>Grover's step for a general state \\(\\left|\\psi\\right&gt;\\):</p> <p>Consider now the general case. Starting with the state: \\(\\left|\\psi\\right&gt; = \\alpha\\left|g\\right&gt; + \\beta\\left|b\\right&gt;\\). Lets write it in a vector form: - \\(\\left|\\psi\\right&gt; = \\begin{pmatrix}\\alpha \\\\ \\beta\\end{pmatrix}\\) - \\(U_f = \\begin{pmatrix}-1 &amp; 0 \\\\0 &amp; 1\\end{pmatrix}\\) - \\(U_0 = \\begin{pmatrix}\\cos\\theta &amp; \\sin\\theta \\\\-\\sin\\theta &amp; \\cos\\theta\\end{pmatrix} \\begin{pmatrix}-1 &amp; 0 \\\\0 &amp; 1\\end{pmatrix} \\begin{pmatrix}\\cos\\theta &amp; -\\sin\\theta \\\\\\sin\\theta &amp; \\cos\\theta\\end{pmatrix}\\)</p> <p>, where \\(\\cos\\theta = \\sqrt{\\frac{1}{N}}\\) and \\(\\sin\\theta = \\sqrt{\\frac{N-1}{N}}\\).</p> <p>Then the Grover's step is:</p> \\[ \\begin{aligned} - H^{\\otimes n} U_0 H^{\\otimes n} U_f \\left|\\psi\\right&gt; &amp;=  \\begin{pmatrix} -1 &amp; 0 \\\\ 0 &amp; -1 \\end{pmatrix} \\begin{pmatrix} \\cos\\theta &amp; \\sin\\theta \\\\ -\\sin\\theta &amp; \\cos\\theta \\end{pmatrix} \\begin{pmatrix} 1 &amp; 0 \\\\ 0 &amp; -1 \\end{pmatrix} \\begin{pmatrix} \\cos\\theta &amp; -\\sin\\theta \\\\ \\sin\\theta &amp; \\cos\\theta \\end{pmatrix} \\begin{pmatrix} -1 &amp; 0 \\\\ 0 &amp; 1 \\end{pmatrix} \\begin{pmatrix} \\alpha \\\\ \\beta \\end{pmatrix} \\\\ &amp;= \\begin{pmatrix} \\cos 2\\theta &amp; \\sin 2\\theta \\\\ -\\sin 2\\theta &amp; \\cos 2\\theta \\end{pmatrix} \\begin{pmatrix} \\alpha \\\\ \\beta \\end{pmatrix} \\end{aligned} \\] <p>One can then imidietely see that attenuation of the amplitude of the bad state after Grover's step is \\(\\beta' = \\beta \\cos 2\\theta - \\alpha \\sin 2\\theta\\). This means that the amplitude of the good state and the bad state contribute with an opposite sign to the ampltiude of the bad state after Grover's step.</p> <p>This can be then visualised as rotation of the state \\(\\left|\\psi\\right&gt;\\) around the \\(\\left|+\\right&gt;\\) state by an angle of \\(2\\theta\\) in anti-clockwise direction.</p> <p></p> <p>Why is then the complexity of the algorithm \\(O(\\sqrt{N})\\)? Well to get from a bad state to a good state we need to rotate the state by an angle of \\(\\pi/2\\). This means that we need to rotate \\(\\frac{\\pi/2}{2\\theta}\\) times. As \\(\\theta \\approx \\sin \\theta = \\sqrt{\\frac{1}{N}}\\) we get that we need to rotate \\(\\frac{\\pi/2}{2\\sqrt{\\frac{1}{N}}} = \\frac{\\pi}{4}\\sqrt{N}\\) times. This gives \\(O(\\sqrt{N})\\) iterations.</p>"},{"location":"qip1_2024/ch4b.html#explanation-2-rotations-around-2d-plane","title":"Explanation 2: Rotations around 2D-plane:","text":"<p>not finished</p>"},{"location":"qip1_2024/ch4c.html","title":"Chapter 4c: Quantum Fourier Transform, Period Finding Algorithm:","text":""},{"location":"qip1_2024/ch4c.html#43-discrete-fourier-transform-and-quantum-fourier-transform","title":"4.3. Discrete Fourier Transform and Quantum Fourier Transform:","text":"<p>Quantum Fourier Transform (QFT) in dimension N: defined on the computational basis \\(\\{\\left|x\\right&gt; \\}^{N-1}_{x=0}\\) as the map:</p> \\[ \\mathcal{Q}_N\\left|x\\right&gt; := \\frac{1}{\\sqrt{N}} \\sum_{y=0}^{N-1} \\left( e^{2\\pi i /N } \\right)^{xy} \\left|y\\right&gt; \\] <p>, where \\(xy\\) is a product of two integers</p> <p>This is rather straighforward definition, and it is not so different from the classical Discrete Fourier Transform. Few examples of the QFT matrices for different dimensions are:</p> \\[ Q_2=\\frac{1}{\\sqrt{2}}\\left(\\begin{array}{cc} 1 &amp; 1 \\\\ 1 &amp; -1 \\end{array}\\right), \\quad Q_3=\\frac{1}{\\sqrt{3}}\\left(\\begin{array}{ccc} 1 &amp; 1 &amp; 1 \\\\ 1 &amp; e^{2 \\pi i / 3} &amp; e^{-2 \\pi i / 3} \\\\ 1 &amp; e^{-2 \\pi i / 3} &amp; e^{2 \\pi i / 3} \\end{array}\\right), \\quad Q_4=\\frac{1}{2}\\left(\\begin{array}{cccc} 1 &amp; 1 &amp; 1 &amp; 1 \\\\ 1 &amp; i &amp; -1 &amp; -i \\\\ 1 &amp; -1 &amp; 1 &amp; -1 \\\\ 1 &amp; -i &amp; -1 &amp; i \\end{array}\\right) \\] <p>Let's focus on the matrix \\(\\mathcal{Q}_4\\), and try to understand how it transforms a vector \\(\\left|x\\right&gt;\\). To do this we should consider first the matrix multiplication. When one multiplies the matrix \\(\\mathcal{Q}_4\\) with a vector \\(x\\), \\(\\left(y = \\mathcal{Q}_4 x\\right)\\), then for each element of \\(y\\), one performs a dot product of \\(x\\) with the i-th row of the matrix. As each consecutive row of the matrix is a vector that rotates in complex space with some angular frequency, the dot product effectively picks up, the component of \\(x\\) with this given angular frequency i.e. performs a Fourier Transform.</p> <p></p> <p>We can see the pattern of this matrix - first row is a vector that roates with angular frequency of \\(0 \\frac{2\\pi}{4}\\), second row with angular frequency of \\(1 \\frac{2\\pi}{4}\\), third row with angular frequency of \\(2\\frac{2\\pi}{4}\\) and the last row with angular frequency of \\(3\\frac{2\\pi}{4}\\). </p> <p>More generally, the QFT can be written as a following matrix:</p> \\[ \\mathcal{Q}_N=\\frac{1}{\\sqrt{N}}\\left(\\begin{array}{cccccc} 1 &amp; 1 &amp; 1 &amp; 1 &amp; \\cdots &amp; 1 \\\\ 1 &amp; \\omega &amp; \\omega^2 &amp; \\omega^3 &amp; \\cdots &amp; \\omega^{N-1} \\\\ 1 &amp; \\omega^2 &amp; \\omega^4 &amp; \\omega^6 &amp; \\cdots &amp; \\omega^{2(N-1)} \\\\ 1 &amp; \\omega^3 &amp; \\omega^6 &amp; \\omega^9 &amp; \\cdots &amp; \\omega^{3(N-1)} \\\\ \\vdots &amp; \\vdots &amp; \\vdots &amp; \\vdots &amp; &amp; \\vdots \\\\ 1 &amp; \\omega^{N-1} &amp; \\omega^{2(N-1)} &amp; \\omega^{3(N-1)} &amp; \\cdots &amp; \\omega^{(N-1)(N-1)} \\end{array}\\right) \\] <p>, where \\(\\omega = e^{2\\pi i / N}\\)</p> <p>For a general \\(\\mathcal{Q}_N\\) the i-th row is a vector that rotates with angular frequency of \\(i \\frac{2\\pi}{N}\\). When multiplied with the vector the i-th element of the resulting vector is a dot product of \\(x\\) with the i-th row of the matrix, hence picking up the component of \\(x\\) with the angular frequency of \\(i \\frac{2\\pi}{N}\\).</p>"},{"location":"qip1_2024/ch4c.html#44-efficient-implementation-of-qft","title":"4.4. Efficient Implementation of QFT:","text":"<p>Classically Discrete Fourier Transform can be implemented on a classical computer in time \\(O(N\\log N)\\) using Fast Fourier Transform (FFT) algorithm. We want to show in the following that we can implement QFT applied to n qubits in time \\(O(n^2)\\). This means that the QFT can be implemented in \\(O(\\log^2N)\\) time complexity on a quantum computer.</p> <p>Let's start with the definition of QFT:</p> \\[ \\mathcal{Q}_N\\left|x\\right&gt; := \\frac{1}{\\sqrt{N}} \\sum_{y=0}^{N-1} \\left( e^{2\\pi i /N } \\right)^{xy} \\left|y\\right&gt; \\] <p>Representing \\(x\\), and \\(y\\) by n-bit strings:</p> \\[ x = x_{n-1}2^{n-1} + x_{n-2}2^{n-2} + ... + x_0 \\] \\[ y = y_{n-1}2^{n-1} + y_{n-2}2^{n-2} + ... + y_0 \\] <p>Now:</p> \\[ xy = \\sum_{j=0}^{n-1}x\\left(y_j 2^j\\right) \\] <p>and so:</p> \\[ \\begin{aligned} \\sum_y e^{2 \\pi i \\frac{x y}{2^n}}\\left|y\\right&gt; &amp;=\\sum_{y_0, \\ldots, y_{n-1} \\in \\{0,1\\}} e^{2 \\pi i \\frac{x y}{2^n}}\\left|y_{n-1}\\right&gt;\\left|y_{n-2}\\right&gt; \\ldots\\left|y_0\\right&gt; \\\\ &amp;=  \\left(\\sum_{y_0 \\in \\{0,1\\}} e^{2 \\pi i \\frac{x\\left(y_0 2^0\\right)}{2^n}}\\left|y_0\\right&gt; \\right)\\ldots\\left(\\sum_{y_{n-1} \\in \\{0,1\\}} e^{2 \\pi i \\frac{x\\left(y_{n-1} 2^{n-1}\\right)}{2^n}}\\left|y_{n-1}\\right&gt; \\right) \\\\ &amp; = \\left( \\left|0\\right&gt;_0 +  e^{2 \\pi i \\frac{x\\left(2^0\\right)}{2^n}}\\left|1\\right&gt;_0 \\right)\\ldots\\left( \\left|0\\right&gt;_{n-1} +  e^{2 \\pi i \\frac{x\\left(2^{n-1}\\right)}{2^n}}\\left|1\\right&gt;_{n-1} \\right) \\\\ &amp; = \\left( \\left|0\\right&gt;_0 +  e^{2 \\pi i \\frac{\\left(\\sum_{x_i} x_i 2^i\\right)\\left(2^0\\right)}{2^n}}\\left|1\\right&gt;_0 \\right)\\ldots\\left( \\left|0\\right&gt;_{n-1} +  e^{2 \\pi i \\frac{\\left(\\sum_{x_i} x_i 2^i\\right)\\left(2^{n-1}\\right)}{2^n}}\\left|1\\right&gt;_{n-1} \\right)  \\end{aligned} \\] <p>This would quite easy to implement on a quantum computer. We just need to apply a Haddamard gate, and then rotate phase of j'th qubit controlled on each i'th qubit by \\(\\frac{2\\pi 2^j 2^i}{2^n} = \\frac{\\pi}{2^{n-i-j-1}}\\). We can achieve this with a controlled \\(R_d\\) gate which rotates a qubit in a following way:</p> \\[ R_d:=\\left(\\begin{array}{cc} 1 &amp; 0 \\\\ 0 &amp; e^{\\pi i / 2^d} \\end{array}\\right) \\] <p>The circuit would look like this.</p> <p></p> <p>But you might notice that for some of the controlled \\(R_d\\) gates, the \\(d &lt; 0\\). For such gates the rotation is by a integer multiple of \\(2\\pi\\), and so effectively such gates do not contribute to the final result. We can skip applying such gates.</p> <p></p> <p>Secondly what we can notice that applying a \\(R_0\\) gate to \\(H \\left|0\\right&gt;_i\\) controlled on a j'th qubit is equivalent to applying a \\(H\\) gate directly to the j'th qubit.</p> <p>i.e. </p> <p></p> <p>This means that we can rewrite this circuit in a much simpler form, where we reuse the original qubits.</p> <p></p> <p>As you can see the order of the outputs is reversed relative to the input. The original order can be restored by using n/2 SWAP operations.</p> <p>Query complexity for this circuit is \\(\\left(n\\right)\\left(n-1\\right)\\ldots\\left(1\\right) = O(n^2)\\)</p>"},{"location":"qip1_2024/ch4c.html#45-period-finding-algorithm","title":"4.5 Period Finding Algorithm:","text":"<p>Problem and promises: Suppose we are given a black box function \\(f:\\left\\{0,1\\right\\}^n \\rightarrow \\left\\{0,1\\right\\}^m\\) with a promise that:  - \\(f\\) is periodic, with a period \\(r\\) such that \\(f(x+r)=f(x)\\) for all \\(x\\) - \\(f\\) is a one-to-one function in each period i.e. \\(f(x_1) \\neq f(x_2)\\)  for all \\(0 \\leq x_1, x_2 &lt; r\\).</p> <p>The goal is to find the period \\(r\\) of the function \\(f\\).</p> <p>Algorithm:</p> <p></p> <p>So the algorithm runs in a following way. We first start with \\(n+m\\) qubits. Then we prepare a superposition of all basis states \\(\\{\\left|x\\right&gt; \\}\\) on the \\(n\\) qubits. We then apply a bit oracle \\(O_f\\), which entangles n qubits with m qubits - effectively grouping the \\(\\{ x_0, x_0+r, x_0+2r, ... \\}\\) together and associating them with some value in the m-register \\(f(x_0)\\). Upon measuring the m-register we get a value of \\(f(x_0)\\), which collapses the n-register into a superposition of states \\(\\{ \\left|x_0\\right&gt;, \\left|x_0+r\\right&gt;, \\left|x_0+2r\\right&gt;, ... \\}\\).</p> <p>Now you might think - this is it! If I measure this n-register enough times, then I will definitely find the value of \\(r\\). You will realise upon measuring the m-register for the second time that the n-register collapses into a superposition of \\(\\{ \\left|x_0'\\right&gt;, \\left|x_0'+r\\right&gt;, \\left|x_0'+2r\\right&gt;, ... \\}\\) and so on. Damn! We got different numbers! To make sure that we are insensitive to the value of \\(x_0\\) we need to apply QFT to the n-register. After applying QFT we always end up in the superpiosition of the periods which are multiples of \\(r\\) and invariant to the value of \\(f(x_0)\\) being measured during the first measurement.</p> <p>Step by step state evolution:</p> <ol> <li>Apply the \\(H^{\\otimes n}\\) gate to the n-register: $\\left|0\\right&gt;_m\\left|+\\right&gt;_n = H_n\\left|0\\right&gt;_m\\left|0\\right&gt;_n $</li> <li>Apply the bit oracle \\(O_f\\): \\(\\left|0\\right&gt;_m\\left|+\\right&gt;_n \\rightarrow \\sum_{x_0=0}^{r-1} \\left|f(x_0)\\right&gt;_m\\left(\\left|x_0\\right&gt; + \\left|x_0+r\\right&gt; + \\left|x_0+2r\\right&gt; + ... \\right)_n\\)</li> <li>Measure the m-register getting a result \\(f(x_0)\\) and collapsing the n-register into a superposition of states \\(\\left|period\\right&gt; =  \\left|x_0\\right&gt;+ \\left|x_0+r\\right&gt; + \\left|x_0+2r\\right&gt; + ...\\)</li> <li>Apply the QFT to the n-register: \\(\\mathcal{Q}_{2^n}\\left|per\\right&gt; = \\sum_{k=0}^{r-1} \\left|kN/r\\right&gt;\\)</li> <li>Measure the n-register and get the value of \\(r\\)</li> </ol> <p></p> <p>Post Processing: So now the measurement of the n-register will give us values of \\(c = kN/r\\). Is this enough to find the value of \\(r\\)? With help comes number theory.</p> <p>There are two options:</p> <ol> <li>k and r are co-prime to each other -  it means that \\(\\frac{k}{r}\\) is the irreducible fraction, which means that by finding irreducible fraction of \\(\\frac{c}{N}\\) gives us directly the values of \\(k\\) and \\(r\\). Simple!</li> <li>k and r aren't co-prime to each other - it means that \\(k\\), and \\(r\\) share a common factor, and so the irreducible fraction of \\(\\frac{c}{N}\\) will give us some \\(\\frac{k/m}{r/m}\\).</li> </ol> <p>This means that each time we can simply test, whether \\(f(x_0)=f(x_0+r)\\) and if not, discard the result and try again.</p> <p>Theorem 1:(Coprimality theorem) The number of integers less than r that are co-prime to r grows as \\(O(\\frac{r}{\\log \\log r})\\) with increasing r. Hence if \\(k &lt; r\\) is chosen at random, then the probability that \\(k\\) is co-prime to \\(r\\) is \\(O(\\frac{1}{\\log \\log r})\\).</p> <p>As each measurement is independent then repeating the whole process \\(O(\\log \\log r)&lt;O(\\log \\log N)\\) times gives us the result with constant probability.</p>"},{"location":"qip1_2024/ch4c.html#46-phase-estimation-algorithm","title":"4.6 Phase Estimation Algorithm:","text":""},{"location":"qip1_2024/ch5.html","title":"Chapter 5: Shor's Algorithm:","text":"<p>Shor's algorithm is probably one of the most famous quantum algorithms, and the reason for interest of various militaries around the world in quantum computing. It is connected to RSA encryption, which basically is the foundation of the internet privacy as we know it. Breaking it, would have huge implications on everything we do. Breaking RSA can be reduced to factoring large numbers.</p>"},{"location":"qip1_2024/ch5.html#51-introduction","title":"5.1 Introduction:","text":"<p>Problem: Given an integer \\(N\\), output a factor \\(1 &lt; K &lt; N\\). with any chosen constant level of probability \\((1-\\epsilon)\\), and the algorithm will run in polynomial time \\(O(n^3)\\).</p>"},{"location":"qip1_2024/ch5.html#52-factoring-as-a-periodicity-problem","title":"5.2. Factoring as a periodicity problem:","text":"<p>The approach we will take is to transform the factoring problem into a periodicity problem. And then we will show that we can solve the periodicity problem efficiently with a quantum algorithm.</p> <p>Theorem: (Euler's theorem) If \\(a\\) and \\(N\\) are coprime, then there is a least power \\(1&lt;r&lt;N\\) such that \\(a^r\\equiv 1 \\pmod{N}\\). This \\(r\\) is called the order of \\(a\\) mod \\(N\\).</p> <p>Using Euler's theorem we can show that \\(f(k) = a^k \\pmod{N}\\) is periodic with period \\(r\\). This is because </p> \\[ f(k + r) = a^{k+r} \\pmod{N} = a^k a^r \\pmod{N} = a^k \\pmod{N} = f(k) \\] <p>Suppose that we find the period \\(r\\) of \\(f(k)\\) and this period \\(r\\) is even. Then we can re-write our original statement as:</p> \\[ a^r - 1 = (a^{r/2} - 1)(a^{r/2} + 1) \\equiv 0 \\pmod{N} \\] <p>\\(N\\) does not divide \\(a^{r/2} - 1\\), therefore \\(N\\) must either (a) divide \\(a^{r/2} + 1\\) or (b) partly divide into \\(a^{r/2} + 1\\) and partly into \\(a^{r/2} - 1\\). If it partly divides into \\(a^{r/2} + 1\\), we can use classically efficient euclids algorithm \\(gcd(a^{r/2} + 1, N)\\) to find a non-trivial factor of \\(N\\). Therefore, if we pick \\(a\\) at random then, assuming \\(r\\) is even and \\(a^{r/2}+1\\) is not divisible by \\(N\\), we can classically find a non-trivial factor of \\(N\\).</p> <p>Theorem: Suppose \\(N\\) is odd and not a power of a prime. If \\(a&lt;N\\) is chosen uniformly at random with \\(gcd(a,N)=1\\) then \\(Prob(\\text{r is even and } a^{r/2}\\not\\equiv -1 \\pmod{N})\\) is at least \\(1/2\\).</p>"},{"location":"qip1_2024/ch5.html#53-algorithm","title":"5.3. Algorithm:","text":"<ol> <li>Is N even? If so, output 2 and stop</li> <li>Choose \\(a\\) at random from 1 to \\(N-1\\) and compute \\(gcd(a,N)\\). If \\(gcd(a,N) \\neq 1\\) then we are done.</li> <li>If s=1 find the period r of the sequence \\(a^k \\pmod{N}\\). If r is odd or \\(a^{r/2} \\equiv -1 \\pmod{N}\\), then go back to step 2.</li> <li>Otherwise \\(gcd(a^{r/2} + 1, N)\\) and \\(gcd(a^{r/2} - 1, N)\\) are non-trivial factors of \\(N\\).</li> </ol> <p>As you can see already here, everything about solving this problem boils down to the efficient implementation of fidning the period of r of \\(a^x \\pmod{N}\\). Following section will show how can we do it efficiently with a quantum algorithm.</p>"},{"location":"qip1_2024/ch5.html#54-efficient-implementation-of-period-finding-of-ak-pmodn","title":"5.4. Efficient implementation of period finding of \\(a^k \\pmod{N}\\):","text":"<p>In the end what we need to do is to find the period \\(r\\) of the sequence \\(a^k \\pmod{N}\\). The circuit should be the same as the one for period finding algorithm. What we want to show is that each block of this circuit can be implemented efficiently.</p> <p></p> <p>We have already shown that the QFT can be implemented efficiently in terms of query complexity. If we want to know whether the algorithm can be efficient in terms of time-complexity, we need to consider how we can implement the bit oracle \\(O_f\\) efficiently. Efficient oracle \\(O_f\\) is equivalent to efficient implementation of \\(f(k) = a^k \\pmod{N}\\).</p>"},{"location":"qip1_2024/ch5.html#541-efficient-implementation-of-fx-ax-pmodn","title":"5.4.1. Efficient implementation of \\(f(x) = a^x \\pmod{N}\\):","text":"<p>Using binary representation of \\(x\\) we can write:</p> \\[ x=x_{m-1} \\cdot 2^{m-1}+x_{m-2} \\cdot 2^{m-2}+\\ldots+x_0 \\] <p>therefore</p> \\[ a^x\\pmod{N}=\\left(a^{2^{m-1}}\\right)^{x_{m-1}}\\left(a^{2^{m-2}}\\right)^{x_{m-2}} \\ldots(a)^{x_0}\\pmod{N} \\] <p>, and as each \\(x_i\\) is either 0 or 1, therefore we will be either multiplying or not the result of the previous step by \\(a^{2^i}\\). We can implement it as a multiplication by \\(a^{2^i}\\) controlled on the qubit \\(x_i\\). This is equivalent to the following circuit:</p> <p></p> <p>Therefore if we prepare the first register in the state \\(\\sum_{x=0}^{N-1} \\left|x\\right&gt;\\), and the second register in the state \\(\\left|1\\right&gt;\\), then we will end up with the state after applicaion for the circuit above:</p> \\[ \\sum_{x=0}^{N-1} \\left|x\\right&gt;\\left|1\\right&gt; \\rightarrow \\sum_{x=0}^{N-1} \\left|x\\right&gt; \\left|a^x \\bmod{N}\\right&gt; \\] <p>Comment:</p> <p>Maybe an interesting thing to note is that we between two steps of the algorithm we can re-use the previous multiplication to compute the next power of \\(a\\). This is because we can write it recursively as, and so it only needs to be squared:</p> \\[ a^{2^j} \\pmod{N} = \\left(a^{2^{j-1}}\\right)^2 \\pmod{N} \\] <p>This somewhat means that we can reuse the result of the previous computation to compute the next power of \\(a\\). This means that </p>"},{"location":"qip1_2024/ch6.html","title":"Chapter 6: Density Matrix Formalism:","text":""},{"location":"qip1_2024/ch6.html#60-extending-the-closed-quantum-system-formalism-to-consider-the-open-quantum-systems","title":"6.0. Extending the closed quantum system formalism to consider the open quantum systems:","text":"<p>The necessity for density matrix formalism arises from two reasons. Firstly, sometimes we are not quite sure about the state of the system. When this happens we dont want to be constrained to the pure states only. We need to describe such system with a probability distribution over the states. Secondly even if we are sure about the state of the system, then the unitary evolution of the larger system can be seen as non-unitary evolution on its subsystem. We would like to describe such evolution as well, as quite often we are not interested in the whole system, but only in some part of it. I will only briefly touch upon the formalism of the density matrices.</p>"},{"location":"qip1_2024/ch6.html#61-density-matrix","title":"6.1. Density Matrix:","text":"<p>If you are not familiar with the density matrices - have a look at Philip Kammelander QIP notes. Here I will only provide a brief set of definitions. </p> <ul> <li>Density operator (also called density matrix), \\(\\rho\\), is defined as \\(\\rho = \\sum_i p_i \\left|\\psi_i\\right&gt;\\left&lt;\\psi_i\\right|\\)</li> <li>Set of quantum states \\(\\mathcal{S}\\left(\\mathcal{H}\\right)\\) is a set of density operators \\(\\mathcal{S}(\\mathcal{H}):=\\{\\rho \\in \\operatorname{LinMap}(\\mathcal{H}) \\mid \\rho \\geq 0 \\text { Hermitian, } \\operatorname{tr}(\\rho)=1\\}\\)</li> <li>\\(\\rho \\in \\mathcal{S}\\left(\\mathcal{H}\\right)\\) is called a pure if there exists \\(\\left|\\phi\\right&gt;\\in\\mathcal{H}\\) such that \\(\\rho = \\left|\\phi\\right&gt;\\left&lt;\\phi\\right|\\) has rank 1, which is equivalent to \\(\\text{tr}\\left(\\rho^2\\right)=1\\).</li> <li>Unitary evolution of a density operator is given by \\(\\rho \\mapsto U \\rho U^{\\dagger}=U\\left(\\sum_i p_i\\left|\\psi_i \\right&gt; \\left&lt;\\psi_i\\right|\\right) U^{\\dagger}=\\sum_i p_i U\\left|\\psi_i\\right&gt;\\left&lt;\\psi_i\\right| U^{\\dagger}\\)</li> <li>Projective measurement with outcomes labelled \\(\\{x\\}_x\\) is associated with set of projectors \\(\\{\\Pi_x\\}_x\\) satisfying \\(\\sum_x \\Pi_x = \\mathbb{I}\\). The probability of outcome \\(x\\) is given by \\(p(x) = \\text{tr}\\left(\\Pi_x \\rho\\right)\\) and the post-measurement state is given by \\(\\frac{\\Pi_x \\rho \\Pi_x}{\\text{tr}\\left(\\Pi_x \\rho\\right)}\\). This is nice as now we can describe the final state of the system after the measurement that was forgotten: </li> </ul> \\[ \\rho^{\\prime}=\\sum_x \\operatorname{Pr}[x \\mid \\rho] \\rho_x^{\\prime}=\\sum_x \\operatorname{tr}\\left(\\Pi_x \\rho\\right) \\frac{\\Pi_x \\rho \\Pi_x}{\\operatorname{tr}\\left(\\Pi_x \\rho\\right)}=\\sum_x \\Pi_x \\rho \\Pi_x \\]"},{"location":"qip1_2024/ch6.html#62-partial-trace-system-rightarrow-subsystem","title":"6.2. Partial Trace: system \\(\\rightarrow\\) subsystem:","text":"<p>When we have access only to the subsystem \\(A\\) of the composite system \\(AB\\), the appropriate density operator is: </p> \\[ \\rho^A = \\text{tr}_B\\left(\\rho^{AB}\\right) \\] <p>If a global state is pure, then the reduced state is not necessarily pure. i.e. consider \\(\\rho_{A B}=\\left|\\psi^{00} \\right&gt;\\left&lt; \\psi^{00}\\right|_{A B}\\). Taking partial trace over subsystem \\(B\\) we get \\(\\rho^A = \\mathbb{I}_A/2\\), which is maximally mixed.</p>"},{"location":"qip1_2024/ch6.html#63-purification-subsystem-rightarrow-system","title":"6.3. Purification: subsystem \\(\\rightarrow\\) system:","text":"<p>Consider somewhat opposite task of finding a global state \\(\\left|\\psi^{AB}\\right&gt;\\) given a reduced state \\(\\rho^A\\), s.t. \\(\\text{tr}_B\\left(\\left|\\psi^{AB}\\right&gt;\\left&lt;\\psi^{AB}\\right|\\right) = \\rho^A\\). \\(\\left|\\psi^{AB}\\right&gt;\\) is called purification of \\(\\rho^A\\). This means that any mixed state can be seen as pure state on a larger system, which is nice result. This means that things don't stop being quantum, but simply they start to entangle with all the enviornment. </p>"},{"location":"qip1_2024/ch6.html#64-quantum-operations-evolution-and-allowed-operations-on-the-open-quantum-system","title":"6.4. Quantum Operations: Evolution and allowed operations on the open quantum system:","text":"<p>Given that we defined a more general formalism for the open quantum systems, we should also ponder over the allowed operations on such systems. For closed quantum system living in \\(\\mathcal{H}\\) the allowed operations was set of unitaries \\(\\mathcal{U}\\left(\\mathcal{H}\\right)\\) that maps the set of pure quantum states to itself. By opening up the system we extended the quantum states from hilbert space to the set of density operators \\(\\mathcal{H} \\rightarrow \\mathcal{S}\\left(\\mathcal{H}\\right)\\). We are interested in the most general maps that map this set to itself. Given that we already used up the name 'operator' to describe the operations on the closed system, we will call the operations on the open system 'superoperators', \\(\\mathcal{E}\\). \\(\\mathcal{E}\\) is expected to be:</p> <ul> <li>linear: \\(\\mathcal{E}(p \\rho+q \\sigma)=p \\mathcal{E}(\\rho)+q \\mathcal{E}(\\sigma)\\)</li> <li>trace preserving: \\(\\text{tr}\\left(\\mathcal{E}(\\rho)\\right) = \\text{tr}(\\rho)\\)</li> <li>positive: \\(\\mathcal{E}(\\rho) \\geq 0\\) for all \\(\\rho \\geq 0\\) - this means that the eigenvalues of \\(\\mathcal{E}(\\rho)\\) are non-negative.</li> <li>completely positive: We also would like for \\(\\mathcal{E}_A \\otimes \\mathcal{I}_B\\left(\\rho_{A B}\\right) \\geq 0\\) for all \\(\\rho_{A B} \\geq 0\\).</li> </ul> <p>To know that an superoperator is valid we somehow need to understand the overall global system.</p>"},{"location":"qip1_2024/ch6.html#65-the-stinespring-dilation-theorem-purification-of-superoperators","title":"6.5. The Stinespring dilation theorem: Purification of superoperators:","text":"<p>For any completely positive trace preserving(cptp) map there exists a hilber space \\(\\mathcal{H}_B\\) and a pure state \\(\\left|\\phi_N\\right&gt; \\in \\mathcal{H}_B\\) together with a unitary \\(\\mathcal{U}_{AB}\\) s.t. </p> \\[ \\mathcal{E}\\left(\\rho^A\\right) = \\text{tr}_B\\left(\\mathcal{U}_{AB}\\left(\\rho^A \\otimes \\left|\\phi\\right&gt;\\left&lt;\\phi\\right|\\right)\\mathcal{U}_{AB}^{\\dagger}\\right) \\] <p>for all \\(\\rho^A \\in \\mathcal{S}\\left(\\mathcal{H}^A\\right)\\).</p>"},{"location":"qip1_2024/ch6.html#66-operator-sum-representation","title":"6.6. Operator-sum representation:","text":"\\[ \\mathcal{E}\\left(\\rho^A\\right) = \\text{tr}_B\\left(\\mathcal{U}_{AB}\\left(\\rho^A \\otimes \\left|\\phi\\right&gt;\\left&lt;\\phi\\right|\\right)\\mathcal{U}_{AB}^{\\dagger}\\right) \\] <p>Then if we consider orthonormal basis of \\(\\mathcal{H}_B\\) to be \\(\\{ \\left|\\phi_i\\right&gt;\\}_i^{dim \\mathcal{H}_B}\\) and we rotate the basis in a way that the purification is \\(\\left|\\phi\\right&gt; = \\left|\\phi_1\\right&gt;\\) we get:</p> \\[ \\mathcal{E}\\left(\\rho^A\\right) = \\sum_i \\mathbb{I}_A \\otimes \\left&lt;\\phi_i\\right|_B \\left(\\mathcal{U}_{AB}\\left(\\rho^A \\otimes \\left|\\phi_1\\right&gt;\\left&lt;\\phi_1\\right|\\right)\\mathcal{U}_{AB}^{\\dagger}\\right) \\mathbb{I}_A \\otimes \\left|\\phi_i\\right&gt;_B = \\sum_i \\left( \\left&lt;\\phi_i\\right|\\mathcal{U}_{AB} \\left|\\phi_1\\right&gt; \\right)\\rho^A \\left(\\left&lt;\\phi_1\\right|\\mathcal{U}_{AB}^{\\dagger}\\left|\\phi_i\\right&gt;\\right) \\] <p>Defining Krauss Operator: \\(E_k = \\left&lt;\\phi_k\\right|\\mathcal{U}_{AB} \\left|\\phi_1\\right&gt;\\) we can write any quantum operation as</p> \\[ \\mathcal{E}\\left(\\rho^A\\right) = \\sum_k E_k \\rho^A E_k^{\\dagger} \\] <p>Notice that \\(\\sum_k E_k^{\\dagger} E_k = \\mathbb{I}\\).</p>"},{"location":"qip1_2024/ch7.html","title":"Chapter 7: Quantum Error Correction:","text":"<p>At this moment we are far from reliable quantum hardware. Any quantum state that we engineer is very fragile if left alone, and even more fragile when we perform any operations on it. The fragility of things is not so distant to our understanding and we can easily comprehend it. If we deal with something fragile, we better should work with a few copies of it(in case one of them breakes). This somehow points to using a redundancy. </p> <p>For quantum world this is even more important, as we store information in the superposition of quantum states. This means that any disturbance to any qubit hurts us even more. This is because it equally affects all the superpositioned states. And if we use some sort of interference for our algorithms we are screwed, because it will be even more affected. </p> <p>Therefore we need to understand both the nature of errors, and think about the strategies to protect our quantum information from them. As mentioned above already a strategy of creating a redundancy could be helpful. In this chapter we will explore those redundancies. It is important to note that somewhat in quantum world we need to be careful with the measurements on the redundant systems, as they might collapse the superposition. So we need to take a special care of that and perform only the measurements that can tell us about the errors, but simultaneously leave the logical information unchanged. </p> <p>In this write-up I want first to introduce the intuition behind error correction and only then introduce the mathematical formalism.</p>"},{"location":"qip1_2024/ch7.html#70-redundancy-for-qubits","title":"7.0. Redundancy for qubits:","text":"<p>Let's first consider what does it mean that our qubit is encoded in a redundant space. Consider a space with 4 distinct states. If we want to encode a binary information, then we have too many states than we need. But let's consider the following situation, which is illustrated on the diagram below. We have 4-distinct states and some errors that move us from one state to another. This errors can be arbitrary, but in our case we consider that they only can follow the grey lines.</p> <p></p> <p>On the diagram above you can see 4 black dots, each corresponding to a distinct state. Those dots are connected to each other by grey lines, which stand for the errors that can act on our system. This means that if we did encode the information in the 0(blue) and 3(red) states, then a single error would not be able to change the information from blue to red. It would only move us either to a state 1 or 2. In fact we could even find out where did this error come from, which means that we haven't lost any information due to this error. We could find out which error occured simply by assuming the state must have been in the blue or red state, and now by measuring whether it is in 1, or 2 we can tell which error occured. However, this would be bad, as this would tell us also the logical information, and collapse the superposition. </p> <p>Instead consider that the error \\(E_3 = E_1\\). In this situation performing a measurement to determine whether we are in a subspace span by states {0, 3} or {1, 2} would tell us whether the error \\(E_3 = E_1\\) occured without revealing any logical information. This is helpful as then we can simply perform the operation that reverses the error \\(E_3 = E_1\\) to bring us back to the original state. If we keep doing it repeatedly, we can contineously allow the system to stay in the blue and red states that carry the information. The aspect of being able to measure whether the error happened without learning anything about the logical information will be discussed later.</p>"},{"location":"qip1_2024/ch7.html#701-knill-laflamme-condition-constraints-the-separation","title":"7.0.1. Knill-Laflamme condition constraints the separation:","text":"<p>Seeing the space of states and how the errors act on it allow us to understand whether we will be able to correct the errors or not. Consider following example:</p> <p></p> <p>In this example the error \\(E_1\\) moves the state from 0 to 1, and the error \\(E_2\\) moves the state from 2 to 1. In this case if error occured, we cannot tell whether it was \\(E_1\\) or \\(E_2\\) that happened. This means that we cannot correct the error.</p> <p>This example can be more formally stated as the Knill-Laflamme condition. Which states that for the errors to be distinguishable, the following condition should be met:</p> \\[ { }_L\\left&lt; j\\right| E_b^{\\dagger} E_a\\left|i\\right&gt;_L= \\delta_{ab}\\delta_{ij} \\] <p>If this condition is met, it means we can distinguish between the errors, and so we are able to correct them. The Knill-Laflamme condition is a necessary and sufficient condition for the errors to be corrected.</p> <p>What it means as well is that if we prepared any state in the logical space of \\(\\left|\\psi\\right&gt;_L = \\alpha\\left|0\\right&gt;_L + \\beta\\left|1\\right&gt;_L\\), then the error followed by the error measurement and correction should not affect both \\(\\alpha\\) and \\(\\beta\\). If Knill-Laflamme condition isn't met, then we can see how alpha and beta will be mixed together.</p> <p>Whils't thinking diagrametically about both cases, we can see that the Knill-Laflamme condition is met in the first case and not met in the second one. What is different about those two is that in order for the K-L condition to be met logical 0 (blue) cannot be connected to a state, to which logical 1 (red) is connected. </p>"},{"location":"qip1_2024/ch7.html#702-how-large-hilbert-space-do-we-need-to-correct-for-errors","title":"7.0.2. How large Hilbert space do we need to correct for errors:","text":"<p>So then the natural next question comes to mind. How many nodes of separation do we need to correct for errors? If we want to be able to correct for states where only single error happened, then we need to have at least two nodes of separation. </p> <p>In order to have this larger Hilbert space, we either need to have more qubits or use qudits. Consider that the only error channel that we need to consider is a bit flip channel. In this case if we use \\(n\\) qubits to encode a logical state, then we have n possible non-logical qubit states into which each one of our logical states can.</p> <p>So for logical state composed of 1 qubit, the logical state is connected only to one other state. For logical state composed of 2 qubits, the logical state is connected to 2 other states. And so on. We know equally that the necessary size of the vector space to be able to correct for all errors is such that the distance between any two logical states is at least 2. Therefore for \\(n\\) qubits with bit-flip errors we need at least \\(2n+2\\) states to be able to correct for all errors. Necessary graphs for different values of \\(n\\) are shown below.</p> <p></p> <p>We straight away can notice that for \\(n=1\\) we need 4 states to be able to correct for all errors, but the hilbert space of single qubit is only 2-dimensional. This means that it would be impossible to correct for errors in this case. We could try to use \\(n=2\\) qubits, but we will run into similar problem. We need 6 states to be able to correct for all errors, but the hilbert space of 2-qubit is only 4-dimensional. Going further we can see that for \\(n=3\\) we need 8 states to be able to correct for all errors, and the Hilbert space of 3-qubit is 8-dimensional. This means that we can correct for errors in this case. Code that does that, is called 3-qubit bit-flip code, and will be described below. </p> <p>By analogy we can try to understand how large Hilbert space do we need if each physical qubit comes with a bit-flip and phase-flip error. This means that for logical state composed of \\(n\\) qubits we need to have \\(2\\left(2n\\right)+2\\) states to be able to correct for all errors. We can do a similar analysis as above and see that \\(2^n \\geq 2\\left(2n\\right)+2\\) for n=5. This is exactly the smallest code size that can correct for both bit-flip and phase-flip errors. The analysis is done below:</p> <p></p>"},{"location":"qip1_2024/ch7.html#703-see-without-seeing","title":"7.0.3. See without seeing:","text":"<p>As mentioned already before, quantum error correction is somewhat more subtle than what we sofar described. Yes we want to know in which state we are to know which error occured, but at the same time we don't want to learn anything about the logical information. If we did, we would simply collapse the superposition into one of the measurement outcomes, and we would loose the quantum information. </p> <p>To do this we can for instance instead of measuring the exact state in which the qubit are, we can pair this state up with some other state that was caused by the same type of error (but is due to this error occuring on a different logical state). This way we can measure which error occured without learning anything about the logical information.</p> <p>This is illustrated on the diagram below:</p> <p></p> <p>What we see is two logical states which are each connected to three other states, that are due to the errors \\(E_1\\), \\(E_2\\), and \\(E_3\\). I now grouped the states from two logical subspaces together if they were caused by the same type of error. We can measure whether the states belong to this group. If they do, they must have been caused by error \\(E_i\\), and so we know how can we bring them back to the original logical state. Because we now measure whether we are in a subspace, of which states from both logical subspaces are part of, we can't learn anything about the logical information, and so we learn about the error without collapsing the superposition. The requirement for it is that the errors act in the same way on both logical states.</p>"},{"location":"qip1_2024/ch7.html#704-even-tiny-error-is-massive-when-measured","title":"7.0.4. Even tiny error is massive when measured:","text":"<p>One thing I was initially confused about is why the errors that we consider are always so massive. It seems that we are always considering the errors that for instance flip entirely the phase or the bit, or like ilustrated above move us from one state in our vector space to another. But can't I have just a tiny error, where I am rotating slightly from state i to state j?</p> <p>Yes, of course you can! However, in quantum mechanics it will look like a jump if you measure it:</p> \\[ \\left|\\psi\\right&gt; \\rightarrow \\left|\\psi\\right&gt; + \\epsilon\\left|\\psi'\\right&gt; \\] <p>For instance we can take a tiny bit-flip error on the first qubit acting on the state \\(\\left|000\\right&gt;\\):</p> \\[ \\left|000\\right&gt; \\rightarrow \\left|000\\right&gt; + \\epsilon\\left|100\\right&gt; \\] <p>And now what we can see is that actually when we make a measurement as described in the chapter 7.0.3, we will always collapse our state into either \\(\\left|000\\right&gt;\\) or \\(\\left|100\\right&gt;\\). This means that any small rotation, or tiny tiny error will always be transformed into either a bit-flip or no error at all. This is nice because it means that each error is very visible and we can correct for it.</p>"},{"location":"qip1_2024/ch7.html#71-the-three-qubit-bit-flip-code","title":"7.1. The Three Qubit Bit Flip Code:","text":"<p>Given that we undestood some basic concepts of error correction, let's now look at the first example of error correction. The 3-qubit bit-flip code. This should formalize the concepts that we have discussed sofar.</p> <p>As we said encoding information simply in a single physical qubit \\(\\left|\\psi\\right&gt; = \\alpha\\left|0\\right&gt; + \\beta\\left|1\\right&gt;\\) is not a good idea, as any error will be catastrophic. Let's consider that the only error that can happen is a bit-flip error. In this case the error flipping the bit would cause the \\(E \\left|\\psi\\right&gt; = E\\left(\\alpha\\left|0\\right&gt; + \\beta\\left|1\\right&gt;\\right) = \\alpha\\left|1\\right&gt; + \\beta\\left|0\\right&gt;\\).</p> <p>As discussed above if we want to correct for single errors per qubit, then we need at least 3 qubits to be able to correct for all errors. Let's then encode the information in a 3-qubit code, where \\(\\left|\\psi\\right&gt;_L = \\alpha\\left|0\\right&gt;_L + \\beta\\left|1\\right&gt;_L\\), and where \\(\\left|0\\right&gt;_L = \\left|000\\right&gt;\\) and \\(\\left|1\\right&gt;_L = \\left|111\\right&gt;\\). We can construct this code by having information encoded in the first qubit, and then performing two CNOT operations controlled on the first qubit and applied to the second and third qubits. </p> <p>In this case there are 3 possible errors that can happen, which correspond to the bit-flip errors on each of the qubits. We can represent this on the diagram below:</p> <p></p> <p>And as you can see the all possible errors are distinguishable as neither of the states is connected to the two logical states via some error channel. To correct for the error we would like to distinguish whether we are in black, green, pink or blue subspace. Notice that even if we know in which of those subspaces we are, it doesn't reveal us any information about the logical information.</p> <p>How can we measure in which subspace we are. Well, there are four states, so it should be enough to make \\(\\log_2\\left(4\\right) = 2\\) measurements. We can do through measuring \\(Z_1Z_2\\) and \\(Z_2Z_3\\) and then we can see in which subspace we are. In the diagram below I have illustrated the measurement. The blue color tells us that we would measure positive value for this measurement, and the red color tells us that we would measure negative value for this measurement.</p> <p></p> <p>As both of those measurements slice the space differently, by knowing the outcomes of both measurements we can tell in which subspace we are. This means that we know exactly which error occured, and so we can correct for it.</p> <p>The logical operators that would measure the logical qubit would have the following form: </p> \\[ X_L = X_1X_2X_3 \\] \\[ Z_L = Z_1Z_2Z_3 \\] <p>Mathematically what we require from the error syndrome measurement is that the error syndrome measurement should commute with the logical operators. If they did not, they would consequently reveal information about the logical state, and so destroy the coherence of the logical state.</p> <p>We can see that:</p> \\[ \\left[Z_L, Z_1Z_2\\right] = \\left[Z_L, Z_2Z_3\\right] = \\left[X_L, Z_1Z_2\\right] = \\left[X_L, Z_2Z_3\\right] = 0 \\] <p>which aggrees with out already formed intuition.</p> <p>Additionally I am including here a table of all possible errors and their corresponding error syndrome measurements, and the error correction operations.</p> Error Syndrome s \\(\\left(Z_1Z_2, Z_2Z_3\\right)\\) Correction \\(U_s\\) \\(\\left(I I I\\right)\\) \\(\\left(0, 0\\right)\\) \\(\\left(I I I\\right)\\) \\(\\left(X I I\\right)\\) \\(\\left(1, 0\\right)\\) \\(\\left(X I I\\right)\\) \\(\\left(I X I\\right)\\) \\(\\left(1, 1\\right)\\) \\(\\left(I X I\\right)\\) \\(\\left(I I X\\right)\\) \\(\\left(0, 1\\right)\\) \\(\\left(I I X\\right)\\) <p>The circuit to measure the error syndrome is shown below:</p> <p></p> <p>I wont go into other codes here, as it would be useful to first introduce the concept of stabilizer formalism, and then we will have much more compact notation for the codes.</p>"},{"location":"qip1_2024/ch7.html#72-knill-laflamme-condition","title":"7.2. Knill-Laflamme condition:","text":"<p>The actual Knill-Laflamme condition can be written actually as a necessary and sufficient condition:</p> \\[ \\left&lt; j\\right| E_b^{\\dagger} E_a\\left|i\\right&gt;_L = c_{ab}\\delta_{ij} \\] <p>This is a necessary and sufficient condition for the errors to be corrected. And how do we reconcile this with the intuition that we have developed sofar. What happens when two errors bring us to the same state or bring us a bit to the same state? Well this is simply because we poorly defined our basis states. If we were to define our basis states better, we would be able to distinguish between those errors. So given that we have our matrix \\(c_{ab}\\) we can always find a better basis, where the \\(c_ab\\) will be diagonal, and so will have the form:</p> \\[ \\left&lt; j\\right| E_b^{\\dagger} E_a\\left|i\\right&gt;_L = \\delta_{ab}\\delta_{ij} \\] <p>or similar. </p>"},{"location":"qip1_2024/ch8.html","title":"Chapter 8: Stabiliser Formalism:","text":"<p>This is section will be expanded in the future. Good reference for this is Surviving as a Quantum Computer in the Classical World by Daniel Gottesman.</p>"},{"location":"qip1_2024/ch8.html#81-stabiliser-groups-definitions","title":"8.1. Stabiliser Groups definitions:","text":"<ul> <li>\\(\\left|\\phi\\right&gt; \\in \\mathcal{H}\\) is a stabilised by an operator K if \\(K\\left|\\phi\\right&gt; = \\left|\\phi\\right&gt;\\) - i.e. \\(\\left|\\phi\\right&gt;\\) is an eigenstate of K with eigenvalue 1.</li> <li>Pauli Group for a single qubit is defined as: \\(\\mathcal{P} := \\left\\{ \\pm I, \\pm X, \\pm Y, \\pm Z, \\pm i I, \\pm i X, \\pm i Y, \\pm i Z \\right\\}\\)</li> <li>n-qubit Pauli Group is defined as: \\(\\mathcal{P_n} := \\{A_1 \\otimes ... A_n |A_i \\in \\mathcal{P}\\}\\)</li> <li>Stabiliser Group \\(\\mathcal{S}\\) is a subgroup of \\(\\mathcal{P_n}\\) s.t. \\([S_i, S_j] = 0 \\forall S_i, S_j \\in \\mathcal{S}\\) and \\(-I \\notin \\mathcal{S}\\). This can be said more compact through \"Non-abelian subgroup of \\(\\mathcal{P_n}\\), that does not contain \\(-id\\)\".</li> <li>Set of generators of a group is a set of elements s.t. any element of the group can be written as a product of the generators and their inverses.</li> <li>Minimal set of generators is a set of generators s.t. they are linearly independent.</li> <li>Stabiliser subspace: \\(\\mathcal{H_S} := \\{\\left|\\psi\\right&gt; | S\\left|\\psi\\right&gt; = \\left|\\psi\\right&gt; \\forall S \\in \\mathcal{S}\\}\\)</li> </ul>"},{"location":"qip1_2024/ch8.html#82-stabiliser-codes","title":"8.2. Stabiliser Codes:","text":""},{"location":"qip1_2024/ch8.html#821-size-of-the-stabilised-space","title":"8.2.1. Size of the Stabilised space:","text":"<p>One can then ponder about what does picking specific stabiliser mean for the space that we stabilise, and the errors that we can correct. Well let's first address the first question. If the stabiliser group defined in a space of n-qubits is formed by minimal set of generators \\(\\mathcal{S} = \\left&lt; S_1, ..., S_k \\right&gt;\\) then the dimension of the stabilised space is \\(2^{n- k}\\). This is because the stabiliser group is a subset of the Pauli group, and so \\(S^2=I\\) for all \\(S \\in \\mathcal{S}\\) (both because the S are elements of the Pauli group and because applicatiion of stabiliser twice should also stabilise the state). This means that \\(S^2 = I\\) for all \\(S \\in \\mathcal{S}\\). This means that eigenvalues of all stabilisers are \\(\\pm 1\\), which furhter means that each of the stabiliser splits the vector space into two.</p>"},{"location":"qip1_2024/ch8.html#8211-why-does-measurement-of-s_1-and-s_2-partition-the-space-into-4-equal-subspaces","title":"8.2.1.1. Why does measurement of \\(S_1\\) and \\(S_2\\) partition the space into 4 equal subspaces?","text":"<p>So we have shown that the measurement of the stabiliser splits the vector space into two sets, one composed of the eigenfunctions that result in eigenvalue 1, and the other composed of the eigenfunctions that result in eigenvalue -1. Now we can ask the question, why does the measurement of \\(S_1\\) and \\(S_2\\) partition the space into 4 equal subspaces, where results of two measurements are (1,1), (1,-1), (-1,1), (-1,-1)?</p> <p>Let's consider that it is not the case. We can then </p> <p>Therefore the stabilised space is always divided into two, and since all the stabilisers are linearly independent, they split the space into \\(2^k\\) subspaces. Therefore the dimension of the stabilised space is \\(2^n - k\\).</p>"},{"location":"qip1_2024/ch8.html#822-given-our-stabiliser-group-what-errors-can-we-detect","title":"8.2.2. Given our Stabiliser Group, what errors can we detect?","text":"<p>Suppose that \\(\\left|\\psi\\right&gt;_L\\) lies in a stabilised subspace of \\(\\mathcal{S}=\\left&lt; S_1, ..., S_k \\right&gt;\\). In order to be able to notice the error, we would like to be able to distinguish it from the logical state. This means that some sort of measurement should be able to distinguish the two. As the stabiliser stabilizes the stabilised space, the error should bring the state out of the stabilised space. Therefore the error should anticommute with at least one of the stabilisers.</p> <p>Ok, so now we know whether we can correct for an error, but how do we make sure that we dont learn anything about the logical state? This can be again done by reformulating the Knill-Laflamme conditions for stabiliser codes.</p> \\[ \\{ E_i, S_j \\} = 0 \\implies \\text{error is detected} \\] <p>Can we refolmulate the Knill-Laflamme conditions for stabiliser codes?</p> \\[ E_b^\\dagger E_a \\in \\mathcal{S} \\]"},{"location":"qip1_2024/ch8.html#823-given-our-stabiliser-group-how-can-we-perform-a-logical-operation","title":"8.2.3. Given our Stabiliser Group, how can we perform a logical operation?","text":"<p>What we want from our logical operators, is that they dont bring us outside of the stabilised space, as otherwise we would somehow leak the information about the logical state. Therefore we want that the logical operators commute with all the stabilisers. </p> <p>Hence if one finds two operators \\(U\\), \\(V\\) s.t. \\([U, S]=[V, S]=0 \\forall S \\in \\mathcal{S}\\), and \\(\\{U, V\\}=0\\) then they can identify them as \\(U=Z_L\\) and \\(V=X_L\\).</p> <p>Code words can be identified as the eigenstates of the logical operator \\(Z_L\\).</p>"},{"location":"qip1_2024/ch8.html#83-stabiliser-codes","title":"8.3. Stabiliser Codes:","text":"<p>Here in this section I will include few examples of stabiliser codes.</p>"},{"location":"qip1_2024/ch8.html#831-3-bit-flip-code","title":"8.3.1. 3-bit flip code:","text":"\\(S_(1)\\) \\(Z\\) \\(Z\\) \\(I\\) \\(S_(2)\\) \\(I\\) \\(Z\\) \\(Z\\) \\(Z_(L)\\) \\(Z\\) \\(Z\\) \\(Z\\) \\(X_(L)\\) \\(X\\) \\(X\\) \\(X\\)"},{"location":"qip1_2024/ch8.html#832-3-bit-phase-code","title":"8.3.2. 3-bit phase code:","text":"\\(S_(1)\\) \\(X\\) \\(X\\) \\(I\\) \\(S_(2)\\) \\(I\\) \\(X\\) \\(X\\) \\(Z_(L)\\) \\(X\\) \\(X\\) \\(X\\) \\(X_(L)\\) \\(Z\\) \\(Z\\) \\(Z\\)"},{"location":"qip1_2024/ch8.html#833-9-bit-shors-code","title":"8.3.3. 9-bit Shors code:","text":"\\(S_(1)\\) \\(Z\\) \\(Z\\) \\(I\\) \\(I\\) \\(I\\) \\(I\\) \\(I\\) \\(I\\) \\(I\\) \\(S_(2)\\) \\(I\\) \\(Z\\) \\(Z\\) \\(I\\) \\(I\\) \\(I\\) \\(I\\) \\(I\\) \\(I\\) \\(S_(3)\\) \\(I\\) \\(I\\) \\(I\\) \\(Z\\) \\(Z\\) \\(I\\) \\(I\\) \\(I\\) \\(I\\) \\(S_(4)\\) \\(I\\) \\(I\\) \\(I\\) \\(I\\) \\(Z\\) \\(Z\\) \\(I\\) \\(I\\) \\(I\\) \\(S_(5)\\) \\(I\\) \\(I\\) \\(I\\) \\(I\\) \\(I\\) \\(I\\) \\(Z\\) \\(Z\\) \\(I\\) \\(S_(6)\\) \\(I\\) \\(I\\) \\(I\\) \\(I\\) \\(I\\) \\(I\\) \\(I\\) \\(Z\\) \\(Z\\) \\(S_(7)\\) \\(X\\) \\(X\\) \\(X\\) \\(X\\) \\(X\\) \\(X\\) \\(I\\) \\(I\\) \\(I\\) \\(S_(8)\\) \\(I\\) \\(I\\) \\(I\\) \\(X\\) \\(X\\) \\(X\\) \\(X\\) \\(X\\) \\(X\\) \\(Z_(L)\\) \\(X\\) \\(X\\) \\(X\\) \\(I\\) \\(I\\) \\(I\\) \\(I\\) \\(I\\) \\(I\\) \\(X_(L)\\) \\(Z\\) \\(I\\) \\(I\\) \\(Z\\) \\(I\\) \\(I\\) \\(Z\\) \\(I\\) \\(I\\)"},{"location":"qip1_2024/ch8.html#834-steane-code","title":"8.3.4. Steane code:","text":"\\(S_(1)\\) \\(I\\) \\(I\\) \\(I\\) \\(Z\\) \\(Z\\) \\(Z\\) \\(Z\\) \\(S_(2)\\) \\(I\\) \\(Z\\) \\(Z\\) \\(I\\) \\(I\\) \\(Z\\) \\(Z\\) \\(S_(3)\\) \\(Z\\) \\(I\\) \\(Z\\) \\(I\\) \\(Z\\) \\(I\\) \\(Z\\) \\(S_(4)\\) \\(I\\) \\(I\\) \\(I\\) \\(X\\) \\(X\\) \\(X\\) \\(X\\) \\(S_(5)\\) \\(I\\) \\(X\\) \\(X\\) \\(I\\) \\(I\\) \\(X\\) \\(X\\) \\(S_(6)\\) \\(X\\) \\(I\\) \\(X\\) \\(I\\) \\(X\\) \\(I\\) \\(X\\) \\(Z_(L)\\) \\(Z\\) \\(Z\\) \\(Z\\) \\(Z\\) \\(Z\\) \\(Z\\) \\(Z\\) \\(X_(L)\\) \\(X\\) \\(X\\) \\(X\\) \\(X\\) \\(X\\) \\(X\\) \\(X\\)"},{"location":"qip1_2024/ch8.html#835-5-qubit-code","title":"8.3.5. 5-qubit code:","text":"\\(S_(1)\\) \\(X\\) \\(Z\\) \\(Z\\) \\(X\\) \\(I\\) \\(S_(2)\\) \\(I\\) \\(X\\) \\(Z\\) \\(Z\\) \\(X\\) \\(S_(3)\\) \\(X\\) \\(I\\) \\(X\\) \\(Z\\) \\(Z\\) \\(S_(4)\\) \\(Z\\) \\(X\\) \\(I\\) \\(X\\) \\(Z\\) \\(Z_(L)\\) \\(Z\\) \\(Z\\) \\(Z\\) \\(Z\\) \\(Z\\) \\(X_(L)\\) \\(X\\) \\(X\\) \\(X\\) \\(X\\) \\(X\\)"},{"location":"qip1_2024/organisation.html","title":"Organisation","text":""},{"location":"qip1_2024/organisation.html#group-chat","title":"Group Chat:","text":""},{"location":"qip1_2025/ch0.html","title":"Chapter 0: Introduction","text":"<p>Welcome to Quantum Information Processing. It is a course that wants to introduce you to many elegant and beautiful concepts surrounding the field that has a potential to massively increase human understanding of quantum mechanics and many body physics. You are taking it at a very special time, because it seems that we start to see some early signs that the whole venture of quantum computing is perhaps not that hopeless. And I am also sure many of you are precisely here because of that, so we will talk about quantum computation.</p> <p>In my notes I will largely \"ignore small formal subtleties, not because they're not interesting, but because they're a distraction from all the interesting physics we want to learn!\" [1]. I will actually skip some of the formalism introduced in the lecture if I feel like it hinders my own understanding of Quantum Mechanics. I am open to being criticised for it. </p>"},{"location":"qip1_2025/ch0.html#01-information-is-tied-to-physical-representation","title":"0.1.: Information is tied to physical representation:","text":"<p>Before we dive into computation itself, it is worth pausing to think about information. Information is everywhere in our lives, but what exactly is it? At its core, information can be seen as a refinement of our knowledge about the state of a system. The most basic unit of information is a bit, which can take one of two values.</p> <p>In abstract mathematics we can freely manipulate bits, apply functions, and reason about logical operations without worrying about what the bits \u201care.\u201d But the moment we want to process information in reality, it must be given a physical representation. A bit is never just an abstract symbol: it must be encoded in some physical system-whether as voltages in a circuit, magnetic domains on a hard drive, or photons in a fiber. \u201cInformation is not a disembodied abstract entity; it is always tied to a physical representation.\u201d [3]</p> <p>This perspective has deep consequences. If information is represented in physical degrees of freedom, then any act of computation must correspond to a physical evolution of that system. The laws of physics therefore set the ultimate limits of computation.</p> <p>The current paradigm of computing is rooted in classical physics. That choice defines which operations are natural and efficient to perform. \"But that is not our World. To the best of our current experimental knowledge, our World is a quantum, not classical.\" [1]. This realization suggests an opportunity: if we can carefully isolate and manipulate quantum systems, then we may access a richer set of operations and new forms of information processing.</p> <p>This is the promise of Quantum Information Processing (QIP). The QIP\u2013Implementation perspective asks: how can we actually build physical systems that store and manipulate information using quantum mechanics? The QIP\u2013Conceptual perspective asks: what happens to the very notion of information once we treat it in a quantum way? Together, these perspectives aim to provide the grounding you need to explore how quantum mechanics reshapes the paradigm of computation.</p>"},{"location":"qip1_2025/ch0.html#02-so-what-are-the-good-reasons-to-build-a-quantum-computer","title":"0.2.: So what are the good reasons to build a quantum computer:","text":"<p>So far, we have seen that quantum mechanics offers new ways to represent and process information. But an obvious question follows: why should we care? What are the real motivations behind building a quantum computer? The answer depends strongly on who you ask.</p> <ul> <li>For physicists, the motivation is largely fundamental. Quantum systems quickly become intractable as their size grows, because the number of parameters needed to describe them scales exponentially. Today, we rely heavily on approximations or numerical tricks. A controllable quantum device that can emulate many-body quantum dynamics would therefore be revolutionary. It would act as a kind of \u201cmicroscope\u201d for quantum reality, allowing us to probe strongly correlated systems, exotic phases of matter, and high-energy physics in ways that classical computers cannot.</li> <li>For governments, the primary interest lies in security. Much of modern cryptography relies on the assumption that certain mathematical problems (like factoring large integers) are practically impossible for classical machines. Quantum computers threaten this assumption: algorithms such as Shor\u2019s could, in principle, break widely used encryption schemes. This potential disruption is driving intense global investment and competition.</li> <li>For industry, the motivations are more applied. Quantum computing promises advantages in fields where nature itself is quantum mechanical: quantum chemistry, materials science, and molecular modeling. Better simulations could accelerate drug discovery, improve catalysts for clean energy, and enable the design of new materials with tailored properties. Companies also hope for breakthroughs in optimization and machine learning, although these applications are less firmly established than chemistry and physics.</li> </ul> <p>Different communities see different \u201ckiller applications.\u201d But the unifying motivation is that a quantum computer would allow us to do things fundamentally beyond the reach of classical machines. Whether the goal is to understand nature more deeply, protect or disrupt information security, or unlock practical technologies, the reasons are compelling-and they explain why the race to build quantum computers is so intense today.</p>"},{"location":"qip1_2025/ch0.html#03-what-makes-quantum-more-powerfull-than-classical","title":"0.3.: What makes quantum more powerfull than classical:","text":""},{"location":"qip1_2025/ch1a.html","title":"Chapter 1a: Principles of Quantum Mechanics","text":""},{"location":"qip1_2025/ch1a.html#11-space-which-we-are-exploring","title":"1.1. Space which we are exploring:","text":"<p>Hilbert Space:</p> <p>A Hilbert space is the mathematical stage on which quantum mechanics plays out. Formally, it is a vector space \\(\\mathcal{H}\\) over the complex numbers \\(\\mathbb{C}\\), equipped with a complete inner product. - Vector space: This simply means we can take linear combinations of elements (called vectors) and remain within the space. - Inner product: A rule that allows us to compute angles and lengths, generalizing the familiar dot product. It is a map \\((\\cdot , \\cdot): \\mathcal{H} \\times \\mathcal{H} \\to \\mathbb{C}.\\) - Completeness: A technical requirement ensuring that limits of convergent sequences of vectors remain in the space. (For our purposes, this subtlety will not play an important role, but it guarantees the mathematical consistency of the theory.)</p> <p>The inner product satisfies four key properties:</p> \\[ \\begin{aligned} \\text { conjugate symmetry } &amp; (\\phi, \\psi)=\\overline{(\\psi, \\phi)} \\\\ \\text { linearity } &amp; (\\phi, a \\psi)=a(\\phi, \\psi) \\\\ \\text { additivity } &amp; (\\phi, \\psi+\\chi)=(\\phi, \\psi)+(\\phi, \\chi) \\\\ \\text { positive-definiteness } &amp; (\\psi, \\psi) \\geq 0 \\forall \\psi \\in \\mathcal{H} \\end{aligned} \\] <p>From the inner product we can define the norm (or length) of a vector:</p> \\[ |\\psi| \\equiv \\sqrt{(\\psi, \\psi)}. \\] <p>This norm equips \\(\\mathcal{H}\\) with a metric, allowing us to measure distances between states.</p> <p>Finally, in quantum mechanics, states of a system are represented by vectors \\(\\psi \\in \\mathcal{H}\\). This simple but powerful idea-representing physical states as elements of a Hilbert space-is the foundation of the entire theory.</p> <p>Dual Spaces:</p> <p>Dual space \\(\\mathcal{H^*}\\) of \\(\\mathcal{H}\\) is the space of linear maps \\(\\mathcal{H} \\rightarrow \\mathbb{C}\\). That is, an element \\(\\phi \\in \\mathcal{H^*}\\) defines a map \\(\\varphi: \\psi \\mapsto \\varphi(\\psi) \\in \\mathbb{C}\\) for every \\(\\psi \\in \\mathcal{H}\\), such that </p> \\[ \\varphi: a \\psi_1+b \\psi_2 \\mapsto a \\varphi\\left(\\psi_1\\right)+b \\varphi\\left(\\psi_2\\right) \\] <p>One can think about the objects in the dual space as rules, where they take the vectors from Hilbert space and spit out complex numbers.</p> <p>Example: One of the dual space \\(\\mathcal{H^*}\\) is for instance the inner product \\((\\phi, \\quad) \\in \\mathcal{H}^*\\) for \\(\\phi \\in \\mathcal{H}\\), where </p> \\[ (\\phi, \\quad): \\psi \\mapsto(\\phi, \\psi) \\]"},{"location":"qip1_2025/ch1a.html#12-dirac-notation","title":"1.2. Dirac Notation:","text":"<p>To reduce overhead we introduce more compact notation to deal with quantum mechanics. Since in the quantum mechanics we often switch basis it is useful to introduce a notation that allows us to deal with a spacific states in any basis. Dirac notation (empirically) provides this clarity. It is difficult to formally define the notation, and quite often when one does it, they get confused (unless they are deep down in theory). Therefore I would propose to learn it through learning the basic few properties and then trying things out. </p> <p>Dirac denotes element of \\(\\mathcal{H}\\) as \\(\\left|\\psi\\right&gt;\\) 'ket', and an element of the dual space is written as \\(\\mathcal{H^*}\\) as \\(\\left&lt;\\psi\\right|\\) 'bra'. The inner product between two states \\(\\left|\\psi\\right&gt;, \\left|\\phi\\right&gt; \\in \\mathcal{H}\\) is written as \\(\\left&lt;\\psi|\\phi\\right&gt;\\).</p> <ul> <li>The advantage of using bra-ket notation is:<ul> <li>We can talk about multiple things at the same time - Dirac notation is effectively just a label that points to an abstract object in the Hilbert space. We don't need to specify whether the variable is contineous, or if it is a vector or a function.</li> <li>Allows us to label states by their eigenvalues</li> <li>Somehow it is more natural and causes less confusion</li> </ul> </li> </ul>"},{"location":"qip1_2025/ch1a.html#13-operators","title":"1.3. Operators:","text":"<ul> <li>A linear operator A is a map \\(A : \\mathcal{H} \\rightarrow \\mathcal{H}\\) that is compatible with the vector space structure \\(A(c_1\\left|\\phi_1\\right&gt; + c_2\\left|\\phi_2\\right&gt;) = c_1A\\left|\\phi_1\\right&gt; + c_2A\\left|\\phi_2\\right&gt;\\)</li> <li>All operators in Quantum Mechanics are linear, hence we will call them just 'operators'</li> <li>Operators form algebra<ul> <li>Sum: \\((\\alpha A+\\beta B):\\left|\\phi\\right&gt; \\mapsto \\alpha A\\left|\\phi\\right&gt;+\\beta B\\left|\\phi\\right&gt;\\)</li> <li>Product: \\(A B: \\phi \\mapsto A \\circ B\\left|\\phi\\right&gt;=A(B\\left|\\phi\\right&gt;)\\)</li> <li>Commutator: \\([A, B]=A B-B A\\)</li> </ul> </li> <li>A state \\(\\psi \\in \\mathcal{H}\\) is said to be an eigenstate of an operator A if \\(A\\left|\\psi\\right&gt; = a_\\psi\\left|\\psi\\right&gt;\\) with an associated eigenvalue '\\(a_\\psi\\)'.</li> <li>Adjoint \\(A^\\dagger\\) of an operator \\(A\\) is defined as \\(\\left&lt;\\phi\\right|A^{\\dagger}\\left| \\psi\\right&gt;=\\overline{\\left&lt;\\psi\\right|A\\left| \\phi\\right&gt;} \\quad\\)<ul> <li>An operator \\(Q\\) is called Hermitian if \\(Q^\\dagger=Q\\)</li> <li>An operator \\(U\\) is called Unitary if \\(U^\\dagger U= U U^\\dagger = \\mathbb{I}\\)</li> <li>An operator \\(\\Pi\\) is called Projector if \\(\\Pi\\Pi= \\Pi\\)</li> </ul> </li> </ul>"},{"location":"qip1_2025/ch1a.html#14-composite-systems","title":"1.4. Composite systems:","text":"<p>Tensor Product - Tensor product can be thought simply as adding a new dimension (axis) to the existing space. Consider for instance one space that is one dimensional, and the other space that is two dimensional. The tensor product of these two spaces is a three dimension space. Thats simple! - Formally Tensor product \\(\\mathcal{H}_1 \\otimes \\mathcal{H}_2\\) is a vector space over \\(\\mathbb{C}\\) spanned by all pairs of elements \\(\\left|e_a\\right&gt; \\otimes\\left|f_\\alpha\\right&gt;\\), where \\(\\left|e_a\\right&gt; \\in \\mathcal{H_1}\\), \\(\\left|f_\\alpha\\right&gt; \\in \\mathcal{H_2}\\) - It is not true that a general element of \\(\\mathcal{H}_1 \\otimes \\mathcal{H}_2\\) necessarily takes the form \\(\\left|\\psi_1\\right&gt;\\otimes\\left|\\psi_2\\right&gt;\\) - Rather, a general element may be written as \\(\\left|\\Psi\\right&gt;=\\sum_{a, \\alpha} r_{a \\alpha}\\left|e_a\\right&gt; \\otimes\\left|f_\\alpha\\right&gt;\\) - Elements of the form \\(\\left|\\psi_1\\right&gt;\\otimes\\left|\\psi_2\\right&gt;\\) are called simple, and the elements of the form \\(\\left|\\Psi\\right&gt;=\\sum_{a, \\alpha} r_{a \\alpha}\\left|e_a\\right&gt; \\otimes\\left|f_\\alpha\\right&gt;\\) are refered as entangled - \\(\\left&lt;\\alpha\\otimes\\beta|\\alpha'\\otimes\\beta'\\right&gt; := \\left&lt;\\alpha|\\alpha'\\right&gt;\\left&lt;\\beta|\\beta'\\right&gt;\\) - \\(\\left( S_\\alpha \\otimes T_\\beta \\right)\\left(\\alpha \\otimes \\beta\\right) = \\left(S_\\alpha\\alpha\\right)\\otimes\\left(T_\\beta\\beta\\right)\\)</p> <p>Tensor Product in action (states)</p> <ul> <li>Let's as an example consider that our states \\(\\left|\\alpha\\right&gt;_A \\text{ and } \\left|\\beta\\right&gt;_B\\) live both in \\(\\mathbb{C}^2_A\\) and \\(\\mathbb{C}^2_B\\) respectively. Then we can pick orthonormal basis of \\(\\mathbb{C}^2_A\\) to be \\(\\left\\{\\left|u_1\\right&gt;_A, \\left|u_2\\right&gt;_A \\right\\}\\), and of \\(\\mathbb{C}^2_B\\) to be \\(\\left\\{\\left|v_1\\right&gt;_B, \\left|v_2\\right&gt;_B \\right\\}\\)</li> <li>Then one can write \\(\\left|\\alpha\\right&gt;_A = a_1 \\left|u_1\\right&gt;_A + a_2 \\left|u_2\\right&gt;_A = a_1 \\begin{pmatrix} 1\\\\ 0 \\end{pmatrix}_A + a_2 \\begin{pmatrix} 0\\\\ 1 \\end{pmatrix}_A\\),</li> <li>and \\(\\left|\\beta\\right&gt;_B = b_1 \\left|v_1\\right&gt;_B + b_2 \\left|v_2\\right&gt;_B = b_1 \\begin{pmatrix} 1\\\\ 0 \\end{pmatrix}_B + b_2 \\begin{pmatrix} 0\\\\ 1 \\end{pmatrix}_B\\)</li> <li>This means that one can write </li> </ul> \\[ \\left|\\alpha\\right&gt;_A \\otimes \\left|\\beta\\right&gt;_B = \\begin{pmatrix} a_1\\\\ a_2 \\end{pmatrix}_A \\otimes \\begin{pmatrix} b_1\\\\ b_2 \\end{pmatrix}_B = \\begin{pmatrix} a_1b_1\\\\ a_1b_2\\\\ a_2b_1\\\\ a_2b_2 \\end{pmatrix} \\] <ul> <li>or sticking to the Dirac notation:</li> </ul> \\[ \\left|\\alpha\\right&gt;_A \\otimes \\left|\\beta\\right&gt;_B = \\sum_{i,j} a_i b_j \\left|u_i\\right&gt;_A \\otimes \\left|v_j\\right&gt;_B \\] <p>Tensor Product in action (operators)</p> <ul> <li>For operators \\(A\\) and \\(B\\) that live in \\(\\mathbb{C}^2_A\\) and \\(\\mathbb{C}^2_B\\) respectively, one can write \\(A = \\sum_{i,j} a_{ij} \\left|u_i\\right&gt;_A \\left&lt;u_j\\right|\\) and \\(B = \\sum_{i,j} b_{ij} \\left|v_i\\right&gt;_B \\left&lt;v_j\\right|\\)</li> <li>This means:</li> </ul> \\[ A \\otimes B = \\sum_{i,j,k,\\ell} a_{ij} b_{k\\ell} \\left|u_i\\right&gt;_A \\otimes \\left|v_k\\right&gt;_B \\left&lt;u_j\\right|\\otimes\\left&lt;v_\\ell\\right| \\] <ul> <li>or in a matrix form:</li> </ul> \\[ A \\otimes B = \\begin{pmatrix} a_{11}B &amp; a_{12}B\\\\ a_{21}B &amp; a_{22}B \\end{pmatrix} = \\begin{pmatrix} a_{11}b_{11} &amp; a_{11}b_{12} &amp; a_{12}b_{11} &amp; a_{12}b_{12}\\\\ a_{11}b_{21} &amp; a_{11}b_{22} &amp; a_{12}b_{21} &amp; a_{12}b_{22}\\\\ a_{21}b_{11} &amp; a_{21}b_{12} &amp; a_{22}b_{11} &amp; a_{22}b_{12}\\\\ a_{21}b_{21} &amp; a_{21}b_{22} &amp; a_{22}b_{21} &amp; a_{22}b_{22}\\\\ \\end{pmatrix} \\]"},{"location":"qip1_2025/ch1a.html#15-postulates-of-quantum-mechanics","title":"1.5. Postulates of Quantum Mechanics:","text":"<ul> <li>(1) A quantum system A is associated with complex Hilber space \\(\\mathcal{H}\\). A physical state of an isolated system is represented by a normalised vector \\(\\left|\\psi\\right&gt; \\in \\mathcal{H}\\), which is unique up to a phase factor</li> <li>(2) The evolution of an isolated quantum system is reversible. In this formalism this corresponds to unitary evolution of the form \\(\\left|\\psi\\right&gt; \\mapsto U\\left|\\psi\\right&gt;\\) for \\(U \\in \\mathcal{U}(\\mathcal{H})\\), i.e. \\(U^{\\dagger} U=U U^{\\dagger}=\\mathbb{I}\\). The unitary is unique up to a phase factor</li> <li>(3) Composite system - For two quantum system A, and B with associated Hilber spaces \\(\\mathcal{H_A}\\) and \\(\\mathcal{H_B}\\) the Hilbert space \\(\\mathcal{H_{AB}}\\) associated with the composite system AB is isomorphic to the tensor product \\(\\mathcal{H_A}\\otimes\\mathcal{H_B}\\). For unitary operation on the subsystem we use: \\(U_A \\otimes \\mathbb{I}_B\\left|i j\\right&gt;_{A B} \\equiv U_A\\left|i j\\right&gt;_{A B}\\)</li> <li>(4) Measurement - A projective measurement on a quantum system with outcomes labelled \\({x}_x\\) is associated with a set of projectors \\({\\Pi_x}x\\) satisfying \\(\\sum_x \\Pi_x = \\mathbb{I}\\). <ul> <li>Probability of getting outcome x when measuring state \\(\\left|\\psi\\right&gt;\\) is given by the Born rule: \\(Pr[x \\mid \\psi]=\\left\\langle\\psi\\left|\\Pi_x\\right| \\psi\\right\\rangle\\)</li> <li>Post-measurement state is given the outcome x is \\(\\left|\\psi_x^{\\prime}\\right&gt;=\\frac{1}{\\sqrt{\\operatorname{Pr}[x \\mid \\psi]}} \\Pi_x\\left|\\psi\\right&gt;=\\frac{\\Pi_x\\left|\\psi\\right&gt;}{\\sqrt{\\left\\langle\\psi\\left|\\Pi_x\\right| \\psi\\right\\rangle}}\\)</li> </ul> </li> </ul>"},{"location":"qip1_2025/ch1b.html","title":"Chapter 1b: Usefull Toolbox","text":""},{"location":"qip1_2025/ch1b.html#16-bloch-sphere","title":"1.6. Bloch Sphere:","text":"<ul> <li>Bloch Sphere is just a common representation of a two level system, which allows one to think about the states and operations in a more intuitive way</li> <li>Normally when one thinks about how many parameters one needs to define a two level system, they can naively consider 4 degrees of freedom. In the end two level system lives in \\(\\left|\\psi\\right&gt; \\in \\mathbb{C}^2\\). In different words, any pure state can be written as a superposition of the basis vectors \\(\\left|0\\right&gt;\\) and \\(\\left|1\\right&gt;\\), where the coefficient of each of the two basis vectors is a complex number. \\(\\left|\\psi\\right&gt; = a_1e^{i\\theta_1} \\left|0\\right&gt; +  a_2e^{i\\theta_2} \\left|1\\right&gt;\\). 4-parameters right?<ul> <li>We know, however, that the norm of a pure state must equal to 1, which means that $\\left&lt;\\psi|\\psi\\right&gt; = 1 $, and so \\(\\left|a_1\\right|^2 + \\left|a_2\\right|^2=1\\). This reduces the number of free parameters to 3</li> <li>We also know that we dont care about the global phase of a state, as it doesn't change anything about our measurement, and so we can also neglect one degree of freedom, which reduces the number of free parameters to 2</li> <li>This means that we can represent any 2-level quantum pure state on a two dimensional manifold (which is easy to think about). More specifically we care about two things (a) the relative phase between the two basis vector, and (b) the relative projections (populations) onto two basis vectors. We can use the angle around the circle to define the relative phase, and we can use the distance from the center of the circle to define the relative projections. This is the Bloch Sphere.</li> </ul> </li> <li>How does one parametrise something on a unit-sphere?<ul> <li>One can do it with angles, \\(\\theta \\text{ and } \\phi\\)</li> <li>\\(\\left|\\psi\\right&gt; = \\cos\\frac{\\theta}{2} \\left|0\\right&gt; +  e^{i\\phi}\\sin{\\frac{\\theta}{2}} \\left|1\\right&gt;\\)</li> <li>In such representation the probability of measuring state \\(\\left|0\\right&gt;\\) is: \\(\\left&lt;0|\\psi\\right&gt; = \\cos^2\\frac{\\theta}{2}\\), and to measure state \\(\\left|1\\right&gt;\\) is \\(\\sin^2\\frac{\\theta}{2}\\)</li> <li>\\(\\left|\\psi\\right&gt;\\) can be represented on a unit sphere as:</li> </ul> </li> </ul> <ul> <li>Any Unitary Operator then will be some sort of rotation of this state, mapping it from one point on this sphere to another point on this sphere - you will see it in the subchapter Quantum Circuits</li> </ul>"},{"location":"qip1_2025/ch1b.html#17-bell-basis","title":"1.7. Bell Basis","text":"<ul> <li>Let \\(\\mathcal{H}_{A B}=\\mathcal{H}_A \\otimes \\mathcal{H}_B \\cong \\mathbb{C}^4\\) be the bipartite Hilbert space of two qubits and consider the product basis of the computational bases of the qubit subsystems. For \\(\\mathcal{H_{AB}}\\) there exists a basis consisting of maximally entangled states denotes as:</li> </ul> \\[\\begin{array}{ll}\\left|\\psi^{00}\\right&gt;=\\frac{1}{\\sqrt{2}}(\\left|00\\right&gt;+\\left|11\\right&gt;) &amp; =\\left|\\Phi^{+}\\right&gt; \\\\ \\left|\\psi^{01}\\right&gt;=\\frac{1}{\\sqrt{2}}(\\left|00\\right&gt;-\\left|11\\right&gt;) &amp; =\\left|\\Phi^{-}\\right&gt; \\\\ \\left|\\psi^{10}\\right&gt;=\\frac{1}{\\sqrt{2}}(\\left|01\\right&gt;+\\left|10\\right&gt;) &amp; =\\left|\\Psi^{+}\\right&gt; \\\\ \\left|\\psi^{11}\\right&gt;=\\frac{1}{\\sqrt{2}}(\\left|01\\right&gt;-\\left|10\\right&gt;) &amp; =\\left|\\Psi^{-}\\right&gt;\\end{array}\\] <ul> <li>The first number stands for parity, the second number stands for phase. \\(\\left|\\psi^{10}\\right&gt;\\) has parity 1 (odd number of 1's), and relative phase \\((-1)^0=1\\)</li> <li>The maximally entangled states are locally convertible - there exist local operations on the subsystem B that transforms one Bell state into another Bell state. \\(\\(\\left|\\psi^{i j}\\right&gt;=\\left(\\mathbb{I}_A \\otimes X_B^i Z_B^j\\right)\\left|\\psi^{00}\\right&gt;\\)\\)</li> </ul>"},{"location":"qip1_2025/ch1b.html#18-quantum-circuits","title":"1.8. Quantum Circuits","text":"<p>Example Quantum circuit</p> <p> </p> <p>corresponds to unitary operator \\(\\left(V \\otimes \\mathbb{I}\\right)\\left(\\mathbb{I}\\otimes U\\right)\\left(H\\otimes\\mathbb{I}\\otimes Z\\right)\\) applied to three qubits followed by a Z-measurement of the first qubit</p> <p>Common Gates</p> <p> </p> <ul> <li>Haddamard Gate:<ul> <li>\\(H=\\frac{1}{\\sqrt{2}}\\left(\\begin{array}{cc}1 &amp; 1 \\\\ 1 &amp; -1\\end{array}\\right)=\\left|+\\right&gt;\\left&lt; 0\\right|+\\left|-\\right&gt; \\left&lt;1\\right|=\\left| 0\\right&gt;\\left&lt;+\\right|+\\left| 1\\right&gt;\\left&lt;-\\right|\\)</li> <li>As an orthogonal transformation in the real Euclidean plane \\(\\mathbb{R}^2\\), H is reflection in the mirror line at angle \\(\\frac{\\pi}{8}\\) to the x-axis</li> </ul> </li> <li>X, Y, Z:<ul> <li>\\(X = \\left(\\begin{array}{ll} 0 &amp; 1 \\\\ 1 &amp; 0 \\end{array}\\right)\\), \\(Z = \\left(\\begin{array}{ll} 1 &amp; 0 \\\\ 0 &amp; -1 \\end{array}\\right)\\), \\(Y = \\left(\\begin{array}{ll} 0 &amp; 1 \\\\ -1 &amp; 0 \\end{array}\\right)\\)</li> </ul> </li> <li>Controlled-U Gate:<ul> <li>\\(\\mathrm{C} U=\\left|0\\right&gt;\\left&lt;0\\right|\\otimes \\mathrm{id}+\\left| 1\\right&gt;\\left&lt;1\\right| \\otimes U\\)</li> </ul> </li> <li>Controlled-Not Gate:<ul> <li>\\(\\mathrm{CNOT}=\\left(\\begin{array}{llll}1 &amp; 0 &amp; 0 &amp; 0 \\\\ 0 &amp; 1 &amp; 0 &amp; 0 \\\\ 0 &amp; 0 &amp; 0 &amp; 1 \\\\ 0 &amp; 0 &amp; 1 &amp; 0\\end{array}\\right)=\\left|0 \\right&gt;\\left&lt; 0\\right| \\otimes \\mathbb{I}+\\left|1\\right&gt;\\left&lt;1\\right| \\otimes X\\)</li> </ul> </li> </ul>"},{"location":"qip1_2025/ch2a.html","title":"Chapter 2a: Quantum Information","text":""},{"location":"qip1_2025/ch2a.html#21-nature-of-quantum-information","title":"2.1. Nature of Quantum Information:","text":"<ul> <li>Quantum information is different from the classical information in a sense that the measurements change the state itself</li> <li>We can prepare any desired pure state, but if we receive such pure state we cannot identify it with certainty (if we dont know how to measure it)</li> <li>But also after measuring the state, we know with certainty in which state the system is (this will be useful)</li> <li>Given a unknown quantum state \\(\\left|\\psi\\right&gt;\\) there are three basic operations that we can perform:<ul> <li>Ancilla - take a second, known, quantum system \\(\\left|A\\right&gt;\\) and join it with \\(\\left|\\psi\\right&gt;\\) and treat it as a composite system \\(\\left|\\psi\\right&gt; \\otimes \\left|A\\right&gt;\\)</li> <li>Unitary - we can perform a unitary on \\(\\left|\\psi\\right&gt;\\) and obtain \\(\\left|\\psi^{\\prime}\\right&gt; = U\\left|\\psi\\right&gt;\\) - i.e. all your gates</li> <li>Measurement - we can perform a measurement on \\(\\left|\\psi\\right&gt;\\), or sub-system of it, record the outcome and retain the post-measurement state for further processing</li> </ul> </li> <li>Any quantum operation can be described as a composition of these three operations. Quite often the algorithms used to manipulate information use all of those operations and not just gates</li> </ul>"},{"location":"qip1_2025/ch2a.html#22-no-cloning-theorem","title":"2.2. No-Cloning Theorem:","text":"<ul> <li>Cloning operation of a quantum state \\(\\left|\\psi\\right&gt;\\) is defined as a map \\(\\left|\\psi\\right&gt;_A \\left|0\\right&gt;_B \\rightarrow \\left|\\psi\\right&gt;_A \\left|\\psi\\right&gt;_B\\)</li> <li>We can extend it to a larger system, by adjoining ancilla to it. In this case the cloning operations can be defined as \\(\\left|\\psi\\right&gt;_A \\left|0\\right&gt;_B \\left|M_0\\right&gt;_M \\rightarrow \\left|\\psi\\right&gt;_A \\left|\\psi\\right&gt;_B \\left|M_\\psi\\right&gt;_M\\)</li> <li>No-Cloning Theorem: Let \\(\\mathcal{S}\\) be any set of states of A that contains at least one non-orthogonal state. Then there is no unitary cloning process that achieves cloning for all states in \\(\\mathcal{S}\\).</li> <li>Remark: I am only presenting a proof of 'no-cloning theorem' for the case where the agent is only allowed to perform unitary operations. There exists an extention of this theorem for any 3 basic operations (Ancilla, Unitary, Measurement).</li> </ul>"},{"location":"qip1_2025/ch2a.html#proof","title":"Proof:","text":"<p>Let \\(\\left|\\psi\\right&gt;\\) and \\(\\left|\\phi\\right&gt;\\) be two distinct non-orthogonal states in \\(\\mathcal{S}\\). Lets assume that there exist a unitary \\(U\\) that clone the states in \\(\\mathcal{S}\\).</p> <p>then</p> \\[ U\\left|\\psi\\right&gt;_A \\left|0\\right&gt;_B \\left|M_0\\right&gt;_M = \\left|\\psi\\right&gt;_A \\left|\\psi\\right&gt;_B \\left|M_\\psi\\right&gt;_M \\] \\[ U\\left|\\phi\\right&gt;_A \\left|0\\right&gt;_B \\left|M_0\\right&gt;_M = \\left|\\phi\\right&gt;_A \\left|\\phi\\right&gt;_B \\left|M_\\phi\\right&gt;_M \\] <p>then </p> \\[ \\left&lt;M_0\\right|_M\\left&lt;0\\right|_B\\left&lt;\\psi\\right|_A U^\\dagger U\\left|\\phi\\right&gt;_A \\left|0\\right&gt;_B \\left|M_0\\right&gt;_M = \\left&lt;M_\\psi\\right|_M \\left&lt;\\psi\\right|_B \\left&lt;\\psi\\right|_A \\left|\\phi\\right&gt;_A \\left|\\phi\\right&gt;_B \\left|M_\\phi\\right&gt;_M \\] \\[ \\left&lt;M_0|M_0\\right&gt;_M\\left&lt;0|0\\right&gt;_B\\left&lt;\\psi|\\phi\\right&gt;_A = \\left&lt;M_\\psi|M_\\psi\\right&gt;_M\\left&lt;\\psi|\\phi\\right&gt;_A\\left&lt;\\psi|\\phi\\right&gt;_B \\] \\[ \\left&lt;\\psi|\\phi\\right&gt;_A = \\left&lt;M_\\psi|M_\\phi\\right&gt;_M\\left&lt;\\psi|\\phi\\right&gt;_A\\left&lt;\\psi|\\phi\\right&gt;_B \\] <p>since \\(\\left|\\psi\\right&gt;\\) and \\(\\left|\\phi\\right&gt;\\) are non-orthogonal, we can divide both sides by \\(\\left&lt;\\psi|\\phi\\right&gt;_A\\) and get:</p> \\[ 1 = |\\left&lt;M_\\psi|M_\\phi\\right&gt;_M\\left&lt;\\psi|\\phi\\right&gt;_B| \\] <ul> <li>\\(M_\\psi\\) and \\(M_\\phi\\) are quantum states: \\(|\\left&lt;M_\\psi|M_\\phi\\right&gt;_M| \\leq 1\\),  </li> <li>\\(\\left|\\psi\\right&gt;\\) and \\(\\left|\\phi\\right&gt;\\) are distinct states and so: \\(|\\left&lt;\\psi|\\phi\\right&gt;_B| &lt; 1\\)</li> <li>Therefore we arrive to a contradiction, which completes the proof</li> </ul>"},{"location":"qip1_2025/ch2a.html#herberts-method-of-superluminal-communication","title":"Herbert's method of superluminal communication:","text":"<ul> <li>The no-cloning theorem was crucial for debugging the protocol of superluminal communication proposed by Herbert. See more in Richard's Jozsa notes [4].</li> </ul>"},{"location":"qip1_2025/ch2a.html#23-quantum-teleportation","title":"2.3. Quantum Teleportation:","text":"<p>Consider that Alice and Bob share an entangled Bell state \\(\\left|\\phi^{+}\\right&gt;_{23} = \\frac{1}{\\sqrt{2}}(\\left|00\\right&gt; + \\left|11\\right&gt;)_{23}\\), such that each of them has one qubit of the pair. Additionally Alice has a qubit in a state \\(\\left|\\alpha\\right&gt;_1 = a\\left|0\\right&gt; + b \\left|1\\right&gt;\\). </p> <p>This means that the combined state of the system is:</p> \\[ \\begin{aligned} \\left|\\psi\\right&gt;_{AB} &amp;= \\left|\\alpha\\right&gt;_1 \\left|\\phi^{+}\\right&gt;_{23} = \\left(a\\left|0\\right&gt; + b\\left|1\\right&gt;\\right)_1 \\frac{1}{\\sqrt{2}}(\\left|00\\right&gt; + \\left|11\\right&gt;)_{23} \\\\ &amp; = \\frac{a}{\\sqrt{2}}\\left|000\\right&gt; + \\frac{a}{\\sqrt{2}}\\left|011\\right&gt; + \\frac{b}{\\sqrt{2}}\\left|100\\right&gt; + \\frac{b}{\\sqrt{2}}\\left|111\\right&gt; \\end{aligned} \\] <p>Task: of the quantum teleportation is to transfer the state of \\(\\left|\\alpha\\right&gt;_1\\) to \\(\\left|\\beta\\right&gt;_3\\) by performing local operations and classical communication.</p>"},{"location":"qip1_2025/ch2a.html#algorithm","title":"Algorithm:","text":"<ol> <li>Alice performs a Bell measurement on the two qubits (Performs a projective measurement in the Bell basis)     &lt;!-- 1. Alice applies CX to her qubits 1 and 2<ol> <li>Alice applies H to her qubit 1</li> <li>Alice measures her two qbits to obtain a 2-bit string 00, 01, 10 or 11 --&gt;</li> </ol> </li> <li>Alice sends a 2-bit measurement outcome ij to Bob</li> <li>On receiving ij Bob applies the unitary operation \\(Z^iX^j\\) to his qubit, which is then guaranteed to be in the state \\(\\left|\\alpha\\right&gt;_3\\)</li> </ol> <p>Remark: No information about \\(\\left|\\alpha\\right&gt;_2\\) is left with Alice</p>"},{"location":"qip1_2025/ch2a.html#why-it-works","title":"Why it works:","text":""},{"location":"qip1_2025/ch2a.html#explanation-1","title":"Explanation 1:","text":"<p>(From explanation 1 we would like to learn about how local operations on single qubits can affect the measurement outcome of the measurement of the second qubit.)</p> <p>We can write \\(\\left|\\psi\\right&gt;_{AB}\\) as:</p> \\[ \\begin{aligned} \\left|\\psi\\right&gt;_{AB} &amp;= \\frac{a}{\\sqrt{2}}\\left|000\\right&gt;_{123} + \\frac{a}{\\sqrt{2}}\\left|011\\right&gt;_{123} + \\frac{b}{\\sqrt{2}}\\left|100\\right&gt;_{123} + \\frac{b}{\\sqrt{2}}\\left|111\\right&gt;_{123}\\\\ &amp;= \\frac{a}{2}\\left(\\left|\\psi_{00}\\right&gt;_{12} + \\left|\\psi_{01}\\right&gt;_{12}\\right)\\left|0\\right&gt;_{3} + \\frac{a}{2}\\left(\\left|\\psi_{10}\\right&gt;_{12} + \\left|\\psi_{11}\\right&gt;_{12}\\right)\\left|1\\right&gt;_{3} + \\frac{b}{2}\\left(\\left|\\psi_{10}\\right&gt;_{12} - \\left|\\psi_{11}\\right&gt;_{12}\\right)\\left|0\\right&gt;_{3} + \\frac{b}{2}\\left(\\left|\\psi_{00}\\right&gt;_{12} - \\left|\\psi_{01}\\right&gt;_{12}\\right)\\left|1\\right&gt;_{3} \\\\ &amp;= \\left|\\psi_{00}\\right&gt;_{12}\\left(\\frac{a}{2}\\left|0\\right&gt;_{3} + \\frac{b}{2}\\left|1\\right&gt;_{3}\\right) + \\left|\\psi_{01}\\right&gt;_{12}\\left(\\frac{a}{2}\\left|0\\right&gt;_{3} - \\frac{b}{2}\\left|1\\right&gt;_{3}\\right) + \\left|\\psi_{10}\\right&gt;_{12}\\left(\\frac{a}{2}\\left|1\\right&gt;_{3} + \\frac{b}{2}\\left|0\\right&gt;_{3}\\right) + \\left|\\psi_{11}\\right&gt;_{12}\\left(\\frac{a}{2}\\left|1\\right&gt;_{3} - \\frac{b}{2}\\left|0\\right&gt;_{3}\\right)\\\\ \\end{aligned} \\] <p>Therefore when we measure in which bell state the first two qubits are then we get the following post-measurement states:</p> \\[ \\begin{array}{cc} \\text { mmt outcome } &amp; \\text { post-mmt state } \\\\ 00 &amp; \\left|00\\right&gt;_{12}\\left|\\alpha\\right&gt;_3 \\\\ 01 &amp; \\left|01\\right&gt;_{12}X\\left|\\alpha\\right&gt;_3 \\\\ 10 &amp; \\left|10\\right&gt;_{12}Z\\left|\\alpha\\right&gt;_3 \\\\ 11 &amp; \\left|11\\right&gt;_{12}XZ\\left|\\alpha\\right&gt;_3 \\end{array} \\] <p>Therefore knowing the outcome of the measurement Alice can send a 2-bit string to Bob, who then applies the corresponding operation to his qubit and recovers the state \\(\\left|\\alpha\\right&gt;_3\\)</p>"},{"location":"qip1_2025/ch2a.html#explanation-2","title":"Explanation 2:","text":"<p>(From this explanation we would like to learn how to perform an operation that depends on the measurement outcome.)</p> <p>What I would like to do here is to provide slightly different explanation. I don't like Explanation 1 because it feels very brute forcy, and it doesn't provide any additional intuition about why things are, like they are. The following explanation is perhaps slightly more tricky to grasp, but I think it provides more insight.</p> <p>E.2.1.</p> <p>I would like to start with a simple observation. When we project the first two qubits into the state \\(\\left|\\psi_{00}\\right&gt;_{12}\\) then we get:</p> \\[ \\left&lt;\\psi_{00}\\right|_{12}\\left|\\alpha\\right&gt;_1\\left|\\psi_{00}\\right&gt;_{23} = \\left|\\alpha\\right&gt;_3 \\] <p>One might then ask is it true for more general case? Is this statement true for any state \\(\\left|\\psi_{ij}\\right&gt;_{23}\\):</p> \\[ \\left&lt;\\psi_{ij}\\right|_{12}\\left|\\alpha\\right&gt;_1\\left|\\psi_{ij}\\right&gt;_{23} \\stackrel{?}{=} \\left|\\alpha\\right&gt;_3 \\] <p>This must be true as we can write </p> \\[ \\left&lt;\\psi_{ij}\\right|_{12}\\left|\\alpha\\right&gt;_1\\left|\\psi_{ij}\\right&gt;_{23} = \\left(\\left&lt;\\psi_{00}\\right|_{12} X_2^j Z_2^i\\right)\\left|\\alpha\\right&gt;_1\\left(Z_2^i X_2^j\\left|\\psi_{00}\\right&gt;_{23}\\right) = \\left&lt;\\psi_{00}\\right|_{12}\\left|\\alpha\\right&gt;_1\\left|\\psi_{00}\\right&gt;_{23}= \\left|\\alpha\\right&gt;_3 \\] <p>Wow! This means that quantum teleportation is trivial. If we could perform a projection operation on the first two qubits onto the bell state in which we prepared the pair of second and third qubit, we would simply teleport the state from a qubit 1 to a qubit 3. However, the projection operation is non-unitary and we cannot do it in a unitary way. We need to find workaround. </p> <p>Something that performs a projection operation on the first two qubits is the Bell measurement. This will, however, perform a projective measurement to an arbitrary state and not just the \\(\\left|\\psi_{00}\\right&gt;_{12}\\). The measurement projects the first two qubits into {\\(\\left|\\psi_{00}\\right&gt;_{12}\\), \\(\\left|\\psi_{01}\\right&gt;_{12}\\), \\(\\left|\\psi_{10}\\right&gt;_{12}\\), \\(\\left|\\psi_{11}\\right&gt;_{12}\\)}. Can we somehow know into which state it will project and perform a corresponding operation on the third qubit prior to the measurement?</p> <p>We know it after the measurement, but not before. Before the measurement we cannot know the state into which the measurement will project us (no hidden-variables :)). </p> <p>E.2.2.</p> <p>And here comes the step two: perhaps it doesn't really matter whether we do the operation on the third qubit prior to the measurement or after the measurement. And this I am showing below.</p> \\[ \\left( \\left&lt;\\psi_{ij}\\right|_{12} \\otimes \\mathbb{I}_3\\right) \\left( \\mathbb{I}_{12} \\otimes X_3^i Z_3^j\\right) \\left|\\psi\\right&gt;_{AB} = \\left( \\mathbb{I}_{12} \\otimes X_3^i Z_3^j\\right) \\left( \\left&lt;\\psi_{ij}\\right|_{12} \\otimes \\mathbb{I}_3\\right) \\left|\\psi\\right&gt;_{AB}  = \\left|\\alpha\\right&gt;_3 \\] <p>Et voil\u00e0! It doesn't matter. This is great news, because after the measurement we know into which state we projected the Bell basis. And if we then can perform the unitaries on the qubit 3, we can achieve the same result as if we did it before the measurement.</p> <p>E.2.3.</p> <p>This completes the explanation. What I want to show with this explanation, that you can try to think how to build non-unitary operations on your quantum system if you include the measurement and ancilla as part of your allowed operations. This can quite often suprise you.</p> <p>Feedback: The explanation was coined by me through talking to others and thinking. I haven't seen it anywhere else, so I would love to refine it if you have any ideas how to improve the clarity of the delivery wadamczyk@phys.ethz.ch.</p>"},{"location":"qip1_2025/organisation.html","title":"Organisation","text":""},{"location":"qip1_2025/organisation.html#group-chat","title":"Group Chat:","text":"<p>In case of any queries and feedback, don't hesitate to contact me (wadamczyk@phys.ethz.ch)</p>"},{"location":"qip1_2025/organisation.html#resources","title":"Resources:","text":"<p>Which I used to write my notes - There is a lot of re-writing and paraphrasing, which I havent cited next to the sentence (the nature of notes)</p> <ul> <li>Principles of Quantum Mechanics (David Skinner) [1]</li> <li>Quantum Information Processing (J.P.Home) [2]</li> <li>Quantum Information and Computation (Richard Jozsa) [3]</li> <li>Foundations of Computer Science (Anil Madhavapeddy, Jonathan Ludlam) [4]</li> <li>Quantum Information (C.H.W. Barnes) [5]</li> </ul>"},{"location":"random_walk/atomic_physics/cheat_sheet.html","title":"Cheat sheet","text":"<ul> <li>saturation parameter: \\(s = \\frac{2 \\Omega^2}{\\Gamma^2} = \\frac{I}{I_{sat}}\\)</li> <li>\\(\\Omega_{\\mathrm{eff}}=\\frac{\\Omega_{2 i} \\Omega_{i 1}}{2 \\Delta}\\)</li> </ul> <p>\\(\\Omega_{\\mathrm{eff}}=\\frac{\\Omega_{2 i} \\Omega_{i 1}}{2 \\Delta_b} = \\sqrt{\\frac{s_1\\Gamma_1^2}{2}}\\sqrt{\\frac{s_2\\Gamma_2^2}{2}}\\frac{1}{2\\Delta_b}\\)</p>"},{"location":"random_walk/classical_optics/aberations/aberations_propagator.html","title":"Aberations as a function of Amplitude and Phase Mask:","text":""},{"location":"random_walk/classical_optics/aberations/aberations_propagator.html#0-introduction","title":"0. Introduction","text":"<ul> <li>In optical systems, aberrations are deviations from the ideal behavior of light propagation through lenses or other optical elements. These aberrations depend on various factors, including the position and angle at which a beam enters an optical component.</li> <li>Traditionally, we consider how the position and angle of incidence affect aberrations in a single lens, however in the context of holography it is insightfull to rephrase the problem in terms of phase and amplitude field just before the lens and ask how those affect the abberation map. </li> </ul>"},{"location":"random_walk/classical_optics/aberations/aberations_propagator.html#1-single-surface-lens","title":"1. Single Surface Lens:","text":"<p>To gain intuition about aberrations, lets follow the analysis from the Physics III notes by Jonathan Home @ ETH Zurich. Consider a collimated beam hitting a single-surface lens perpendicularly to the lens normal.</p> <p> </p> <p>The total optical path taken for the ray starting at hieght h is:</p> \\[ n_1 g(h)+n_2\\left(h^2+(f-g(h))^2\\right)^{1 / 2} \\] <p>To ensure constructive interference for all rays (regardless of h), we need to find the stationary points of the optical path length with repsect to h. </p> \\[ n_1 g^{\\prime}(h)+\\frac{n_2\\left(2 h-2(f-g(h)) g^{\\prime}(h)\\right)}{2\\left(h^2+(f-g(h))^2\\right)^{1 / 2}}=0 \\] <p>Solutions to this equations are not simple, and as a result it is very tricky to manufacture perfect shape. Therefore, we often use spherical lenses, which are easier to produce but introduce imperfections.</p> <p>For a spherical lens, the surface profile is:</p> \\[ g(h)=R-\\sqrt{\\left(R^2-h^2\\right)} \\approx \\frac{h^2}{2 R}+O\\left[h^4\\right] \\] <p>The focal length \\(f\\) for this lens is:</p> \\[ f=\\frac{R}{\\left(1-\\frac{n_1}{n_2}\\right)} \\] <p>However, spherical lenses introduce spherical aberration because the optical path difference is not perfectly corrected. The extra phase acquired by a beam entering at height \\(h\\) is approximately:</p> \\[ \\frac{n_2+\\frac{2 n_2^2}{n_1-n_2}+\\frac{\\left(n_1-n_2\\right)\\left(n_2-n_1\\right)^3}{n_2^2}}{8} \\frac{h^3}{f^3} h \\] <p>This analysis assumes a plane wave entering with a flat phase front. To understand the imperfections introduced when the phase front isn't flat, we would need to perform a similar analysis for each possible phase mask \u2014 a complex and challenging problem.</p>"},{"location":"random_walk/classical_optics/aberations/aberations_propagator.html#2-the-wave-equation-and-concept-of-propagators","title":"2. The Wave Equation and concept of propagators:","text":"<p>Electromagnetic field can be modelled as a complex field \\(U(x, y, z)\\) that follows Helmholz equation \\(\\nabla^2 U(\\boldsymbol{r})=-\\frac{\\omega^2}{v^2} U(\\boldsymbol{r})\\).</p> <p>We can transform \\(U\\) into Fourier space:</p> \\[ \\begin{aligned} \\tilde{U}\\left(k_x, k_y ; z\\right) &amp; =\\frac{1}{2 \\pi} \\int_{-\\infty}^{\\infty} \\int_{-\\infty}^{\\infty} U(x, y, z) \\exp \\left[-\\mathrm{i}\\left(k_x x+k_y y\\right)\\right] \\mathrm{d} x \\mathrm{~d} y  \\end{aligned} \\] <p>, where the Helmholz equation would takes form</p> \\[ \\frac{d^2 \\tilde{U}}{d z^2}+\\left(k^2-k_x^2-k_y^2\\right) \\tilde{U}\\left(k_x, k_y ; z\\right)=0 \\] <p>The solution is:</p> \\[ \\tilde{U}\\left(k_x, k_y ; z\\right)=\\tilde{U}\\left(k_x, k_y ; 0\\right) \\exp \\left(\\mathrm{i} \\sqrt{k^2-k_x^2-k_y^2} z\\right)=\\tilde{U}\\left(k_x, k_y ; 0\\right) \\mathcal{H}\\left(k_x, k_y, z\\right) \\] <p>, where \\(\\mathcal{H}\\left(k_x, k_y, z\\right)\\) is a Helmholz propagator.</p> <p>Propagators:</p> <p>Using Green's theorem and the Fresnel-Kirchhoff diffraction formula, we can relate the field at any plane \\(z=z_0\\) to a field at \\(z=0\\) thrugh a propagator \\(\\tau(x,y,z_0,x',y',0)\\). Then we can write that </p> \\[U(x, y, z_0) = \\int\\int dx' dy' \\left(\\tau(x,y,z_0,x',y',0) U(x, y, 0) \\right) \\] <p>In free space, it's advantageous to work in Fourier space due to the linearity of the equations, which reduces computational complexity.</p> <p>When introducing a phase mask, multiplication in real space corresponds to convolution in Fourier space. This means the operation is linear in real space but becomes more intricate in Fourier space.</p> <p>In general, the transformation can be expressed using the propagator \\(\\tau(x,y,z,x',y',z')\\). </p>"},{"location":"random_walk/classical_optics/aberations/aberations_propagator.html#3-representing-field-as-a-matrix","title":"3. Representing field as a matrix:","text":"<p>To facilitate numerical computations, we can discretize the field and represent it as a matrix. The field becomes a rank-2 tensor \\(U_{nm}\\), and the propagator becomes a rank-4 tensor \\(\\tau_{klnm}\\). The relationship between the fields at different planes is:</p> \\[ U_{kl} = \\tau_{klnm} U_{nm} \\] <p>We can define aberrations \\(\\tau^{\\Delta}_{klnm}\\), as a difference in the actual propagator, \\(\\tau_{klnm}\\), and the ideal (aberation-free) propagator, \\(\\tau^0_{klnm}\\).</p> \\[ \\tau^{\\Delta}_{klnm} = \\tau_{klnm} - \\tau^0_{klnm} \\]"},{"location":"random_walk/classical_optics/aberations/aberations_propagator.html#4-can-we-do-not-wavefront-calibration-but-rather-propagator-calibration","title":"4. Can we do not wavefront calibration, but rather propagator calibration?","text":"<p>Why was I thinking about this in the first place is my interest in the paper 'Rapid stochastic spatial light modulator calibration and pixel crosstalk optimisation'. I was wondering whether instead of learning the wavefront mask, we could learn the whole propagator. </p>"},{"location":"random_walk/classical_optics/aberations/aberations_propagator.html#reversible-neural-network","title":"Reversible Neural Network","text":""},{"location":"random_walk/quantum_optics/rabi_frequencies.html","title":"Light-Matter Interaction","text":""},{"location":"random_walk/quantum_optics/rabi_frequencies.html#rabi-frequencies","title":"Rabi Frequencies","text":"<p>Rabi Frequency is the fundamental quantity regarding interaction of an atom with light. It tells us about how much coupling do we get between two eigenstates of our atom in the presence of the oscilating electric field.</p> <p>Given the complexities and the confusion surrounding the derivations of dipole and quadrupole Rabi frequencies, a re-derivation is presented here. In this derivation we stay in a single gauge throughout. This derivation draws from Weissbluth book.</p>"},{"location":"random_walk/quantum_optics/rabi_frequencies.html#minimum-coupling-hamiltonian","title":"Minimum Coupling Hamiltonian","text":"<p>Consider an arbitrary electromagnetic vector field, \\(\\mathbf{A}(\\mathbf{r},t)\\), within the Coulomb gauge (\\(\\nabla \\cdot \\mathbf{A}(\\mathbf{r}) = 0\\)) in vacuum (\\(\\phi(\\mathbf{r}, t)=0\\)). Throughout the derivation we will assume that the field is small enough so that we can treat it as a perturbation.</p> <p>The minimum-coupling Hamiltonian in Coulomb's gauge is expressed as:</p> \\[  H=\\sum_\\alpha\\left(\\frac{\\left[\\mathbf{p}^{(\\alpha)}-q^{(\\alpha)} \\mathbf{A}\\left(\\mathbf{x}^{(\\alpha)}, t\\right)\\right]^2}{2 m^{(\\alpha)}}\\right)+H_F+V_{\\text{Coul}}  +\\frac{e \\hbar}{2 m c} \\boldsymbol{\\sigma} \\cdot \\boldsymbol{\\nabla} \\times \\mathbf{A} \\] <p>where \\(H_F\\) represents the free field energy (\\(H_F=\\frac{1}{2} \\int \\mathrm{d}^3 r\\left(\\epsilon_0 \\mathbf{E}^2(\\mathbf{r}, t)+\\frac{1}{\\mu_0} \\mathbf{B}^2(\\mathbf{r}, t)\\right)\\)) and \\(V_{\\text{Coul}}\\) contains terms defining the atomic state, including Coulomb interactions and spin-orbit coupling.</p> <p>Focusing on electron dynamics rather than absolute energy levels allows us to neglect constant energy terms \\(H_F\\) and \\(\\varepsilon_{\\text{Coul}}^\\alpha\\), keeping only the terms that depend on \\(\\mathbf{x}_\\alpha\\) or \\(\\mathbf{p}_\\alpha\\). Coulomb's Gauge \\(\\nabla \\cdot \\mathbf{A}(\\mathbf{r}) = 0\\) ensures that \\(\\mathbf{p}_\\alpha\\) and \\(\\mathbf{A}(\\mathbf{x}_\\alpha, t)\\) commute, so we can rewrite \\({H}\\) as:</p> \\[ \\begin{aligned} H &amp;=\\sum_\\alpha\\left(\\frac{\\left[\\mathbf{p}^{(\\alpha)}-q^{(\\alpha)} \\mathbf{A}\\left(\\mathbf{x}^{(\\alpha)}, t\\right)\\right]^2}{2 m^{(\\alpha)}}\\right)+V_{\\text {Coul }} + \\frac{e \\hbar}{2 m c} \\boldsymbol{\\sigma} \\cdot \\boldsymbol{\\nabla} \\times \\mathbf{A} \\\\&amp;=\\sum_\\alpha \\frac{\\mathbf{p^{(\\alpha)}}^2}{2 m^{(\\alpha)}}+V_{\\text {Coul }}+\\sum_\\alpha\\left(-\\frac{q^{(\\alpha)} \\mathbf{p}^{(\\alpha)} \\cdot \\mathbf{A}\\left(\\mathbf{x}^{(\\alpha)}, t\\right)}{m^{(\\alpha)}}+\\frac{{q^{(\\alpha)}}^2\\mathbf{A}\\left(\\mathbf{x}^{(\\alpha)}, t\\right)^2}{2 m^{(\\alpha)}}\\right) +  \\frac{e \\hbar}{2 m c} \\boldsymbol{\\sigma} \\cdot \\boldsymbol{\\nabla} \\times \\mathbf{A} \\end{aligned} \\] <p>Neglecting less dominant terms of the interaction Hamiltonian \\(\\frac{q_\\alpha^2\\mathbf{A}\\left(\\mathbf{x}_\\alpha, t\\right)^2}{2 m_\\alpha}\\) and \\(\\frac{e \\hbar}{2 m c} \\boldsymbol{\\sigma} \\cdot \\boldsymbol{\\nabla} \\times \\mathbf{A}\\), and grouping them together we get:</p> \\[  \\begin{aligned} &amp;H = H_0 + H_I \\\\ &amp;H_0 = \\sum_\\alpha \\frac{\\mathbf{p^{(\\alpha)}}^2}{2 m^{(\\alpha)}}+V_{\\text {Coul }} = \\sum_i \\mathcal{E}_i\\left|i\\right&gt;\\left&lt; i\\right| \\\\ &amp;H_I = \\sum_\\alpha-q^{(\\alpha)} \\mathbf{\\dot{x}}^{(\\alpha)} \\cdot \\mathbf{A}\\left(\\mathbf{x}^{(\\alpha)}, t\\right) \\end{aligned} \\] <p>\\(\\mathbf{x} = \\mathbf{R} + \\mathbf{r}\\), where \\(\\mathbf{R}\\) is a postion of the nucleus and \\(\\mathbf{r}\\) is position of an electron relative to the nucleus. Using Born-Oppenheimer approximation we can write \\(\\mathbf{\\dot{x}} = \\mathbf{\\dot{r}}\\) neglecting \\(\\mathbf{\\dot{R}}\\).</p> \\[ H_I = \\sum_\\alpha-q_\\alpha \\mathbf{\\dot{r}}_\\alpha \\cdot \\mathbf{A}\\left(\\mathbf{R}+\\mathbf{r}_\\alpha, t\\right) \\]"},{"location":"random_walk/quantum_optics/rabi_frequencies.html#multipole-expansion","title":"Multipole expansion","text":"<p>Taylor expanding \\(\\mathbf{A}(\\mathbf{R}+\\mathbf{r}_\\alpha, t)\\), we get:</p> \\[ H_I = \\sum_\\alpha-q_\\alpha \\dot{r}^{(\\alpha)}_{\\mu} \\left(A^\\mu\\left(\\mathbf{R}, t\\right) + \\partial^\\nu A^\\mu\\left(\\mathbf{R}, t\\right)r^{(\\alpha)}_{\\nu} \\right) \\] <p>From now on, Lets define \\(A^\\mu = A^\\mu(\\mathbf{R}, t)\\) </p> \\[ \\begin{aligned} H_I &amp;= \\sum_{\\alpha, i, j} |i\\rangle\\left\\langle i\\left|e \\dot{r}^{(\\alpha)}_{\\mu} \\left(A^\\mu + \\partial^\\nu A^\\mu r^{(\\alpha)}_{\\nu} + ...\\right) \\right| j\\right\\rangle\\langle j| \\\\ &amp;= \\sum_{\\alpha, i, j} \\left( |i\\rangle\\left\\langle i\\left|e \\dot{r}^{(\\alpha)}_{\\mu} A^\\mu\\right| j\\right\\rangle\\langle j| + |i\\rangle\\left\\langle i\\left|e \\dot{r}^{(\\alpha)}_{\\mu} \\partial^\\nu A^\\mu r^{(\\alpha)}_{\\nu} \\right| j\\right\\rangle\\langle j| + ... \\right) \\\\ &amp;= \\sum_{\\alpha, i, j} \\left( e A^\\mu|i\\rangle\\left\\langle i\\left| \\dot{r}^{(\\alpha)}_{\\mu} \\right| j\\right\\rangle\\langle j| + e\\partial^\\nu A^\\mu |i\\rangle\\left\\langle i\\left| \\dot{r}^{(\\alpha)}_{\\mu}  r^{(\\alpha)}_{\\nu} \\right| j\\right\\rangle\\langle j| + ... \\right) \\end{aligned} \\] <p>As in the end we would like to see how the light field interacts with consecutive terms of the multipole expansion formed by the atom, we need to get rid of \\(\\dot{r}_\\mu^{(\\alpha)}\\).</p> <p>As \\(\\left[ r_\\mu, p^2 \\right] = 2i \\hbar p_\\mu\\), then \\(i \\hbar \\dot{r}_\\mu=\\left[r_\\mu, H_0\\right]\\)</p> <p>Lets then solve consecutive terms of the Taylor expansion</p>"},{"location":"random_walk/quantum_optics/rabi_frequencies.html#0th-order-term","title":"0th Order term:","text":"\\[ \\begin{aligned} \\left\\langle i\\left| \\dot{r}^{(\\alpha)}_{\\mu} \\right| j\\right\\rangle &amp;= -\\frac{i}{\\hbar} \\left\\langle i\\left| [r^{(\\alpha)}_{\\mu}, H_0] \\right| j\\right\\rangle   \\\\&amp;= -\\frac{i}{\\hbar} \\left\\langle i\\left|r^{(\\alpha)}_{\\mu} H_0 - H_0 r^{(\\alpha)}_{\\mu} \\right| j\\right\\rangle  \\\\&amp;= -i \\left\\langle i\\left|r^{(\\alpha)}_{\\mu} \\omega_j - \\omega_i r^{(\\alpha)}_{\\mu} \\right| j\\right\\rangle  \\\\&amp;= i \\omega_{0} \\left\\langle i\\left| r^{(\\alpha)}_{\\mu} \\right| j\\right\\rangle \\end{aligned} \\] <p>, where \\(\\omega_{0} = \\omega_i-\\omega_j\\)</p>"},{"location":"random_walk/quantum_optics/rabi_frequencies.html#1st-order-term","title":"1st Order term:","text":"\\[ \\begin{aligned} \\left\\langle i\\left| \\dot{r}^{(\\alpha)}_{\\mu}  r^{(\\alpha)}_{\\nu} \\right| j\\right\\rangle  &amp;= -\\frac{i}{\\hbar}\\left\\langle i\\left| [r^{(\\alpha)}_{\\mu}, H_0]  r^{(\\alpha)}_{\\nu} \\right| j\\right\\rangle  \\\\&amp;=-\\frac{i}{\\hbar}\\left\\langle i\\left| r^{(\\alpha)}_{\\mu}H_0r_\\nu^{(\\alpha)} - H_0r^{(\\alpha)}_{\\mu}  r^{(\\alpha)}_{\\nu} \\right| j\\right\\rangle \\end{aligned} \\] <p>This is more tricky, because now we need to to commute \\(H_0\\) with \\(r_\\nu^{(\\alpha)}\\) which as a result would give us \\(\\dot{r}^{(\\alpha)}_{\\mu}\\) again. Instead what we can do we can split the problem into symmetric and anti-symmetric part hoping it will get easier. </p> \\[ \\left\\langle i\\left| \\dot{r}^{(\\alpha)}_{\\mu}  r^{(\\alpha)}_{\\nu} \\right| j\\right\\rangle = \\frac{1}{2}\\left\\langle i\\left| \\dot{r}^{(\\alpha)}_{\\mu}  r^{(\\alpha)}_{\\nu} +   r^{(\\alpha)}_{\\nu} \\dot{r}^{(\\alpha)}_{\\mu} \\right| j\\right\\rangle + \\frac{1}{2}\\left\\langle i\\left| \\dot{r}^{(\\alpha)}_{\\mu}  r^{(\\alpha)}_{\\nu} -   r^{(\\alpha)}_{\\nu} \\dot{r}^{(\\alpha)}_{\\mu} \\right| j\\right\\rangle \\] <p>Lets solve the symmetric and antisymmetric part separately:</p> <p>Symmetric part:</p> \\[ \\begin{aligned} \\frac{1}{2}\\left\\langle i\\left| \\dot{r}^{(\\alpha)}_{\\mu}  r^{(\\alpha)}_{\\nu} +   r^{(\\alpha)}_{\\nu} \\dot{r}^{(\\alpha)}_{\\mu} \\right| j\\right\\rangle &amp;=  \\frac{-i}{2\\hbar}\\left\\langle i\\left| [r^{(\\alpha)}_{\\mu}, H_0]  r^{(\\alpha)}_{\\nu} +   r^{(\\alpha)}_{\\nu} [r^{(\\alpha)}_{\\mu}, H_0] \\right| j\\right\\rangle \\\\&amp;=  \\frac{-i}{2\\hbar}\\left\\langle i\\left| -H_0r^{(\\alpha)}_{\\mu}  r^{(\\alpha)}_{\\nu} +   r^{(\\alpha)}_{\\nu} r^{(\\alpha)}_{\\mu}H_0 \\right| j\\right\\rangle \\\\&amp;=  \\frac{1}{2}i\\omega_{0}\\left\\langle i\\left| r^{(\\alpha)}_{\\mu}  r^{(\\alpha)}_{\\nu}  \\right| j\\right\\rangle \\end{aligned} \\] <p>Anti-symmetric part:</p> \\[ \\begin{aligned} \\frac{1}{2} \\partial^\\nu A^\\mu \\left\\langle i\\left| \\dot{r}^{(\\alpha)}_{\\mu}  r^{(\\alpha)}_{\\nu} -   r^{(\\alpha)}_{\\nu} \\dot{r}^{(\\alpha)}_{\\mu} \\right| j\\right\\rangle &amp;= \\frac{1}{2} \\varepsilon^{i \\mu \\nu}\\varepsilon_{i}^{j k} \\partial_j A_k \\left\\langle i\\left| \\dot{r}^{(\\alpha)}_{\\mu}  r^{(\\alpha)}_{\\nu} \\right| j\\right\\rangle \\\\&amp;=  \\frac{1}{2} \\varepsilon_{i}^{j k} \\partial_j A_k \\left\\langle i\\left| \\varepsilon^{i \\mu \\nu}\\dot{r}^{(\\alpha)}_{\\mu}  r^{(\\alpha)}_{\\nu} \\right| j\\right\\rangle \\\\&amp;=  \\frac{1}{2} \\hbar \\varepsilon_{i}^{j k} \\partial_j A_k \\left\\langle i\\left| L^i \\right| j\\right\\rangle \\end{aligned} \\] <p>Therefore one can re-write 1st Order term as:</p> \\[ \\begin{aligned} e \\partial^\\nu A^\\mu\\left\\langle i\\left| \\dot{r}^{(\\alpha)}_{\\mu}  r^{(\\alpha)}_{\\nu} \\right| j\\right\\rangle = \\frac{1}{2} ie\\omega_0 \\partial^\\nu A^\\mu \\left\\langle i\\left| r^{(\\alpha)}_{\\mu}  r^{(\\alpha)}_{\\nu}  \\right| j\\right\\rangle + \\frac{1}{2} \\hbar e \\varepsilon_{i}^{j k} \\partial_j A_k \\left\\langle i\\left| L^i \\right| j\\right\\rangle \\end{aligned} \\] <p>, where the first term corresponds to the electric quadrupole coupling and the second term corresponds to magnetic dipole coupling</p> <p>Collecting all the terms up to the 1st Order of Taylor expansion of \\(A_\\mu\\), we get:</p> \\[ H_I =  \\sum_{\\alpha, i, j} |i\\rangle\\left( \\underbrace{i e \\omega_{0} A^\\mu\\left\\langle i\\left| r^{(\\alpha)}_{\\mu} \\right| j\\right\\rangle }_\\text{Electric Dipole} +  \\underbrace{\\frac{1}{2} ie\\omega_0 \\partial^\\nu A^\\mu \\left\\langle i\\left| r^{(\\alpha)}_{\\mu}  r^{(\\alpha)}_{\\nu}  \\right| j\\right\\rangle}_\\text{Electric Quadrupole} + \\underbrace{\\frac{1}{2} \\hbar e \\varepsilon_{i}^{j k} \\partial_j A_k \\left\\langle i\\left| L^i \\right| j\\right\\rangle}_\\text{Magnetic Dipole} + ... \\right) \\langle j| \\]"},{"location":"random_walk/quantum_optics/rabi_frequencies.html#constraining-a-vector-field","title":"Constraining A-vector field:","text":"<p>Let's constrain our choice of \\(\\mathbf{A}\\) vector-field. In the end what we are interested in is an electric field \\(\\mathbf{E}\\) oscilating at single frequency \\(\\omega\\). As the electric field is an observable, it must be real, and so \\(\\tilde{E}(\\mathbf{x}, -\\omega)\\) =  \\(\\tilde{E}^\\dagger(\\mathbf{x}, \\omega)\\), and so it can be written as: \\(\\mathbf{E}=\\frac{1}{2}\\left(\\mathbf{E}(\\mathbf{x})e^{-i\\omega_lt}+\\mathbf{E}^{\\dagger}(\\mathbf{x})e^{i\\omega_lt}\\right)\\). </p> <p>Working in vacuum in Coulombs gauge we can write \\(\\mathbf{E} = -\\frac{\\partial \\mathbf{A}}{\\partial t}\\), hence</p> \\[ \\mathbf{A} =\\frac{1}{2}\\left(\\left(\\frac{1}{i\\omega_l}\\mathbf{E}(\\mathbf{x})\\right)e^{-i\\omega_lt} + \\left(\\frac{1}{i\\omega_l}\\mathbf{E}(\\mathbf{x})\\right)^{\\dagger}e^{i\\omega_lt}\\right) = \\frac{1}{2}\\left(\\mathbf{A}(\\mathbf{x})e^{-i\\omega_lt} + \\mathbf{A}^{\\dagger}(\\mathbf{x})e^{i\\omega_lt}\\right) \\] <p>The interaction then can be written as:</p> \\[ \\begin{aligned} H_I &amp;= \\sum_{\\alpha, i, j} \\left|i\\right&gt; \\left&lt; i\\left|e \\mathbf{\\dot{r}}^{(\\alpha)} \\mathbf{A} \\right| j\\right&gt; \\left&lt; j\\right| \\\\ &amp;= \\sum_{\\alpha, i, j} \\left|i\\right&gt; \\frac{1}{2} \\left( \\left&lt; i\\left|e \\mathbf{\\dot{r}}^{(\\alpha)} \\mathbf{A}(\\mathbf{x}) \\right| j\\right&gt; e^{-i\\omega_lt} + \\left&lt; i\\left|e \\mathbf{\\dot{r}}^{(\\alpha)} \\mathbf{A}^{\\dagger}(\\mathbf{x}) \\right| j\\right&gt; e^{i\\omega_lt} \\right) \\left&lt; j \\right| \\\\ &amp;= \\sum_{\\alpha, i, j} \\left|i\\right&gt; \\frac{\\hbar}{2} \\left(\\Omega_{ij} e^{-i\\omega_lt} + \\Omega^\\dagger_{ij} e^{i\\omega_lt} \\right) \\left&lt; j\\right|  \\end{aligned} \\] <p>, where Rabi Frequency is defined as follows:</p> \\[ \\hbar\\Omega_{i j}= \\left&lt; i\\left|e \\mathbf{\\dot{r}}^{(\\alpha)} \\mathbf{A}(\\mathbf{x}) \\right| j\\right&gt; \\] <p>As we saw, we can decompose it through the Taylor expansion into the consecutive terms corresponding to different nature of the transition. Usually only one of the coupling types is dominant and the other can be neglected. The dominant type depends on the nature of the transition and the electric field structure.</p> <p>\\(\\Omega_{i j}= \\begin{cases} \\frac{e\\omega_{0}}{\\hbar\\omega_l}E^\\mu\\left\\langle i\\left| r^{(\\alpha)}_{\\mu} \\right| j\\right\\rangle &amp; (\\mathrm{E1}) \\\\  \\frac{e\\omega_0}{2\\hbar\\omega_l} \\partial^\\nu E^\\mu \\left\\langle i\\left| r^{(\\alpha)}_{\\mu}  r^{(\\alpha)}_{\\nu}  \\right| j\\right\\rangle &amp; (\\mathrm{E2})\\\\ \\frac{1}{2} e \\varepsilon_{\\theta}^{\\beta \\gamma} \\partial_\\beta A_\\gamma \\left\\langle i\\left| L^\\theta \\right| j\\right\\rangle &amp; (\\mathrm{M1})\\\\ \\end{cases}\\)</p>"},{"location":"random_walk/quantum_optics/rabi_frequencies.html#final-remarks","title":"Final Remarks:","text":"<p>This is the final expression of the Rabi-frequencies. As far as we are interested in only electric multipole expansion we took all required terms from the dirac equation. We worked in vacuum and in Coulomb gauge. Not switching the gauge allowed us to not to make any mistakes that arise from working in multiple gauges. </p> <p>Other common derivation is using PZW Gauge, which naturally has a form of multipole expansion. I, however, prefered not to work in it, as from what I have seen it wasn't a popular choice of understanding the problem. Coulomb's gauge was a preffered choice, however for many they missed a step to split the first Taylor expansion term into symmetric and antisymmetric part, which forced them to fudge a factor of 1/2. </p> <p>It is important to note that the above derivation is valid for the cases when the interaction is weak, and so the perturbation theory is applicable. This is because \\(i \\hbar \\dot{r}_\\mu=\\left[r_\\mu, H_0\\right]\\) uses this assumption. </p>"}]}