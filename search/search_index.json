{"config":{"lang":["en"],"separator":"[\\s\\-]+","pipeline":["stopWordFilter"]},"docs":[{"location":"index.html","title":"Abstract","text":"<p>Thoughts are fleeting, and to keep them from slipping away, the author attempted to capture them in writing. Both silly and more serious thoughts were recorded. It became apparent that, while writing, the author gained a slightly better understanding of the topics at hand. Whether readers find it enjoyable remains to be seen.</p>"},{"location":"qip1/ch0.html","title":"Chapter 0: Introduction","text":"<p>My plan is to share my edited notes that I made whilst preparing for the teaching. I am doing it mainly in order to make sure I understand the topics, and motivate myself to be clear with explanations. I hope to give different intuition, which perhaps will be useful to some. </p> <p>In case of any queries and feedback, don't hesitate to contact me (wadamczyk@phys.ethz.ch)</p> <p>Resources: Which I used to write my notes - There is a lot of re-writing and paraphrasing, which I havent cited next to the sentence (the nature of notes)</p> <ul> <li>Principles of Quantum Mechanics (David Skinner) [1]</li> <li>Quantum Information Processing (J.P.Home) [2]</li> <li>Quantum Information and Computation (Richard Jozsa) [3]</li> <li>Foundations of Computer Science (Anil Madhavapeddy, Jonathan Ludlam) [4]</li> <li>Quantum Information (C.H.W. Barnes) [5]</li> </ul>"},{"location":"qip1/ch0.html#chapter-0-introduction","title":"Chapter 0: Introduction","text":"<p>Computation is about manipulation of information. Mathematically we can ponder on the different abstract schemes and systems to manipulate information, however, in practice we are very limited to what type of computation can we really do. \"Information is not a disembodied abstract entity; it is always tied to a physical representation\". [3] \"If information is represented in physical states or degrees of freedom of some physical system, then any possible act of computation, or information processing, must correspond to a physical evolution of that physical system.\" [3] This means that the rules of the computation must obey the laws of physics.</p> <p>Current paradigm of computing relies on classical physics, which in result constrains what operations can we perform on the computers. \"But that is not our World. To the best of our current experimental knowledge, our World is a quantum, not classical.\" [1] This gives us hope. If one carefully isolates and always consideres the whole system, we could enlarge the zoo of the operations we could perform. Extra tools could lead to different complexity classes of the algorithms that were previously not solvable by classical computers, and could aid in further understanding of the world. </p> <p>QIP-Implementation intends to show how can we build systems that can manipulate information using laws of quantum physics. QIP-Concepts intends to entertain the idea that we have the possibility of treating the information in a quantum way. We want to give you the grounding of exploring for yourself how does this change the paradigm of computation.</p> <p>In my notes I will largely \"ignore small formal subtleties, not because they're not interesting, but because they're a distraction from all the interesting physics we want to learn!\" [1]. I will actually skip some of the formalism introduced in the lecture if I feel like it hinders my own understanding of Quantum Mechanics. I am open to being criticised for it. </p>"},{"location":"qip1/ch0.html#chapter-01-why-do-we-care-about-quantum-computing","title":"Chapter 0.1: Why do we care about Quantum Computing","text":"<p>...</p>"},{"location":"qip1/ch1a.html","title":"Chapter 1a: Principles of Quantum Mechanics","text":""},{"location":"qip1/ch1a.html#11-hilbert-spaces","title":"1.1. Hilbert spaces:","text":"<p>Hilbert Space:</p> <ul> <li>Hilbert space is a vector space \\(\\mathcal{H}\\) over \\(\\mathbb{C}\\) that is equipped with a complete inner product. </li> <li>This definition has 3 keywords: <ul> <li>Vector space - is well known, </li> <li>Complete - is just a hedge against infinite Hilbert Spaces (unimportant)</li> <li>Inner Product is a map \\((\\quad,\\quad): \\mathcal{H} \\times \\mathcal{H} \\rightarrow \\mathbb{C}\\) that obeys</li> </ul> </li> </ul> \\[ \\begin{aligned} \\text { conjugate symmetry } &amp; (\\phi, \\psi)=\\overline{(\\psi, \\phi)} \\\\ \\text { linearity } &amp; (\\phi, a \\psi)=a(\\phi, \\psi) \\\\ \\text { additivity } &amp; (\\phi, \\psi+\\chi)=(\\phi, \\psi)+(\\phi, \\chi) \\\\ \\text { positive-definiteness } &amp; (\\psi, \\psi) \\geq 0 \\forall \\psi \\in \\mathcal{H} \\end{aligned} \\] <ul> <li>Metric of \\(\\mathcal{H}\\) is defined by the norm \\(\\|\\psi\\| \\equiv \\sqrt{(\\psi, \\psi)}\\)</li> <li>Quantum states can be represented as a vectors \\(\\psi \\in \\mathcal{H}\\)</li> </ul> <p>Dual Spaces:</p> <ul> <li>Dual space \\(\\mathcal{H^*}\\) of a \\(\\mathcal{H}\\) is the space of linear maps \\(\\mathcal{H} \\rightarrow \\mathbb{C}\\). That is, an element \\(\\phi \\in \\mathcal{H^*}\\) defines a map \\(\\varphi: \\psi \\mapsto \\varphi(\\psi) \\in \\mathbb{C}\\) for every \\(\\psi \\in \\mathcal{H}\\), such that </li> </ul> \\[ \\varphi: a \\psi_1+b \\psi_2 \\mapsto a \\varphi\\left(\\psi_1\\right)+b \\varphi\\left(\\psi_2\\right) \\] <ul> <li>One of the dual space \\(\\mathcal{H^*}\\) is for instance the inner product \\((\\phi, \\quad) \\in \\mathcal{H}^*\\) for \\(\\phi \\in \\mathcal{H}\\), where </li> </ul> \\[ (\\phi, \\quad): \\psi \\mapsto(\\phi, \\psi) \\]"},{"location":"qip1/ch1a.html#12-dirac-notation","title":"1.2. Dirac Notation:","text":"<p>In quantum mechanics quite often we often switch basis. This is because intrinsically any measurement causes a collapse onto the measurement basis. Because of this we want to have a notation that allows us to work with multiple basis at the same time, and not get confused. Dirac notation (empirically) provides this clarity. It is difficult to formally define the notation, and quite often when one does it, they get confused (unless they are deep down in theory). Therefore I would propose to learn it through learning the basic few properties and then trying things out. </p> <p>Dirac denotes element of \\(\\mathcal{H}\\) as \\(\\left|\\psi\\right&gt;\\) 'ket', and an element of the dual space is written as \\(\\mathcal{H^*}\\) as \\(\\left&lt;\\psi\\right|\\) 'bra'. The inner product between two states \\(\\left|\\psi\\right&gt;, \\left|\\phi\\right&gt; \\in \\mathcal{H}\\) is written as \\(\\left&lt;\\psi|\\phi\\right&gt;\\).</p> <p>In notes the bra-ket notation is introduced using homomorphisms (linear maps). I find it unecessary.</p> <ul> <li>The advantage of using bra-ket notation is:<ul> <li>We can talk about multiple things at the same time - Dirac notation is effectively just a label that points to an abstract object in the Hilbert space. We don't need to specify whether the variable is contineous, or if it is a vector or a function.</li> <li>Allows us to label states by their eigenvalues</li> <li>Somehow it is more natural and causes less confusion</li> </ul> </li> </ul>"},{"location":"qip1/ch1a.html#13-operators","title":"1.3. Operators:","text":"<ul> <li>A linear operator A is a map \\(A : \\mathcal{H} \\rightarrow \\mathcal{H}\\) that is compatible with the vector space structure \\(A(c_1\\left|\\phi_1\\right&gt; + c_2\\left|\\phi_2\\right&gt;) = c_1A\\left|\\phi_1\\right&gt; + c_2A\\left|\\phi_2\\right&gt;\\)</li> <li>All operators in Quantum Mechanics are linear, hence we will call them just 'operators'</li> <li>Operators form algebra<ul> <li>Sum: \\((\\alpha A+\\beta B):\\left|\\phi\\right&gt; \\mapsto \\alpha A\\left|\\phi\\right&gt;+\\beta B\\left|\\phi\\right&gt;\\)</li> <li>Product: \\(A B: \\phi \\mapsto A \\circ B\\left|\\phi\\right&gt;=A(B\\left|\\phi\\right&gt;)\\)</li> <li>Commutator: \\([A, B]=A B-B A\\)</li> </ul> </li> <li>A state \\(\\psi \\in \\mathcal{H}\\) is said to be an eigenstate of an operator A if \\(A\\left|\\psi\\right&gt; = a_\\psi\\left|\\psi\\right&gt;\\) with an associated eigenvalue '\\(a_\\psi\\)'.</li> <li>Adjoint \\(A^\\dagger\\) of an operator \\(A\\) is defined as \\(\\left&lt;\\phi\\right|A^{\\dagger}\\left| \\psi\\right&gt;=\\overline{\\left&lt;\\psi\\right|A\\left| \\phi\\right&gt;} \\quad\\)</li> <li>An operator \\(Q\\) is called Hermitian if \\(Q^\\dagger=Q\\)</li> <li>An operator \\(U\\) is called Unitary if \\(U^\\dagger U= U U^\\dagger = \\mathbb{I}\\)</li> <li>An operator \\(\\Pi\\) is called Projector if \\(\\Pi\\Pi= \\Pi\\)</li> </ul>"},{"location":"qip1/ch1a.html#14-composite-systems","title":"1.4. Composite systems:","text":"<p>Tensor Product</p> <ul> <li>Tensor product \\(\\mathcal{H}_1 \\otimes \\mathcal{H}_2\\) is a vector space over \\(\\mathbb{C}\\) spanned by all pairs of elements \\(\\left|e_a\\right&gt; \\otimes\\left|f_\\alpha\\right&gt;\\), where \\(\\left|e_a\\right&gt; \\in \\mathcal{H_1}\\), \\(\\left|f_\\alpha\\right&gt; \\in \\mathcal{H_2}\\)</li> <li>It is not true that a general element of \\(\\mathcal{H}_1 \\otimes \\mathcal{H}_2\\) necessarily takes the form \\(\\left|\\psi_1\\right&gt;\\otimes\\left|\\psi_2\\right&gt;\\)</li> <li>Rahter, a general element may be written as \\(\\left|\\Psi\\right&gt;=\\sum_{a, \\alpha} r_{a \\alpha}\\left|e_a\\right&gt; \\otimes\\left|f_\\alpha\\right&gt;\\)</li> <li>Elements of the form \\(\\left|\\psi_1\\right&gt;\\otimes\\left|\\psi_2\\right&gt;\\) are called simple, and the elements of the form \\(\\left|\\Psi\\right&gt;=\\sum_{a, \\alpha} r_{a \\alpha}\\left|e_a\\right&gt; \\otimes\\left|f_\\alpha\\right&gt;\\) are refered as entangled</li> <li>\\(\\left&lt;\\alpha\\otimes\\beta|\\alpha'\\otimes\\beta'\\right&gt; := \\left&lt;\\alpha|\\alpha'\\right&gt;\\left&lt;\\beta|\\beta'\\right&gt;\\)</li> <li>\\(\\left( S_\\alpha \\otimes T_\\beta \\right)\\left(\\alpha \\otimes \\beta\\right) = \\left(S_\\alpha\\alpha\\right)\\otimes\\left(T_\\beta\\beta\\right)\\) - apologies for being slightly sloppy - I think it is understandable what I mean though</li> </ul> <p>Tensor Product in action (states)</p> <ul> <li>Let's as an example consider that our states \\(\\left|\\alpha\\right&gt;_A \\text{ and } \\left|\\beta\\right&gt;_B\\) live both in \\(\\mathbb{C}^2_A\\) and \\(\\mathbb{C}^2_B\\) respectively. Then we can pick orthonormal basis of \\(\\mathbb{C}^2_A\\) to be \\(\\left\\{\\left|u_1\\right&gt;_A, \\left|u_2\\right&gt;_A \\right\\}\\), and of \\(\\mathbb{C}^2_B\\) to be \\(\\left\\{\\left|v_1\\right&gt;_B, \\left|v_2\\right&gt;_B \\right\\}\\)</li> <li>Then one can write \\(\\left|\\alpha\\right&gt;_A = a_1 \\left|u_1\\right&gt;_A + a_2 \\left|u_2\\right&gt;_A = a_1 \\begin{pmatrix} 1\\\\ 0 \\end{pmatrix}_A + a_2 \\begin{pmatrix} 0\\\\ 1 \\end{pmatrix}_A\\),</li> <li>and \\(\\left|\\beta\\right&gt;_B = b_1 \\left|v_1\\right&gt;_B + b_2 \\left|v_2\\right&gt;_B = b_1 \\begin{pmatrix} 1\\\\ 0 \\end{pmatrix}_B + b_2 \\begin{pmatrix} 0\\\\ 1 \\end{pmatrix}_B\\)</li> <li>This means that one can write </li> </ul> \\[ \\left|\\alpha\\right&gt;_A \\otimes \\left|\\beta\\right&gt;_B = \\begin{pmatrix} a_1\\\\ a_2 \\end{pmatrix}_A \\otimes \\begin{pmatrix} b_1\\\\ b_2 \\end{pmatrix}_B = \\begin{pmatrix} a_1b_1\\\\ a_1b_2\\\\ a_2b_1\\\\ a_2b_2 \\end{pmatrix} \\] <ul> <li>or sticking to the Dirac notation:</li> </ul> \\[ \\left|\\alpha\\right&gt;_A \\otimes \\left|\\beta\\right&gt;_B = \\sum_{i,j} a_i b_j \\left|u_i\\right&gt;_A \\otimes \\left|v_j\\right&gt;_B \\] <p>Tensor Product in action (operators)</p> <ul> <li>For operators \\(A\\) and \\(B\\) that live in \\(\\mathbb{C}^2_A\\) and \\(\\mathbb{C}^2_B\\) respectively, one can write \\(A = \\sum_{i,j} a_{ij} \\left|u_i\\right&gt;_A \\left&lt;u_j\\right|\\) and \\(B = \\sum_{i,j} b_{ij} \\left|v_i\\right&gt;_B \\left&lt;v_j\\right|\\)</li> <li>This means:</li> </ul> \\[ A \\otimes B = \\sum_{i,j,k,\\ell} a_{ij} b_{k\\ell} \\left|u_i\\right&gt;_A \\otimes \\left|v_k\\right&gt;_B \\left&lt;u_j\\right|\\otimes\\left&lt;v_\\ell\\right| \\] <ul> <li>or in a matrix form:</li> </ul> \\[ A \\otimes B = \\begin{pmatrix} a_{11}B &amp; a_{12}B\\\\ a_{21}B &amp; a_{22}B \\end{pmatrix} = \\begin{pmatrix} a_{11}b_{11} &amp; a_{11}b_{12} &amp; a_{12}b_{11} &amp; a_{12}b_{12}\\\\ a_{11}b_{21} &amp; a_{11}b_{22} &amp; a_{12}b_{21} &amp; a_{12}b_{22}\\\\ a_{21}b_{11} &amp; a_{21}b_{12} &amp; a_{22}b_{11} &amp; a_{22}b_{12}\\\\ a_{21}b_{21} &amp; a_{21}b_{22} &amp; a_{22}b_{21} &amp; a_{22}b_{22}\\\\ \\end{pmatrix} \\]"},{"location":"qip1/ch1a.html#15-postulates-of-quantum-mechanics","title":"1.5. Postulates of Quantum Mechanics:","text":"<ul> <li>(1) A quantum system A is associated with complex Hilber space \\(\\mathcal{H}\\). A physical state of an isolated system is represented by a normalised vector \\(\\left|\\psi\\right&gt; \\in \\mathcal{H}\\), which is unique up to a phase factor</li> <li>(2) The evolution of an isolated quantum system is reversible. In this formalism this corresponds to unitary evolution of the form \\(\\left|\\psi\\right&gt; \\mapsto U\\left|\\psi\\right&gt;\\) for \\(U \\in \\mathcal{U}(\\mathcal{H})\\), i.e. \\(U^{\\dagger} U=U U^{\\dagger}=\\mathbb{I}\\). The unitary is unique up to a phase factor</li> <li>(3) Composite system - For two quantum system A, and B with associated Hilber spaces \\(\\mathcal{H_A}\\) and \\(\\mathcal{H_B}\\) the Hilbert space \\(\\mathcal{H_{AB}}\\) associated with the composite system AB is isomorphic to the tensor product \\(\\mathcal{H_A}\\otimes\\mathcal{H_B}\\). For unitary operation on the subsystem we use: \\(U_A \\otimes \\mathbb{I}_B\\left|i j\\right&gt;_{A B} \\equiv U_A\\left|i j\\right&gt;_{A B}\\)</li> <li>(4) Measurement - A projective measurement on a quantum system with outcomes labelled \\({x}_x\\) is associated with a set of projectors \\({\\Pi_x}x\\) satisfying \\(\\sum_x \\Pi_x = \\mathbb{I}\\). <ul> <li>Probability of getting outcome x when measuring state \\(\\left|\\psi\\right&gt;\\) is given by the Born rule: \\(Pr[x \\mid \\psi]=\\left\\langle\\psi\\left|\\Pi_x\\right| \\psi\\right\\rangle\\)</li> <li>Post-measurement state is given the outcome x is \\(\\left|\\psi_x^{\\prime}\\right&gt;=\\frac{1}{\\sqrt{\\operatorname{Pr}[x \\mid \\psi]}} \\Pi_x\\left|\\psi\\right&gt;=\\frac{\\Pi_x\\left|\\psi\\right&gt;}{\\sqrt{\\left\\langle\\psi\\left|\\Pi_x\\right| \\psi\\right\\rangle}}\\)</li> </ul> </li> </ul>"},{"location":"qip1/ch1b.html","title":"Chapter 1b: Usefull Toolbox","text":""},{"location":"qip1/ch1b.html#16-bloch-sphere","title":"1.6. Bloch Sphere:","text":"<ul> <li>Because in my class there are a lot of non-physicists I thought it would be useful to introduce the concept of the Bloch Sphere. </li> <li>Bloch Sphere is just a common representation of a two level system, which allows one to think about the states and operations in a more intuitive way</li> <li>Normally when one thinks about how many parameters one needs to define a two level system, they can naively thing 4. In the end two level system lives in \\(\\left|\\psi\\right&gt; \\in \\mathbb{C}^2\\). In different words, any pure state can be written as a superposition of the basis vectors \\(\\left|0\\right&gt;\\) and \\(\\left|1\\right&gt;\\), where the coefficient of each of the two basis vectors is a complex number. \\(\\left|\\psi\\right&gt; = a_1e^{i\\theta_1} \\left|0\\right&gt; +  a_2e^{i\\theta_2} \\left|1\\right&gt;\\). 4-parameters right?<ul> <li>We know, however, that the norm of a pure state must equal to 1, which means that $\\left&lt;\\psi|\\psi\\right&gt; = 1 $, and so \\(\\left|a_1\\right|^2 + \\left|a_2\\right|^2=1\\). This reduces the number of free parameters to 3</li> <li>We also know that we dont care about the global phase of a state, as it doesn't change anything about our measurement, and so we can also neglect one degree of freedom, which reduces the number of free parameters to 2</li> <li>This means that we can represent any 2-level quantum pure state on a unit sphere, which we will call Bloch Sphere</li> </ul> </li> <li>How does one parametrise something on a unit-sphere?<ul> <li>One can do it with angles, \\(\\theta \\text{ and } \\phi\\)</li> <li>\\(\\left|\\psi\\right&gt; = \\cos\\frac{\\theta}{2} \\left|0\\right&gt; +  e^{i\\phi}\\sin{\\frac{\\theta}{2}} \\left|1\\right&gt;\\)</li> <li>In such representation the probability of measuring state \\(\\left|0\\right&gt;\\) is: \\(\\left&lt;0|\\psi\\right&gt; = \\cos^2\\frac{\\theta}{2}\\), and to measure state \\(\\left|1\\right&gt;\\) is \\(\\sin^2\\frac{\\theta}{2}\\)</li> <li>\\(\\left|\\psi\\right&gt;\\) can be represented on a unit sphere as:</li> </ul> </li> </ul> <p>  - Any Unitary Operator then will be some sort of rotation of this state, mapping it from one point on this sphere to another point on this sphere - you will see it in the subchapter Quantum Circuits</p>"},{"location":"qip1/ch1b.html#17-bell-basis","title":"1.7. Bell Basis","text":"<ul> <li>Let \\(\\mathcal{H}_{A B}=\\mathcal{H}_A \\otimes \\mathcal{H}_B \\cong \\mathbb{C}^4\\) be the bipartite Hilbert space of two qubits and consider the product basis of the computational bases of the qubit subsystems. For \\(\\mathcal{H_{AB}}\\) there exists a basis consisting of maximally entangled states denotes as:</li> </ul> \\[\\begin{array}{ll}\\left|\\psi^{00}\\right&gt;=\\frac{1}{\\sqrt{2}}(\\left|00\\right&gt;+\\left|11\\right&gt;) &amp; =\\left|\\Phi^{+}\\right&gt; \\\\ \\left|\\psi^{01}\\right&gt;=\\frac{1}{\\sqrt{2}}(\\left|00\\right&gt;-\\left|11\\right&gt;) &amp; =\\left|\\Phi^{-}\\right&gt; \\\\ \\left|\\psi^{10}\\right&gt;=\\frac{1}{\\sqrt{2}}(\\left|01\\right&gt;+\\left|10\\right&gt;) &amp; =\\left|\\Psi^{+}\\right&gt; \\\\ \\left|\\psi^{11}\\right&gt;=\\frac{1}{\\sqrt{2}}(\\left|01\\right&gt;-\\left|10\\right&gt;) &amp; =\\left|\\Psi^{-}\\right&gt;\\end{array}\\] <ul> <li>The first number stands for parity, the second number stands for phase. \\(\\left|\\psi^{10}\\right&gt;\\) has parity 1 (odd number of 1's), and relative phase \\((-1)^0=1\\)</li> <li>The maximally entangled states are locally convertible - there exist local operations on the subsystem B that transforms one Bell state into another Bell state. \\(\\(\\left|\\psi^{i j}\\right&gt;=\\left(\\mathbb{I}_A \\otimes X_B^i Z_B^j\\right)\\left|\\psi^{00}\\right&gt;\\)\\)</li> </ul>"},{"location":"qip1/ch1b.html#18-quantum-circuits","title":"1.8. Quantum Circuits","text":"<p>Example Quantum circuit</p> <p> </p> <p>corresponds to unitary operator \\(\\left(V \\otimes \\mathbb{I}\\right)\\left(\\mathbb{I}\\otimes U\\right)\\left(H\\otimes\\mathbb{I}\\otimes Z\\right)\\) applied to three qubits followed by a Z-measurement of the first qubit</p> <p>Common Gates</p> <ul> <li>Haddamard Gate:<ul> <li>\\(H=\\frac{1}{\\sqrt{2}}\\left(\\begin{array}{cc}1 &amp; 1 \\\\ 1 &amp; -1\\end{array}\\right)=\\left|+\\right&gt;\\left&lt; 0\\right|+\\left|-\\right&gt; \\left&lt;1\\right|=\\left| 0\\right&gt;\\left&lt;+\\right|+\\left| 1\\right&gt;\\left&lt;-\\right|\\)</li> <li>As an orthogonal transformation in the real Euclidean plane \\(\\mathbb{R}^2\\), H is reflection in the mirror line at angle \\(\\frac{\\pi}{8}\\) to the x-axis  </li> </ul> </li> <li>X, Y, Z:<ul> <li>\\(X = \\left(\\begin{array}{ll} 0 &amp; 1 \\\\ 1 &amp; 0 \\end{array}\\right)\\), \\(Z = \\left(\\begin{array}{ll} 1 &amp; 0 \\\\ 0 &amp; -1 \\end{array}\\right)\\), \\(Y = \\left(\\begin{array}{ll} 0 &amp; 1 \\\\ -1 &amp; 0 \\end{array}\\right)\\)</li> <li>X-gate<ul> <li> </li> </ul> </li> <li>Y-gate<ul> <li> </li> </ul> </li> <li>Z-gate<ul> <li> </li> </ul> </li> </ul> </li> <li>Controlled-U Gate:<ul> <li>\\(\\mathrm{C} U=\\left|0\\right&gt;\\left&lt;0\\right|\\otimes \\mathrm{id}+\\left| 1\\right&gt;\\left&lt;1\\right| \\otimes U\\)</li> </ul> </li> <li>Controlled-Not Gate:<ul> <li>\\(\\mathrm{CNOT}=\\left(\\begin{array}{llll}1 &amp; 0 &amp; 0 &amp; 0 \\\\ 0 &amp; 1 &amp; 0 &amp; 0 \\\\ 0 &amp; 0 &amp; 0 &amp; 1 \\\\ 0 &amp; 0 &amp; 1 &amp; 0\\end{array}\\right)=\\left|0 \\right&gt;\\left&lt; 0\\right| \\otimes \\mathbb{I}+\\left|1\\right&gt;\\left&lt;1\\right| \\otimes X\\)</li> </ul> </li> </ul>"},{"location":"qip1/ch2a.html","title":"Chapter 2a: Quantum Information","text":"<p>Initially I didn't want to talk much about quantum information theory. In my mind there is another course that deals with it in much more detail (Quantum Information Theory). However, because the lecture course covers these topics, I decided to include few ideas. I will try to keep them at a very high level and focus on their relevance to quantum algorithms.</p>"},{"location":"qip1/ch2a.html#21-nature-of-quantum-information","title":"2.1. Nature of Quantum Information:","text":"<ul> <li>Quantum information is different from the classical information in a sense that the measurements corrupts the state itself</li> <li>We can prepare any desired pure state, but if we receive such pure state we cannot identify it with certainty (if we dont know how to measure it)</li> <li>Given a unknown quantum state \\(\\left|\\psi\\right&gt;\\) there are three basic operations that we can perform:<ul> <li>Ancilla - take a second, known, quantum system \\(\\left|A\\right&gt;\\) and join it with \\(\\left|\\psi\\right&gt;\\) and treat it as a composite system \\(\\left|\\psi\\right&gt; \\otimes \\left|A\\right&gt;\\)</li> <li>Unitary - we can perform a unitary on \\(\\left|\\psi\\right&gt;\\) and obtain \\(\\left|\\psi^{\\prime}\\right&gt; = U\\left|\\psi\\right&gt;\\) - i.e. all your gates</li> <li>Measurement - we can perform a measurement on \\(\\left|\\psi\\right&gt;\\), or sub-system of it, record the outcome and retain the post-measurement state for further processing</li> </ul> </li> <li>Any quantum operation can be described as a composition of these three operations. Quite often the algorithms used to manipulate information use all of those operations and not just gates</li> </ul>"},{"location":"qip1/ch2a.html#22-no-cloning-theorem","title":"2.2. No-Cloning Theorem:","text":"<ul> <li>Cloning operation of a quantum state \\(\\left|\\psi\\right&gt;\\) is defined as a map \\(\\left|\\psi\\right&gt;_A \\left|0\\right&gt;_B \\rightarrow \\left|\\psi\\right&gt;_A \\left|\\psi\\right&gt;_B\\)</li> <li>We can extend it to a larger system, by adjoining ancilla to it. In this case the cloning operations can be defined as \\(\\left|\\psi\\right&gt;_A \\left|0\\right&gt;_B \\left|M_0\\right&gt;_M \\rightarrow \\left|\\psi\\right&gt;_A \\left|\\psi\\right&gt;_B \\left|M_\\psi\\right&gt;_M\\)</li> <li>No-Cloning Theorem: Let \\(\\mathcal{S}\\) be any set of states of A that contains at least one non-orthogonal state. Then there is no unitary cloning process that achieves cloning for all states in \\(\\mathcal{S}\\).</li> <li>Remark: I am only presenting a proof of 'no-cloning theorem' for the case where the agent is only allowed to perform unitary operations. There exists an extention of this theorem for any 3 basic operations (Ancilla, Unitary, Measurement).</li> </ul>"},{"location":"qip1/ch2a.html#proof","title":"Proof:","text":"<p>Let \\(\\left|\\psi\\right&gt;\\) and \\(\\left|\\phi\\right&gt;\\) be two distinct non-orthogonal states in \\(\\mathcal{S}\\). Lets assume that there exist a unitary \\(U\\) that clone the states in \\(\\mathcal{S}\\).</p> <p>then</p> \\[ U\\left|\\psi\\right&gt;_A \\left|0\\right&gt;_B \\left|M_0\\right&gt;_M = \\left|\\psi\\right&gt;_A \\left|\\psi\\right&gt;_B \\left|M_\\psi\\right&gt;_M \\] \\[ U\\left|\\phi\\right&gt;_A \\left|0\\right&gt;_B \\left|M_0\\right&gt;_M = \\left|\\phi\\right&gt;_A \\left|\\phi\\right&gt;_B \\left|M_\\phi\\right&gt;_M \\] <p>then </p> \\[ \\left&lt;M_0\\right|_M\\left&lt;0\\right|_B\\left&lt;\\psi\\right|_A U^\\dagger U\\left|\\phi\\right&gt;_A \\left|0\\right&gt;_B \\left|M_0\\right&gt;_M = \\left&lt;M_\\psi\\right|_M \\left&lt;\\psi\\right|_B \\left&lt;\\psi\\right|_A \\left|\\phi\\right&gt;_A \\left|\\phi\\right&gt;_B \\left|M_\\phi\\right&gt;_M \\] \\[ \\left&lt;M_0|M_0\\right&gt;_M\\left&lt;0|0\\right&gt;_B\\left&lt;\\psi|\\phi\\right&gt;_A = \\left&lt;M_\\psi|M_\\psi\\right&gt;_M\\left&lt;\\psi|\\phi\\right&gt;_A\\left&lt;\\psi|\\phi\\right&gt;_B \\] \\[ \\left&lt;\\psi|\\phi\\right&gt;_A = \\left&lt;M_\\psi|M_\\phi\\right&gt;_M\\left&lt;\\psi|\\phi\\right&gt;_A\\left&lt;\\psi|\\phi\\right&gt;_B \\] <p>since \\(\\left|\\psi\\right&gt;\\) and \\(\\left|\\phi\\right&gt;\\) are non-orthogonal, we can divide both sides by \\(\\left&lt;\\psi|\\phi\\right&gt;_A\\) and get:</p> \\[ 1 = |\\left&lt;M_\\psi|M_\\phi\\right&gt;_M\\left&lt;\\psi|\\phi\\right&gt;_B| \\] <ul> <li>\\(M_\\psi\\) and \\(M_\\phi\\) are quantum states: \\(|\\left&lt;M_\\psi|M_\\phi\\right&gt;_M| \\leq 1\\),  </li> <li>\\(\\left|\\psi\\right&gt;\\) and \\(\\left|\\phi\\right&gt;\\) are distinct states and so: \\(|\\left&lt;\\psi|\\phi\\right&gt;_B| &lt; 1\\)</li> <li>Therefore we arrive to a contradiction, which completes the proof</li> </ul>"},{"location":"qip1/ch2a.html#herberts-method-of-superluminal-communication","title":"Herbert's method of superluminal communication:","text":"<ul> <li>The no-cloning theorem was crucial for debugging the protocol of superluminal communication proposed by Herbert. See more in Richard's Jozsa notes [4].</li> </ul>"},{"location":"qip1/ch2a.html#23-quantum-teleportation","title":"2.3. Quantum Teleportation:","text":"<p>Consider that Alice and Bob share an entangled Bell state \\(\\left|\\phi^{+}\\right&gt;_{23} = \\frac{1}{\\sqrt{2}}(\\left|00\\right&gt; + \\left|11\\right&gt;)_{23}\\), such that each of them has one qubit of the pair. Additionally Alice has a qubit in a state \\(\\left|\\alpha\\right&gt;_1 = a\\left|0\\right&gt; + b \\left|1\\right&gt;\\). </p> <p>This means that the combined state of the system is:</p> \\[ \\begin{aligned} \\left|\\psi\\right&gt;_{AB} &amp;= \\left|\\alpha\\right&gt;_1 \\left|\\phi^{+}\\right&gt;_{23} = \\left(a\\left|0\\right&gt; + b\\left|1\\right&gt;\\right)_1 \\frac{1}{\\sqrt{2}}(\\left|00\\right&gt; + \\left|11\\right&gt;)_{23} \\\\ &amp; = \\frac{a}{\\sqrt{2}}\\left|000\\right&gt; + \\frac{a}{\\sqrt{2}}\\left|011\\right&gt; + \\frac{b}{\\sqrt{2}}\\left|100\\right&gt; + \\frac{b}{\\sqrt{2}}\\left|111\\right&gt; \\end{aligned} \\] <p>Task: of the quantum teleportation is to transfer the state of \\(\\left|\\alpha\\right&gt;_1\\) to \\(\\left|\\beta\\right&gt;_3\\) by performing local operations and classical communication.</p>"},{"location":"qip1/ch2a.html#algorithm","title":"Algorithm:","text":"<ol> <li>Alice performs a Bell measurement on the two qubits (Performs a projective measurement in the Bell basis)     &lt;!-- 1. Alice applies CX to her qubits 1 and 2<ol> <li>Alice applies H to her qubit 1</li> <li>Alice measures her two qbits to obtain a 2-bit string 00, 01, 10 or 11 --&gt;</li> </ol> </li> <li>Alice sends a 2-bit measurement outcome ij to Bob</li> <li>On receiving ij Bob applies the unitary operation \\(Z^iX^j\\) to his qubit, which is then guaranteed to be in the state \\(\\left|\\alpha\\right&gt;_3\\)</li> </ol> <p>Remark: No information about \\(\\left|\\alpha\\right&gt;_2\\) is left with Alice</p>"},{"location":"qip1/ch2a.html#why-it-works","title":"Why it works:","text":""},{"location":"qip1/ch2a.html#explanation-1","title":"Explanation 1:","text":"<p>(From explanation 1 we would like to learn about how local operations on single qubits can affect the measurement outcome of the measurement of the second qubit.)</p> <p>We can write \\(\\left|\\psi\\right&gt;_{AB}\\) as:</p> \\[ \\begin{aligned} \\left|\\psi\\right&gt;_{AB} &amp;= \\frac{a}{\\sqrt{2}}\\left|000\\right&gt;_{123} + \\frac{a}{\\sqrt{2}}\\left|011\\right&gt;_{123} + \\frac{b}{\\sqrt{2}}\\left|100\\right&gt;_{123} + \\frac{b}{\\sqrt{2}}\\left|111\\right&gt;_{123}\\\\ &amp;= \\frac{a}{2}\\left(\\left|\\psi_{00}\\right&gt;_{12} + \\left|\\psi_{01}\\right&gt;_{12}\\right)\\left|0\\right&gt;_{3} + \\frac{a}{2}\\left(\\left|\\psi_{10}\\right&gt;_{12} + \\left|\\psi_{11}\\right&gt;_{12}\\right)\\left|1\\right&gt;_{3} + \\frac{b}{2}\\left(\\left|\\psi_{10}\\right&gt;_{12} - \\left|\\psi_{11}\\right&gt;_{12}\\right)\\left|0\\right&gt;_{3} + \\frac{b}{2}\\left(\\left|\\psi_{00}\\right&gt;_{12} - \\left|\\psi_{01}\\right&gt;_{12}\\right)\\left|1\\right&gt;_{3} \\\\ &amp;= \\left|\\psi_{00}\\right&gt;_{12}\\left(\\frac{a}{2}\\left|0\\right&gt;_{3} + \\frac{b}{2}\\left|1\\right&gt;_{3}\\right) + \\left|\\psi_{01}\\right&gt;_{12}\\left(\\frac{a}{2}\\left|0\\right&gt;_{3} - \\frac{b}{2}\\left|1\\right&gt;_{3}\\right) + \\left|\\psi_{10}\\right&gt;_{12}\\left(\\frac{a}{2}\\left|1\\right&gt;_{3} + \\frac{b}{2}\\left|0\\right&gt;_{3}\\right) + \\left|\\psi_{11}\\right&gt;_{12}\\left(\\frac{a}{2}\\left|1\\right&gt;_{3} - \\frac{b}{2}\\left|0\\right&gt;_{3}\\right)\\\\ \\end{aligned} \\] <p>Therefore when we measure in which bell state the first two qubits are then we get the following post-measurement states:</p> \\[ \\begin{array}{cc} \\text { mmt outcome } &amp; \\text { post-mmt state } \\\\ 00 &amp; \\left|00\\right&gt;_{12}\\left|\\alpha\\right&gt;_3 \\\\ 01 &amp; \\left|01\\right&gt;_{12}X\\left|\\alpha\\right&gt;_3 \\\\ 10 &amp; \\left|10\\right&gt;_{12}Z\\left|\\alpha\\right&gt;_3 \\\\ 11 &amp; \\left|11\\right&gt;_{12}XZ\\left|\\alpha\\right&gt;_3 \\end{array} \\] <p>Therefore knowing the outcome of the measurement Alice can send a 2-bit string to Bob, who then applies the corresponding operation to his qubit and recovers the state \\(\\left|\\alpha\\right&gt;_3\\)</p>"},{"location":"qip1/ch2a.html#explanation-2","title":"Explanation 2:","text":"<p>(From this explanation we would like to learn how to perform an operation that depends on the measurement outcome.)</p> <p>What I would like to do here is to provide slightly different explanation. I don't like Explanation 1 because it feels very brute forcy, and it doesn't provide any additional intuition about why things are, like they are. The following explanation is perhaps slightly more tricky to grasp, but I think it provides more insight.</p> <p>E.2.1.</p> <p>I would like to start with a simple observation. When we project the first two qubits into the state \\(\\left|\\psi_{00}\\right&gt;_{12}\\) then we get:</p> \\[ \\left&lt;\\psi_{00}\\right|_{12}\\left|\\alpha\\right&gt;_1\\left|\\psi_{00}\\right&gt;_{23} = \\left|\\alpha\\right&gt;_3 \\] <p>One might then ask is it true for more general case? Is this statement true for any state \\(\\left|\\psi_{ij}\\right&gt;_{23}\\):</p> \\[ \\left&lt;\\psi_{ij}\\right|_{12}\\left|\\alpha\\right&gt;_1\\left|\\psi_{ij}\\right&gt;_{23} \\stackrel{?}{=} \\left|\\alpha\\right&gt;_3 \\] <p>This must be true as we can write </p> \\[ \\left&lt;\\psi_{ij}\\right|_{12}\\left|\\alpha\\right&gt;_1\\left|\\psi_{ij}\\right&gt;_{23} = \\left(\\left&lt;\\psi_{00}\\right|_{12} X_2^i Z_2^j\\right)\\left|\\alpha\\right&gt;_1\\left(Z_2^i X_2^j\\left|\\psi_{00}\\right&gt;_{23}\\right) = \\left&lt;\\psi_{00}\\right|_{12}\\left|\\alpha\\right&gt;_1\\left|\\psi_{00}\\right&gt;_{23}= \\left|\\alpha\\right&gt;_3 \\] <p>Wow! This means that quantum teleportation is trivial. If we could perform a projection operation on the first two qubits onto the bell state in which we prepared the pair of second and third qubit, we would simply teleport the state from a qubit 1 to a qubit 3. However, the projection operation is non-unitary and we cannot do it in a unitary way. We need to find workaround. </p> <p>Something that performs a projection operation on the first two qubits is the Bell measurement. This will, however, perform a projective measurement to an arbitrary state and not just the \\(\\left|\\psi_{00}\\right&gt;_{12}\\). The measurement projects the first two qubits into {\\(\\left|\\psi_{00}\\right&gt;_{12}\\), \\(\\left|\\psi_{01}\\right&gt;_{12}\\), \\(\\left|\\psi_{10}\\right&gt;_{12}\\), \\(\\left|\\psi_{11}\\right&gt;_{12}\\)}. Can we somehow know into which state it will project and perform a corresponding operation on the third qubit prior to the measurement?</p> <p>We know it after the measurement, but not before. Before the measurement we cannot know the state into which the measurement will project us (no hidden-variables :)). </p> <p>E.2.2.</p> <p>And here comes the step two: perhaps it doesn't really matter whether we do the operation on the third qubit prior to the measurement or after the measurement. And this I am showing below.</p> \\[ \\left( \\left&lt;\\psi_{ij}\\right|_{12} \\otimes \\mathbb{I}_3\\right) \\left( \\mathbb{I}_{12} \\otimes X_3^i Z_3^j\\right) \\left|\\psi\\right&gt;_{AB} = \\left( \\mathbb{I}_{12} \\otimes X_3^i Z_3^j\\right) \\left( \\left&lt;\\psi_{ij}\\right|_{12} \\otimes \\mathbb{I}_3\\right) \\left|\\psi\\right&gt;_{AB}  = \\left|\\alpha\\right&gt;_3 \\] <p>Et voil\u00e0! It doesn't matter. This is great news, because after the measurement we know into which state we projected the Bell basis. And if we then can perform the unitaries on the qubit 3, we can achieve the same result as if we did it before the measurement.</p> <p>E.2.3.</p> <p>This completes the explanation. What I want to show with this explanation, that you can try to think how to build non-unitary operations on your quantum system if you include the measurement and ancilla as part of your allowed operations. This can quite often suprise you.</p> <p>Feedback: The explanation was coined by me through talking to others and thinking. I haven't seen it anywhere else, so I would love to refine it if you have any ideas how to improve the clarity of the delivery wadamczyk@phys.ethz.ch.</p>"},{"location":"qip1/ch3a.html","title":"Chapter 3a: Computational Complexity:","text":"<p>I will start first by introducing the ideas from the classical computations, and then I will try to extend it to quantum computation and then try to observe the difference. </p> <p>Computational task is usually general i.e. 'given an n-bit string A (for any n), is A prime?'. Studying information theory, we are interested to know how efficient our computation is and whether allowing for some new quantum properties we will improve this computational efficiency. How efficient algorithm is can be measured though algorithm complexity.</p>"},{"location":"qip1/ch3a.html#31-algorithm-complexity","title":"3.1. Algorithm Complexity:","text":"<p>How efficient an algorithm is, can be measured in the amount of resources that are needed to solve a problem of size n.</p> <ul> <li>Time complexity deals with the number of computational steps required for solving the problem</li> <li>Space complexity deals with the amount of RAM that is needed to solve the problem</li> </ul> <p>Big O-Notation is very handy in this case - to easily compare two algorithms</p>"},{"location":"qip1/ch3a.html#32-big-o-notation","title":"3.2. Big O notation:","text":"<p>Below I included definitions from P.Kammerlander lecture, for more intuitive picture go directly to the grey box:</p> <ul> <li> <p>\\(f(n)=o(g(n))\\) and say that \\(f\\) grows slower than \\(g\\) if \\(\\forall c&gt;0 \\exists n_0&gt;0\\) such that for all \\(n \\geq n_0: f(n) \\leq c g(n)\\),</p> </li> <li> <p>\\(f(n)=O(g(n))\\) and say that \\(f\\) does not grow significantly faster than \\(g\\) if \\(\\exists c&gt;0\\) and \\(n_0&gt;0\\) such that for all \\(n \\geq n_0: f(n) \\leq c g(n)\\),</p> </li> <li> <p>\\(f(n)=\\Omega(g(n))\\) and say that \\(f\\) does not grow significantly slower than \\(g\\) if \\(\\exists c&gt;0\\) and \\(n_0&gt;0\\) such that for all \\(n \\geq n_0: c g(n) \\leq f(n)\\),</p> </li> <li> <p>\\(f(n)=\\Theta(g(n))\\) and say that \\(f\\) grows as fast as \\(g\\) if both \\(f(n)=O(g(n))\\) and \\(f(n)=\\Omega(g(n))\\).</p> </li> </ul> <p>Formally, define \\(f(n)=O(g(n))\\) provided \\(|f(n)| \\leq c|g(n)|\\) as \\(n \\rightarrow \\infty\\) - \\(|f(n)|\\) is bounded for some constant \ud835\udc50 and all su\ufb00iciently large \ud835\udc5b. - Intuitively, look at the most significant term. - Ignore constant factors as they seldom dominate and are often transitory</p> <p>For example: consider \\(\ud835\udc5b^2\\) instead of \\(3\ud835\udc5b^2 + 34\ud835\udc5b + 433\\): - The cost of a program is usually a complicated formula. Often we should consider only the most significant term. If the cost is \\(\ud835\udc5b^2 + 99\ud835\udc5b + 900\\) for an input of size \\(\ud835\udc5b\\), then the \\(\ud835\udc5b^2\\) term will eventually dominate, even though \\(99\ud835\udc5b\\) is bigger for \\(\ud835\udc5b &lt; 99\\). The constant term 900 may look big, but it is soon dominated by \\(\ud835\udc5b^2\\).</p> <p>i.e. We don't care in this case whether each time-step will take 1minute or 1ms, as for sufficiently large problem it wont matter. If we can make the algorithm more efficient, there will exist a n, for which the slow computer will be solving problem of size n faster.</p> <p>Simple Facts about O Notation:</p> <ul> <li>\\(\\begin{array}{r}O(2 g(n)) \\text { is the same as } O(g(n)) \\\\ O\\left(\\log _{10} n\\right) \\text { is the same as } O(\\ln n) \\\\ O\\left(n^2+50 n+36\\right) \\text { is the same as } O\\left(n^2\\right) \\\\ O\\left(n^2\\right) \\text { is contained in } O\\left(n^3\\right) \\\\ O\\left(2^n\\right) \\text { is contained in } O\\left(3^n\\right) \\\\ O(\\log n) \\text { is contained in } O(\\sqrt{n})\\end{array}\\)</li> </ul> <p>Above is taken from [4]</p>"},{"location":"qip1/ch3a.html#33-complexity-classes","title":"3.3. Complexity Classes:","text":"<p>Decision Problem is a problem that can be formulated as a yes-no question of the input value. </p> <p>Zoo of Complexity Classes</p> <ul> <li>P: (Polynomial) The class of decision problems that can be solved in polynomial time on a classical computer.</li> <li>BPP: (Bounded-Error probabilistic polynomial time) The class of decision problems that can be solved by a probabilistic algorithm in polynomial time on a classical computer with failure probability at most \\(\\frac{1}{3}\\) for all possible inputs.</li> <li>NP: The class of decision problems such that, if the answer is \u2018yes\u2019, there is a proof of this which can be verified in polynomial time on a classical computer.</li> <li>PSPACE: (Space complexity polynomial) The class of decision problems that can be solved in polynomial space on a classical computer.</li> <li>NP-complete: A problem is said to be NP-complete if it is in NP and any other problem in NP can be reduced to it in polynomial time.</li> <li>BQP: The class of decision problems that can be solved in polynomial time on a quantum computer with failure probability at most \\(\\frac{1}{3}\\) for all possible inputs.</li> </ul> <p>Some facts:</p> <ul> <li>\\(\\mathbf{P} \\subset \\mathbf{B P P}\\)</li> <li>\\(\\mathbf{P} \\subset \\mathbf{N P} \\subset \\mathbf{P S P A C E}\\)</li> <li>It is not known whether \\(\\mathbf{B P P} \\subset \\mathbf{N P}\\)</li> <li>Factorisation is not known and not believed to be NP-complete</li> <li>We dont know whether \\(\\mathbf{P} = \\mathbf{B P P}\\), although many believe so</li> </ul>"},{"location":"qip1/ch3a.html#34-quantum-complexity","title":"3.4. Quantum Complexity","text":"<p>For quantum computers we need to somehow define the operation. Quantum computation is simply application of some unitary operator \\(U \\in \\mathcal{U}(2^n)\\) to some initial state of n qubit (usually \\(\\left|0\\right&gt;=\\left|00 \\cdots 0\\right&gt;=\\left|0^n\\right&gt;=\\left|0\\right&gt;^{\\otimes n}\\)), followed by a measurement m of the qubits in the computational basis. Any \\(U \\in \\mathcal{U}(2^n)\\) is composed of an elementary gate from \\(\\mathcal{S}\\).</p> <ul> <li>circuit size is the number of elementary gates</li> <li>circuit width is the number of s-qubits that are involved in those elementary gates</li> <li>circuit depth is the number of actual time steps needed while allowing for parallel execution of elementary gates on di\u2000erent qubits. However, the depth di\u2000ers from the size at most by a constant factor of s and is hence not relevant for the asymptotic runtime.</li> </ul>"},{"location":"qip1/ch3b.html","title":"Chapter 3b: Universal gates, Reversible irreversability, Oracle Functions","text":""},{"location":"qip1/ch3b.html#35-universal-sets-of-gates","title":"3.5. Universal sets of gates","text":"<p>\\(\\mathcal{S}\\) is universal set of gates for quantum computing if for any \\(n \\in \\mathbb{N}\\) an arbitrary unitary operation \\(U \\in \\mathcal{U}(n)\\) can be implemented to arbitrary precision using only elementary gates from \\(\\mathcal{S}\\). Elementary gates are assumed to take \\(O(1)\\) time.</p> <ul> <li>Examples of the universal set of gates:<ul> <li>\\(\\{CNOT\\} \\cup \\mathcal{U}(2)\\)</li> <li>\\(\\{CNOT, H, T\\}\\)</li> <li>\\(\\{\\text{Toffoli}, H\\}\\)</li> </ul> </li> </ul> <p>For any fixed universal set \\(\\mathcal{S}\\), a generic unitary matrix on n qubits requires exponentially many elementary gates n to be implemented - this follows from the fact that an n-qubit unitary is determined by \\(O(4^n)\\) real parameters. Goal of quantum computing is to find efficient quantum circuits which use poly(n) qubits and poly(n) elementary gates to solve a problem on an input size n.</p>"},{"location":"qip1/ch3b.html#36-simulating-classical-circuits-on-a-quantum-machine-leftmathbfb-p-p-subset-mathbfb-q-pright","title":"3.6. Simulating Classical Circuits on a Quantum Machine \\(\\left(\\mathbf{B P P} \\subset \\mathbf{B Q P}\\right)\\)","text":"<p>A classical circuit is a sequence of logical operations that act on a small number of bits (AND, OR, NOT). We claim that quantum computation is at least as powerfull as classical computation \\(\\mathbf{B P P} \\subset \\mathbf{B Q P}\\). However, the difficulty in proving it arise when we try to translate irreversible classical operations, such as AND or OR, to quantum gates.Quantum operations are unitary, hence reversible. This poses a problem:</p> <p>The crucial step in showing that one can simulate any classical circuit with a quantum circuit involves showing that any classical boolean operation (even irreversible) can be represented through reversible operation on larger hilbert space. The key point is that if we operate with unitaries on a larger space, but we only look at the subspace, it will look like the operation is non-unitary, (irreversible).</p> <p>Claim: If \\(f: B_m \\rightarrow B_n\\) is a Boolean function it can be expressed in an equivalent reversible form \\(\\tilde{f}: B_{m+n} \\rightarrow B_{m+n}\\).</p> <p>Remark: The claim by itself is simply logic and has nothing to do with quantum computing.</p> <p>Proof: Consider an binary addition operation \\(\\oplus\\) (adding mod 2). For any \\(f: B_m \\rightarrow B_n\\) define \\(\\tilde{f}:B_{m+n}\\rightarrow B_{m+n}\\), where \\(\\tilde{f}(b, c)=(b, c \\oplus f(b))\\). Such function is reversible, as applying the function twice results in \\((b, c \\oplus f(b) \\oplus f(b)) = (b, c \\oplus 0) = (b, c)\\). If we initialise the second register with \\(c=0...0\\), then \\(\\tilde{f}(b, c) = (b, f(b))\\).</p> <p>Conclusion: Through this we satisfied our requirement to represent an irreversible function \\(f\\) as a reversible function \\(\\tilde{f}\\). By replacing all (now reversible) classical gates with quantum gates, one can obtain quantum circuit that simulates the classical one.</p>"},{"location":"qip1/ch3b.html#37-oracle-for-boolean-function","title":"3.7. Oracle for Boolean function:","text":""},{"location":"qip1/ch3b.html#quantum-oracle","title":"Quantum Oracle","text":"<p>A quantum oracle for any Boolean function \\(f:B_n\\rightarrow B_m\\) will be the quantum gate denoted \\(O_f\\) on \\(n+m\\) qubits defined by its action on basis states as follows. Sometimes we refer to n-qubit register \\(\\left|x\\right&gt;\\) and the m-qubit register \\(\\left|y\\right&gt;\\) as the input and output registers respectively $$ O_f\\left|x\\right&gt;\\left|y\\right&gt;=\\left|x\\right&gt;\\left|y \\oplus f(x)\\right&gt; \\quad \\text { for all } x \\in B_n \\text { and } y \\in B_m $$</p>"},{"location":"qip1/ch3b.html#phase-oracle","title":"Phase Oracle","text":"<p>A phase oracle will be quantum gate denoted \\(U_f\\) on \\(n+m\\) qubits defined by its action on basis states as follows  $$ U_f\\left|x\\right&gt;=(-1)^{f(x)}\\left|x\\right&gt; $$</p> <p>This can be achieved through \\(O_f\\) $$ O_f\\left|x\\right&gt;\\left|-\\right&gt;=O_f \\left|x\\right&gt; \\frac{1}{\\sqrt{2}}(\\left|0\\right&gt;-\\left|1\\right&gt;)=\\frac{1}{\\sqrt{2}}(\\left|x\\right&gt;\\left|f(x)\\right&gt;-\\left|x\\right&gt;\\left|1 \\oplus f(x)\\right&gt;)=(-1)^{f(x)}\\left|x\\right&gt;\\left|-\\right&gt; $$</p>"},{"location":"qip1/ch3b.html#38-query-complexity","title":"3.8. Query Complexity:","text":"<p>Let us for a second come back to the complexity classes. In computation it is quite often tricky to consider all gates that are involved in the circuit. But in the end, quite often, we dont care what is the exact time complexity of the circuit. What we rather care about, is how does the complexity of the classical algorithm compares with the complexity of the quantum algorithm.</p> <p>And for this, we can group the gates into queries - both for classical computation and for quantum computation. For instance, an oracle function \\(O_f\\) is just a collection of gates. We also know that the complexity of the quantum oracle is at least as efficient as the classical oracle.</p> <p>This means that if we find that the quantum algorithm is more efficient in the number of queries than the classical algorithm, then the quantum time complexity is definitely better than the classical one.</p> <p>Query complexity is the number of times we need to apply the oracle to the circuit.</p>"},{"location":"qip1/ch3b.html#39-computation-by-quantum-parallelism","title":"3.9. Computation by quantum parallelism:","text":"<p>Now we can talk about what happens when we apply the oracle to a state in a superposition. This is the heart of what makes quantum computers powerful. Consider we have a state in a superposition of all possible inputs \\(\\left|\\psi\\right&gt; = \\frac{1}{\\sqrt{2^n}}\\sum_x\\left|x\\right&gt;\\left|0\\right&gt;\\). Then if we apply the oracle to this state, we get:</p> \\[ O_f\\left|\\psi\\right&gt; = \\frac{1}{\\sqrt{2^n}}\\sum_x O_f\\left|x\\right&gt;\\left|0\\right&gt; = \\frac{1}{\\sqrt{2^n}}\\sum_x \\left|x\\right&gt;\\left|f(x)\\right&gt; \\] <p>This is what we call the computation by quantum parallelism. Fundamentally this is what differentiates quantum computing from classical computing. In classical computing we cannot have states that are in superposition of different inputs. In quantum computing we can, and this allows us to compute the function in parallel for all possible inputs.</p> <p>Problem however is that we dont have a conclusive result from this, if we don't do anything with the result. Consider we now perform a projective measurement on the first register. Then through measuring \\(\\left|x\\right&gt;\\), we can only learn the value of \\(f(x)\\) for a single \\(x\\). </p> <p>Therefore we need to be somewhat more smart what we do with the superposition. This is what you will learn in the next chapter, where we will show how to use the superposition to solve some problems. This is connected to the idea of using interference to solve problems.</p> <p>This subchapter needs some revision to get the point across</p>"},{"location":"qip1/ch3b.html#notes","title":"Notes:","text":"<ul> <li>Things we havent talk about in detail is the concept of universal sets of quantum gates, and the approximately universal sets of gates.</li> </ul>"},{"location":"qip1/ch4a.html","title":"Chapter 4a: DJ Style Algorithms:","text":""},{"location":"qip1/ch4a.html#41-deutsch-josza-dj-algorithm","title":"4.1. Deutsch-Josza (DJ) algorithm:","text":"<p>Problem: Given a function \\(f : \\{0,1\\}^n \\rightarrow \\{0, 1\\}\\) with a promise that a function is either constant or balanced the goal is to find out whether \\(f\\) is constant or balanced. Balanced means that it outputs 0 half of the time and 1 the other half of the time. Constant means that it always outputs the same thing (either 1 or 0).</p> <p>Remark: We will show that classical algorithm will require exponentially many queries to \\(f\\), namely \\(2^{n-2}\\) on average. Quantum algorithm will be able to determine whether f is constant or balanced in a single query. Notice here, that we are comparing the query complexity of both classical and quantum algorithms, not the time complexity. But as discussed in the previous chapter this fundamentally means that the quantum algorithm time complexity will be more efficient than the classical equivalent.</p>"},{"location":"qip1/ch4a.html#algorithm","title":"Algorithm:","text":"<p>This circuit corresponds to: 1. Applying \\(H^{\\otimes n} U_f H^{\\otimes n}\\left|0\\right&gt;^{\\otimes n}\\). 2. Evaluating the probability of \\(y = 0^n\\), which is equivalent to projecting the state onto \\(\\left|0\\right&gt;^{\\otimes n}\\) and taking the absolute value squared.</p> \\[ \\left|\\left&lt;0\\right|^{\\otimes n}H^{\\otimes n} U_f H^{\\otimes n}\\left|0\\right&gt;^{\\otimes n}\\right|^2 = \\begin{cases}1, &amp; \\text { if } f \\text { is constant } \\\\ 0, &amp; \\text { if } f \\text { is balanced }\\end{cases} \\]"},{"location":"qip1/ch4a.html#why-it-works","title":"Why it works?:","text":"<p>There is an explanation in the </p> <p>Explanation 1:</p> <p>What I want you to understand from this explanation is that if we have some sort of symmetric situation due to the measurement - the problem massively simplifies.</p> <p>Here the trick is to realise that operator can act either to the right or to the left. Acting on the left massively simplifies the problem:</p> \\[ \\left&lt;0\\right|^{\\otimes n}H^{\\otimes n} U_f H^{\\otimes n}\\left|0\\right&gt;^{\\otimes n} = \\left(\\frac{1}{\\sqrt{2^n}} \\sum_{x \\in\\{0,1\\}^n}\\left&lt;x\\right|\\right) U_f \\left(\\frac{1}{\\sqrt{2^n}} \\sum_{x' \\in\\{0,1\\}^n}\\left|x'\\right&gt;\\right) = \\frac{1}{2^n} \\sum_{x \\in\\{0,1\\}^n}\\left&lt;x\\right| U_f \\left|x\\right&gt; = \\begin{cases}\\pm 1, &amp; \\text { if } f \\text { is constant } \\\\ 0, &amp; \\text { if } f \\text { is balanced }\\end{cases} \\] <p>Because we have equal superposition of all x-values, then if \\(U_f\\) is balanced then they will all add up to \\(0\\), and if they are constant, they will add up to \\(\\pm 1\\).</p> <p>Therefore we get:</p> \\[ \\left|\\left&lt;0\\right|^{\\otimes n}H^{\\otimes n} U_f H^{\\otimes n}\\left|0\\right&gt;^{\\otimes n}\\right|^2 = \\begin{cases}1, &amp; \\text { if } f \\text { is constant } \\\\ 0, &amp; \\text { if } f \\text { is balanced }\\end{cases} \\] <p>As promised</p> <p>Explanation 2:</p> <p>Second explanation is more visual approach to the problem. It requires us to think about the problem slightly differently, which initially might seem more complicated, but then it becomes easier and more natural - I think it is very useful in subsequent problems such as Grover's algorithm</p> <p>We can represent each n-qubit computational basis state as a number corresponding to its binary value  - \\(\\left|0\\right&gt;_C = \\left|00...0\\right&gt;=\\left|0\\right&gt;^{\\otimes n}\\),  - \\(\\left|1\\right&gt;_C = \\left|00...01\\right&gt;\\),  - \\(\\left|2\\right&gt;_C = \\left|00...10\\right&gt;\\) - \u22ee - \\(\\left|2^n-1\\right&gt; = \\left|11...1\\right&gt;\\)</p> <p>Each quantum state \\(\\left|x\\right&gt;_C\\) can be represented as a delta function \\(\\delta(x)\\) on the x-axis, where \\(x\\) ranges from 0 to \\(2^n-1\\).</p> <p>Then let's run through the algorithm step by step:</p> <ol> <li>Initially we have the state \\(\\left|0\\right&gt;_C\\)</li> </ol> <p></p> <ol> <li>Then we apply Haddamard on the \\(\\left|0\\right&gt;_C\\) state, which results in the equal superposition of all states in \\(\\left|x\\right&gt;_C\\) basis</li> </ol> <p></p> <ol> <li>Then we apply \\(U_f\\) operator, which effectively flips the phase of half of the \\(\\left|x\\right&gt;_C\\) states if its balanced, otherwise it flips either all or none of them</li> </ol> <p></p> <ol> <li>Finally we project it onto the equal superposition of all \\(\\left|x\\right&gt;_C\\) states</li> </ol> <p></p> <p>The result is that if half of the states are flipped, then when we project it onto the equal superposition of all \\(\\left|x\\right&gt;_C\\) states, we will measure it with probability 0, and if all the states are flipped, then we will measure it with probability 1</p>"},{"location":"qip1/ch4b.html","title":"Chapter 4b: Grover's Style Algorithms:","text":""},{"location":"qip1/ch4b.html#42-grovers-algorithm","title":"4.2. Grover's algorithm:","text":"<p>Grover's paper</p> <p>Problem - Unstructured search: Given an access to a computable function \\(f(x) : \\{0,1\\}^n \\rightarrow \\{0,1\\}\\) we want to find some \\(x\\) such that \\(f(x_0) = 1\\), for a unique 'marked' element \\(x_0\\in\\{1,...,N\\}\\).</p> <p>Grover's algorithm is an algorithm which has a large range of applications and is a beautiful example of how quantum mechanics allows us to speed up many problems. But, in words of Scott Aaronson,  the speed up is rather modest, as it is only quadratic. </p> <p>Consider above problem in the classical setting. On average one would have to query \\(N/2\\) elements to find the marked one, which means that the average time complexity is \\(O(N)\\). In contrast, quantum algorithm will be able to find the marked element in \\(O(\\sqrt{N})\\) time. In the chapter below we will try to see how it is achieved.</p>"},{"location":"qip1/ch4b.html#algorithm","title":"Algorithm:","text":"<p>This circuit corresponds to: 1. Applying \\(\\left(-H^{\\otimes n} U_0 H^{\\otimes n} U_f\\right)^{N_{\\text {optimal }}} H^{\\otimes n} \\left|0\\right&gt;^{\\otimes n}\\) 2. Measuring the resulting state</p>"},{"location":"qip1/ch4b.html#why-it-works","title":"Why it works?:","text":"<p>I would like to present here two geometric explanations why Grover's algorithm works. I would recommend you to think about both of them, as both of them allow you to understand different things about the algorithm. Explanation 2 is the standard one and is probably a way how to think about Grover's algorithm. However I think that when Grover was trying to come up with the algorithm he was thinking about Explanation 1, which then led to Explanation 2. You will see this smooth transition in the explanation (and not so smooth transition in my writing :) ).</p>"},{"location":"qip1/ch4b.html#explanation-1-amplitude-amplification","title":"Explanation 1: Amplitude amplification:","text":"<p>Definitions:</p> <p>Before we start with the explanation, let's re-write the operators in Grover's algorithm in a slightly different way. </p> <ul> <li>Lets define good and bad states as:</li> <li>\\(\\left|g\\right&gt; = \\left|x_0\\right&gt;\\)</li> <li>\\(\\left|b\\right&gt; = \\frac{1}{\\sqrt{N-1}} \\sum_{x\\neq x_0} \\left|x\\right&gt; = \\frac{\\sqrt{N}}{\\sqrt{N-1}}\\left|+\\right&gt; - \\frac{1}{\\sqrt{N-1}} \\left|g\\right&gt;\\)</li> <li>And let's define plus and minus states as:</li> <li>\\(\\left|+\\right&gt; = \\frac{1}{\\sqrt{N}} \\sum_x \\left|x\\right&gt; = H^{\\otimes n} \\left|0\\right&gt;^{\\otimes n} = \\frac{1}{\\sqrt{N}}\\left|g\\right&gt; + \\frac{\\sqrt{N-1}}{\\sqrt{N}}\\left|b\\right&gt;\\)</li> <li>\\(\\left|-\\right&gt; = - \\frac{1}{\\sqrt{N}}\\left|g\\right&gt; + \\frac{\\sqrt{N-1}}{\\sqrt{N}}\\left|b\\right&gt;\\)</li> <li>\\(U_f\\) is just a phase oracle, which flips the phase of the marked element. We can rewrite it as \\(U_f = I - 2 \\left|x_0\\right&gt;\\left&lt;x_0\\right|\\)</li> <li>\\(U_0\\) flips the phase of the \\(\\left|0\\right&gt;^{\\otimes n}\\) state. This means that \\(H^{\\otimes n} U_0 H^{\\otimes n} = H^{\\otimes n} \\left(I - 2 \\left|0\\right&gt;\\left&lt;0\\right|^{\\otimes n}\\right) H^{\\otimes n} = I - 2 \\left|+\\right&gt;\\left&lt;+\\right|\\)</li> </ul> <p>Therefore the circuit can be re-writen as:</p> \\[ \\left(-\\underbrace{\\left(I - 2\\left|+\\right&gt;\\left&lt;+\\right|\\right)}_{H^{\\otimes n} U_0 H^{\\otimes n}}\\underbrace{\\left(I - 2\\left|g\\right&gt;\\left&lt;g\\right|\\right)}_{U_f}\\right)^{N_{\\text {optimal }}} \\left|+\\right&gt; \\] <p>Action of the operator on the plus state:</p> <p>Let's consider then the action of the operator on the plus state \\(\\left|+\\right&gt;\\):</p> \\[ \\begin{aligned} -\\left(I - 2\\left|+\\right&gt;\\left&lt;+\\right|\\right)\\left(I - 2\\left|g\\right&gt;\\left&lt;g\\right|\\right)\\left|+\\right&gt;  &amp;= -\\left(I - 2\\left|+\\right&gt;\\left&lt;+\\right|\\right)\\left(\\left|+\\right&gt; - \\frac{2}{\\sqrt{N}}\\left|g\\right&gt;\\right)  \\\\&amp;= -\\left(\\left|+\\right&gt; - \\frac{2}{\\sqrt{N}}\\left|g\\right&gt; - 2\\left|+\\right&gt; + \\frac{4}{N} \\left|+\\right&gt;\\right)  \\\\&amp;= \\left(\\left(1 - \\frac{4}{N}\\right)\\left|+\\right&gt; + \\frac{2}{\\sqrt{N}}\\left|g\\right&gt;\\right) \\end{aligned} \\] <p>This can be visualised as:</p> <p></p> <p>We can see how each step of the algorithm has a specific purpose.  - \\(U_f\\) is an operation that flips the phase of the target state.  - \\(H^{\\otimes n} U_0 H^{\\otimes n}\\) when applied to \\(\\left|\\psi\\right&gt;\\) performs interference between the wavefunction \\(\\left|\\psi\\right&gt;\\) and \\(-2\\left|+\\right&gt;\\left&lt;+|\\psi\\right&gt;\\), effectively shifting the whole wavefunction down by \\(2\\left|+\\right&gt;\\left&lt;+|\\psi\\right&gt;\\). - Minus sign inverts the amplitude of the wavefunction, and is done only for convenience of thinking about the algorithm, but has no real purpose. </p> <p>Can one infinitely amplify the amplitude?:</p> <p>Seeing how does Grover's step affect the \\(\\left|+\\right&gt;\\) state, we can see that the amplitude of the \\(\\left|+\\right&gt;\\) state is attenuated by a factor of \\(\\left(1 - \\frac{4}{N}\\right)\\). One could then get hopefull and think that we should just apply the Grover's step enough times to get rid of the amplitude completely. This is, however, not the case. One can spot now the problem with Grover's algorithm. The approach only works when the phase of marked element is the same as the phase of non-marked elements:</p> <p></p> <p>Then instead of the amplitude amplification we will get amplitude destruction. Will it ever occur? Yes it will! If we keep going with the algorithm for too long then we will first attenuate the amplitude of the \\(\\left|+\\right&gt;\\) state to zero, but we will not always decrease the amplitude of the bad state. Some amount of the amplitude in the good state \\(\\left|g\\right&gt;\\) will contribute to the shift introducted by \\(H^{\\otimes n} U_0 H^{\\otimes n}\\), introducing shift of \\(2\\left&lt;+|\\psi\\right&gt;\\). This will cause eventual overshoot and we will end up in the phase of the bad state being opposite to the phase of the good state. This will continue in a cycle.</p> <p>Grover's step for a general state \\(\\left|\\psi\\right&gt;\\):</p> <p>Consider now the general case. Starting with the state: \\(\\left|\\psi\\right&gt; = \\alpha\\left|g\\right&gt; + \\beta\\left|b\\right&gt;\\). Lets write it in a vector form: - \\(\\left|\\psi\\right&gt; = \\begin{pmatrix}\\alpha \\\\ \\beta\\end{pmatrix}\\) - \\(U_f = \\begin{pmatrix}-1 &amp; 0 \\\\0 &amp; 1\\end{pmatrix}\\) - \\(U_0 = \\begin{pmatrix}\\cos\\theta &amp; \\sin\\theta \\\\-\\sin\\theta &amp; \\cos\\theta\\end{pmatrix} \\begin{pmatrix}-1 &amp; 0 \\\\0 &amp; 1\\end{pmatrix} \\begin{pmatrix}\\cos\\theta &amp; -\\sin\\theta \\\\\\sin\\theta &amp; \\cos\\theta\\end{pmatrix}\\)</p> <p>, where \\(\\cos\\theta = \\sqrt{\\frac{1}{N}}\\) and \\(\\sin\\theta = \\sqrt{\\frac{N-1}{N}}\\).</p> <p>Then the Grover's step is:</p> \\[ \\begin{aligned} - H^{\\otimes n} U_0 H^{\\otimes n} U_f \\left|\\psi\\right&gt; &amp;=  \\begin{pmatrix} -1 &amp; 0 \\\\ 0 &amp; -1 \\end{pmatrix} \\begin{pmatrix} \\cos\\theta &amp; \\sin\\theta \\\\ -\\sin\\theta &amp; \\cos\\theta \\end{pmatrix} \\begin{pmatrix} 1 &amp; 0 \\\\ 0 &amp; -1 \\end{pmatrix} \\begin{pmatrix} \\cos\\theta &amp; -\\sin\\theta \\\\ \\sin\\theta &amp; \\cos\\theta \\end{pmatrix} \\begin{pmatrix} -1 &amp; 0 \\\\ 0 &amp; 1 \\end{pmatrix} \\begin{pmatrix} \\alpha \\\\ \\beta \\end{pmatrix} \\\\ &amp;= \\begin{pmatrix} \\cos 2\\theta &amp; \\sin 2\\theta \\\\ -\\sin 2\\theta &amp; \\cos 2\\theta \\end{pmatrix} \\begin{pmatrix} \\alpha \\\\ \\beta \\end{pmatrix} \\end{aligned} \\] <p>One can then imidietely see that attenuation of the amplitude of the bad state after Grover's step is \\(\\beta' = \\beta \\cos 2\\theta - \\alpha \\sin 2\\theta\\). This means that the amplitude of the good state and the bad state contribute with an opposite sign to the ampltiude of the bad state after Grover's step.</p> <p>This can be then visualised as rotation of the state \\(\\left|\\psi\\right&gt;\\) around the \\(\\left|+\\right&gt;\\) state by an angle of \\(2\\theta\\) in anti-clockwise direction.</p> <p></p> <p>Why is then the complexity of the algorithm \\(O(\\sqrt{N})\\)? Well to get from a bad state to a good state we need to rotate the state by an angle of \\(\\pi/2\\). This means that we need to rotate \\(\\frac{\\pi/2}{2\\theta}\\) times. As \\(\\theta \\approx \\sin \\theta = \\sqrt{\\frac{1}{N}}\\) we get that we need to rotate \\(\\frac{\\pi/2}{2\\sqrt{\\frac{1}{N}}} = \\frac{\\pi}{4}\\sqrt{N}\\) times. This gives \\(O(\\sqrt{N})\\) iterations.</p>"},{"location":"qip1/ch4b.html#explanation-2-rotations-around-2d-plane","title":"Explanation 2: Rotations around 2D-plane:","text":"<p>not finished</p>"},{"location":"qip1/ch4c.html","title":"Chapter 4c: Quantum Fourier Transform, Period Finding Algorithm:","text":""},{"location":"qip1/ch4c.html#43-discrete-fourier-transform-and-quantum-fourier-transform","title":"4.3. Discrete Fourier Transform and Quantum Fourier Transform:","text":"<p>Quantum Fourier Transform (QFT) in dimension N: defined on the computational basis \\(\\{\\left|x\\right&gt; \\}^{N-1}_{x=0}\\) as the map:</p> \\[ \\mathcal{Q}_N\\left|x\\right&gt; := \\frac{1}{\\sqrt{N}} \\sum_{y=0}^{N-1} \\left( e^{2\\pi i /N } \\right)^{xy} \\left|y\\right&gt; \\] <p>, where \\(xy\\) is a product of two integers</p> <p>This is rather straighforward definition, and it is not so different from the classical Discrete Fourier Transform. Few examples of the QFT matrices for different dimensions are:</p> \\[ Q_2=\\frac{1}{\\sqrt{2}}\\left(\\begin{array}{cc} 1 &amp; 1 \\\\ 1 &amp; -1 \\end{array}\\right), \\quad Q_3=\\frac{1}{\\sqrt{3}}\\left(\\begin{array}{ccc} 1 &amp; 1 &amp; 1 \\\\ 1 &amp; e^{2 \\pi i / 3} &amp; e^{-2 \\pi i / 3} \\\\ 1 &amp; e^{-2 \\pi i / 3} &amp; e^{2 \\pi i / 3} \\end{array}\\right), \\quad Q_4=\\frac{1}{2}\\left(\\begin{array}{cccc} 1 &amp; 1 &amp; 1 &amp; 1 \\\\ 1 &amp; i &amp; -1 &amp; -i \\\\ 1 &amp; -1 &amp; 1 &amp; -1 \\\\ 1 &amp; -i &amp; -1 &amp; i \\end{array}\\right) \\] <p>Let's focus on the matrix \\(\\mathcal{Q}_4\\), and try to understand how it transforms a vector \\(\\left|x\\right&gt;\\). To do this we should consider first the matrix multiplication. When one multiplies the matrix \\(\\mathcal{Q}_4\\) with a vector \\(x\\), \\(\\left(y = \\mathcal{Q}_4 x\\right)\\), then for each element of \\(y\\), one performs a dot product of \\(x\\) with the i-th row of the matrix. As each consecutive row of the matrix is a vector that rotates in complex space with some angular frequency, the dot product effectively picks up, the component of \\(x\\) with this given angular frequency i.e. performs a Fourier Transform.</p> <p></p> <p>We can see the pattern of this matrix - first row is a vector that roates with angular frequency of \\(0 \\frac{2\\pi}{4}\\), second row with angular frequency of \\(1 \\frac{2\\pi}{4}\\), third row with angular frequency of \\(2\\frac{2\\pi}{4}\\) and the last row with angular frequency of \\(3\\frac{2\\pi}{4}\\). </p> <p>More generally, the QFT can be written as a following matrix:</p> \\[ \\mathcal{Q}_N=\\frac{1}{\\sqrt{N}}\\left(\\begin{array}{cccccc} 1 &amp; 1 &amp; 1 &amp; 1 &amp; \\cdots &amp; 1 \\\\ 1 &amp; \\omega &amp; \\omega^2 &amp; \\omega^3 &amp; \\cdots &amp; \\omega^{N-1} \\\\ 1 &amp; \\omega^2 &amp; \\omega^4 &amp; \\omega^6 &amp; \\cdots &amp; \\omega^{2(N-1)} \\\\ 1 &amp; \\omega^3 &amp; \\omega^6 &amp; \\omega^9 &amp; \\cdots &amp; \\omega^{3(N-1)} \\\\ \\vdots &amp; \\vdots &amp; \\vdots &amp; \\vdots &amp; &amp; \\vdots \\\\ 1 &amp; \\omega^{N-1} &amp; \\omega^{2(N-1)} &amp; \\omega^{3(N-1)} &amp; \\cdots &amp; \\omega^{(N-1)(N-1)} \\end{array}\\right) \\] <p>, where \\(\\omega = e^{2\\pi i / N}\\)</p> <p>For a general \\(\\mathcal{Q}_N\\) the i-th row is a vector that rotates with angular frequency of \\(i \\frac{2\\pi}{N}\\). When multiplied with the vector the i-th element of the resulting vector is a dot product of \\(x\\) with the i-th row of the matrix, hence picking up the component of \\(x\\) with the angular frequency of \\(i \\frac{2\\pi}{N}\\).</p>"},{"location":"qip1/ch4c.html#44-efficient-implementation-of-qft","title":"4.4. Efficient Implementation of QFT:","text":"<p>Classically Discrete Fourier Transform can be implemented on a classical computer in time \\(O(N\\log N)\\) using Fast Fourier Transform (FFT) algorithm. We want to show in the following that we can implement QFT applied to n qubits in time \\(O(n^2)\\). This means that the QFT can be implemented in \\(O(\\log^2N)\\) time complexity on a quantum computer.</p> <p>Let's start with the definition of QFT:</p> \\[ \\mathcal{Q}_N\\left|x\\right&gt; := \\frac{1}{\\sqrt{N}} \\sum_{y=0}^{N-1} \\left( e^{2\\pi i /N } \\right)^{xy} \\left|y\\right&gt; \\] <p>Representing \\(x\\), and \\(y\\) by n-bit strings:</p> \\[ x = x_{n-1}2^{n-1} + x_{n-2}2^{n-2} + ... + x_0 \\] \\[ y = y_{n-1}2^{n-1} + y_{n-2}2^{n-2} + ... + y_0 \\] <p>Now:</p> \\[ xy = \\sum_{j=0}^{n-1}x\\left(y_j 2^j\\right) \\] <p>and so:</p> \\[ \\begin{aligned} \\sum_y e^{2 \\pi i \\frac{x y}{2^n}}\\left|y\\right&gt; &amp;=\\sum_{y_0, \\ldots, y_{n-1} \\in \\{0,1\\}} e^{2 \\pi i \\frac{x y}{2^n}}\\left|y_{n-1}\\right&gt;\\left|y_{n-2}\\right&gt; \\ldots\\left|y_0\\right&gt; \\\\ &amp;=  \\left(\\sum_{y_0 \\in \\{0,1\\}} e^{2 \\pi i \\frac{x\\left(y_0 2^0\\right)}{2^n}}\\left|y_0\\right&gt; \\right)\\ldots\\left(\\sum_{y_{n-1} \\in \\{0,1\\}} e^{2 \\pi i \\frac{x\\left(y_{n-1} 2^{n-1}\\right)}{2^n}}\\left|y_{n-1}\\right&gt; \\right) \\\\ &amp; = \\left( \\left|0\\right&gt;_0 +  e^{2 \\pi i \\frac{x\\left(2^0\\right)}{2^n}}\\left|1\\right&gt;_0 \\right)\\ldots\\left( \\left|0\\right&gt;_{n-1} +  e^{2 \\pi i \\frac{x\\left(2^{n-1}\\right)}{2^n}}\\left|1\\right&gt;_{n-1} \\right) \\\\ &amp; = \\left( \\left|0\\right&gt;_0 +  e^{2 \\pi i \\frac{\\left(\\sum_{x_i} x_i 2^i\\right)\\left(2^0\\right)}{2^n}}\\left|1\\right&gt;_0 \\right)\\ldots\\left( \\left|0\\right&gt;_{n-1} +  e^{2 \\pi i \\frac{\\left(\\sum_{x_i} x_i 2^i\\right)\\left(2^{n-1}\\right)}{2^n}}\\left|1\\right&gt;_{n-1} \\right)  \\end{aligned} \\] <p>This would quite easy to implement on a quantum computer. We just need to apply a Haddamard gate, and then rotate phase of j'th qubit controlled on each i'th qubit by \\(\\frac{2\\pi 2^j 2^i}{2^n} = \\frac{\\pi}{2^{n-i-j-1}}\\). We can achieve this with a controlled \\(R_d\\) gate which rotates a qubit in a following way:</p> \\[ R_d:=\\left(\\begin{array}{cc} 1 &amp; 0 \\\\ 0 &amp; e^{\\pi i / 2^d} \\end{array}\\right) \\] <p>The circuit would look like this.</p> <p></p> <p>But you might notice that for some of the controlled \\(R_d\\) gates, the \\(d &lt; 0\\). For such gates the rotation is by a integer multiple of \\(2\\pi\\), and so effectively such gates do not contribute to the final result. We can skip applying such gates.</p> <p></p> <p>Secondly what we can notice that applying a \\(R_0\\) gate to \\(H \\left|0\\right&gt;_i\\) controlled on a j'th qubit is equivalent to applying a \\(H\\) gate directly to the j'th qubit.</p> <p>i.e. </p> <p></p> <p>This means that we can rewrite this circuit in a much simpler form, where we reuse the original qubits.</p> <p></p> <p>As you can see the order of the outputs is reversed relative to the input. The original order can be restored by using n/2 SWAP operations.</p> <p>Query complexity for this circuit is \\(\\left(n\\right)\\left(n-1\\right)\\ldots\\left(1\\right) = O(n^2)\\)</p>"},{"location":"qip1/ch4c.html#45-period-finding-algorithm","title":"4.5 Period Finding Algorithm:","text":"<p>Problem and promises: Suppose we are given a black box function \\(f:\\left\\{0,1\\right\\}^n \\rightarrow \\left\\{0,1\\right\\}^m\\) with a promise that:  - \\(f\\) is periodic, with a period \\(r\\) such that \\(f(x+r)=f(x)\\) for all \\(x\\) - \\(f\\) is a one-to-one function in each period i.e. \\(f(x_1) \\neq f(x_2)\\)  for all \\(0 \\leq x_1, x_2 &lt; r\\).</p> <p>The goal is to find the period \\(r\\) of the function \\(f\\).</p> <p>Algorithm:</p> <p></p> <p>So the algorithm runs in a following way. We first start with \\(n+m\\) qubits. Then we prepare a superposition of all basis states \\(\\{\\left|x\\right&gt; \\}\\) on the \\(n\\) qubits. We then apply a bit oracle \\(O_f\\), which entangles n qubits with m qubits - effectively grouping the \\(\\{ x_0, x_0+r, x_0+2r, ... \\}\\) together and associating them with some value in the m-register \\(f(x_0)\\). Upon measuring the m-register we get a value of \\(f(x_0)\\), which collapses the n-register into a superposition of states \\(\\{ \\left|x_0\\right&gt;, \\left|x_0+r\\right&gt;, \\left|x_0+2r\\right&gt;, ... \\}\\).</p> <p>Now you might think - this is it! If I measure this n-register enough times, then I will definitely find the value of \\(r\\). You will realise upon measuring the m-register for the second time that the n-register collapses into a superposition of \\(\\{ \\left|x_0'\\right&gt;, \\left|x_0'+r\\right&gt;, \\left|x_0'+2r\\right&gt;, ... \\}\\) and so on. Damn! We got different numbers! To make sure that we are insensitive to the value of \\(x_0\\) we need to apply QFT to the n-register. After applying QFT we always end up in the superpiosition of the periods which are multiples of \\(r\\) and invariant to the value of \\(f(x_0)\\) being measured during the first measurement.</p> <p>Step by step state evolution:</p> <ol> <li>Apply the \\(H^{\\otimes n}\\) gate to the n-register: $\\left|0\\right&gt;_m\\left|+\\right&gt;_n = H_n\\left|0\\right&gt;_m\\left|0\\right&gt;_n $</li> <li>Apply the bit oracle \\(O_f\\): \\(\\left|0\\right&gt;_m\\left|+\\right&gt;_n \\rightarrow \\sum_{x_0=0}^{r-1} \\left|f(x_0)\\right&gt;_m\\left(\\left|x_0\\right&gt; + \\left|x_0+r\\right&gt; + \\left|x_0+2r\\right&gt; + ... \\right)_n\\)</li> <li>Measure the m-register getting a result \\(f(x_0)\\) and collapsing the n-register into a superposition of states \\(\\left|period\\right&gt; =  \\left|x_0\\right&gt;+ \\left|x_0+r\\right&gt; + \\left|x_0+2r\\right&gt; + ...\\)</li> <li>Apply the QFT to the n-register: \\(\\mathcal{Q}_{2^n}\\left|per\\right&gt; = \\sum_{k=0}^{r-1} \\left|kN/r\\right&gt;\\)</li> <li>Measure the n-register and get the value of \\(r\\)</li> </ol> <p></p> <p>Post Processing: So now the measurement of the n-register will give us values of \\(c = kN/r\\). Is this enough to find the value of \\(r\\)? With help comes number theory.</p> <p>There are two options:</p> <ol> <li>k and r are co-prime to each other -  it means that \\(\\frac{k}{r}\\) is the irreducible fraction, which means that by finding irreducible fraction of \\(\\frac{c}{N}\\) gives us directly the values of \\(k\\) and \\(r\\). Simple!</li> <li>k and r aren't co-prime to each other - it means that \\(k\\), and \\(r\\) share a common factor, and so the irreducible fraction of \\(\\frac{c}{N}\\) will give us some \\(\\frac{k/m}{r/m}\\).</li> </ol> <p>This means that each time we can simply test, whether \\(f(x_0)=f(x_0+r)\\) and if not, discard the result and try again.</p> <p>Theorem 1:(Coprimality theorem) The number of integers less than r that are co-prime to r grows as \\(O(\\frac{r}{\\log \\log r})\\) with increasing r. Hence if \\(k &lt; r\\) is chosen at random, then the probability that \\(k\\) is co-prime to \\(r\\) is \\(O(\\frac{1}{\\log \\log r})\\).</p> <p>As each measurement is independent then repeating the whole process \\(O(\\log \\log r)&lt;O(\\log \\log N)\\) times gives us the result with constant probability.</p>"},{"location":"qip1/ch4c.html#46-phase-estimation-algorithm","title":"4.6 Phase Estimation Algorithm:","text":""},{"location":"qip1/ch5.html","title":"Chapter 5: Shor's Algorithm:","text":"<p>Shor's algorithm is probably one of the most famous quantum algorithms, and the reason for interest of various militaries around the world in quantum computing. It is connected to RSA encryption, which basically is the foundation of the internet privacy as we know it. Breaking it, would have huge implications on everything we do. Breaking RSA can be reduced to factoring large numbers.</p>"},{"location":"qip1/ch5.html#51-introduction","title":"5.1 Introduction:","text":"<p>Problem: Given an integer \\(N\\), output a factor \\(1 &lt; K &lt; N\\). with any chosen constant level of probability \\((1-\\epsilon)\\), and the algorithm will run in polynomial time \\(O(n^3)\\).</p>"},{"location":"qip1/ch5.html#52-factoring-as-a-periodicity-problem","title":"5.2. Factoring as a periodicity problem:","text":"<p>The approach we will take is to transform the factoring problem into a periodicity problem. And then we will show that we can solve the periodicity problem efficiently with a quantum algorithm.</p> <p>Theorem: (Euler's theorem) If \\(a\\) and \\(N\\) are coprime, then there is a least power \\(1&lt;r&lt;N\\) such that \\(a^r\\equiv 1 \\pmod{N}\\). This \\(r\\) is called the order of \\(a\\) mod \\(N\\).</p> <p>Using Euler's theorem we can show that \\(f(k) = a^k \\pmod{N}\\) is periodic with period \\(r\\). This is because </p> \\[ f(k + r) = a^{k+r} \\pmod{N} = a^k a^r \\pmod{N} = a^k \\pmod{N} = f(k) \\] <p>Suppose that we find the period \\(r\\) of \\(f(k)\\) and this period \\(r\\) is even. Then we can re-write our original statement as:</p> \\[ a^r - 1 = (a^{r/2} - 1)(a^{r/2} + 1) \\equiv 0 \\pmod{N} \\] <p>\\(N\\) does not divide \\(a^{r/2} - 1\\), therefore \\(N\\) must either (a) divide \\(a^{r/2} + 1\\) or (b) partly divide into \\(a^{r/2} + 1\\) and partly into \\(a^{r/2} - 1\\). If it partly divides into \\(a^{r/2} + 1\\), we can use classically efficient euclids algorithm \\(gcd(a^{r/2} + 1, N)\\) to find a non-trivial factor of \\(N\\). Therefore, if we pick \\(a\\) at random then, assuming \\(r\\) is even and \\(a^{r/2}+1\\) is not divisible by \\(N\\), we can classically find a non-trivial factor of \\(N\\).</p> <p>Theorem: Suppose \\(N\\) is odd and not a power of a prime. If \\(a&lt;N\\) is chosen uniformly at random with \\(gcd(a,N)=1\\) then \\(Prob(\\text{r is even and } a^{r/2}\\not\\equiv -1 \\pmod{N})\\) is at least \\(1/2\\).</p>"},{"location":"qip1/ch5.html#53-algorithm","title":"5.3. Algorithm:","text":"<ol> <li>Is N even? If so, output 2 and stop</li> <li>Choose \\(a\\) at random from 1 to \\(N-1\\) and compute \\(gcd(a,N)\\). If \\(gcd(a,N) \\neq 1\\) then we are done.</li> <li>If s=1 find the period r of the sequence \\(a^k \\pmod{N}\\). If r is odd or \\(a^{r/2} \\equiv -1 \\pmod{N}\\), then go back to step 2.</li> <li>Otherwise \\(gcd(a^{r/2} + 1, N)\\) and \\(gcd(a^{r/2} - 1, N)\\) are non-trivial factors of \\(N\\).</li> </ol> <p>As you can see already here, everything about solving this problem boils down to the efficient implementation of fidning the period of r of \\(a^x \\pmod{N}\\). Following section will show how can we do it efficiently with a quantum algorithm.</p>"},{"location":"qip1/ch5.html#54-efficient-implementation-of-period-finding-of-ak-pmodn","title":"5.4. Efficient implementation of period finding of \\(a^k \\pmod{N}\\):","text":"<p>In the end what we need to do is to find the period \\(r\\) of the sequence \\(a^k \\pmod{N}\\). The circuit should be the same as the one for period finding algorithm. What we want to show is that each block of this circuit can be implemented efficiently.</p> <p></p> <p>We have already shown that the QFT can be implemented efficiently in terms of query complexity. If we want to know whether the algorithm can be efficient in terms of time-complexity, we need to consider how we can implement the bit oracle \\(O_f\\) efficiently. Efficient oracle \\(O_f\\) is equivalent to efficient implementation of \\(f(k) = a^k \\pmod{N}\\).</p>"},{"location":"qip1/ch5.html#541-efficient-implementation-of-fx-ax-pmodn","title":"5.4.1. Efficient implementation of \\(f(x) = a^x \\pmod{N}\\):","text":"<p>Using binary representation of \\(x\\) we can write:</p> \\[ x=x_{m-1} \\cdot 2^{m-1}+x_{m-2} \\cdot 2^{m-2}+\\ldots+x_0 \\] <p>therefore</p> \\[ a^x\\pmod{N}=\\left(a^{2^{m-1}}\\right)^{x_{m-1}}\\left(a^{2^{m-2}}\\right)^{x_{m-2}} \\ldots(a)^{x_0}\\pmod{N} \\] <p>we can write it recursively as:</p> \\[ a^{2j} \\pmod{N} = \\left(a^{2j-1}\\right)^2 \\pmod{N} \\] <p>This somewhat means that we can reuse the result of the previous computation to compute the next power of \\(a\\). This means that </p> <p></p> <p>Therefore if we prepare the first register in the state \\(\\sum_{x=0}^{N-1} \\left|x\\right&gt;\\), and the second register in the state \\(\\left|1\\right&gt;\\), then we will end up with the state:</p> \\[ \\sum_{x=0}^{N-1} \\left|x\\right&gt;\\left|1\\right&gt; \\rightarrow \\sum_{x=0}^{N-1} \\left|x\\right&gt; \\left|a^x \\bmod{N}\\right&gt; \\]"},{"location":"qip1/ch6.html","title":"Chapter 6: Density Matrix Formalism:","text":""},{"location":"qip1/ch6.html#60-extending-the-closed-quantum-system-formalism-to-consider-the-open-quantum-systems","title":"6.0. Extending the closed quantum system formalism to consider the open quantum systems:","text":"<p>The necessity for density matrix formalism arises from two reasons. Firstly, sometimes we are not quite sure about the state of the system. When this happens we dont want to be constrained to the pure states only. We need to describe such system with a probability distribution over the states. Secondly even if we are sure about the state of the system, then the unitary evolution of the larger system can be seen as non-unitary evolution on its subsystem. We would like to describe such evolution as well, as quite often we are not interested in the whole system, but only in some part of it. I will only briefly touch upon the formalism of the density matrices.</p>"},{"location":"qip1/ch6.html#61-density-matrix","title":"6.1. Density Matrix:","text":"<p>If you are not familiar with the density matrices - have a look at Philip Kammelander QIP notes. Here I will only provide a brief set of definitions. </p> <ul> <li>Density operator (also called density matrix), \\(\\rho\\), is defined as \\(\\rho = \\sum_i p_i \\left|\\psi_i\\right&gt;\\left&lt;\\psi_i\\right|\\)</li> <li>Set of quantum states \\(\\mathcal{S}\\left(\\mathcal{H}\\right)\\) is a set of density operators \\(\\mathcal{S}(\\mathcal{H}):=\\{\\rho \\in \\operatorname{LinMap}(\\mathcal{H}) \\mid \\rho \\geq 0 \\text { Hermitian, } \\operatorname{tr}(\\rho)=1\\}\\)</li> <li>\\(\\rho \\in \\mathcal{S}\\left(\\mathcal{H}\\right)\\) is called a pure if there exists \\(\\left|\\phi\\right&gt;\\in\\mathcal{H}\\) such that \\(\\rho = \\left|\\phi\\right&gt;\\left&lt;\\phi\\right|\\) has rank 1, which is equivalent to \\(\\text{tr}\\left(\\rho^2\\right)=1\\).</li> <li>Unitary evolution of a density operator is given by \\(\\rho \\mapsto U \\rho U^{\\dagger}=U\\left(\\sum_i p_i\\left|\\psi_i \\right&gt; \\left&lt;\\psi_i\\right|\\right) U^{\\dagger}=\\sum_i p_i U\\left|\\psi_i\\right&gt;\\left&lt;\\psi_i\\right| U^{\\dagger}\\)</li> <li>Projective measurement with outcomes labelled \\(\\{x\\}_x\\) is associated with set of projectors \\(\\{\\Pi_x\\}_x\\) satisfying \\(\\sum_x \\Pi_x = \\mathbb{I}\\). The probability of outcome \\(x\\) is given by \\(p(x) = \\text{tr}\\left(\\Pi_x \\rho\\right)\\) and the post-measurement state is given by \\(\\frac{\\Pi_x \\rho \\Pi_x}{\\text{tr}\\left(\\Pi_x \\rho\\right)}\\). This is nice as now we can describe the final state of the system after the measurement that was forgotten: </li> </ul> \\[ \\rho^{\\prime}=\\sum_x \\operatorname{Pr}[x \\mid \\rho] \\rho_x^{\\prime}=\\sum_x \\operatorname{tr}\\left(\\Pi_x \\rho\\right) \\frac{\\Pi_x \\rho \\Pi_x}{\\operatorname{tr}\\left(\\Pi_x \\rho\\right)}=\\sum_x \\Pi_x \\rho \\Pi_x \\]"},{"location":"qip1/ch6.html#62-partial-trace-system-rightarrow-subsystem","title":"6.2. Partial Trace: system \\(\\rightarrow\\) subsystem:","text":"<p>When we have access only to the subsystem \\(A\\) of the composite system \\(AB\\), the appropriate density operator is: </p> \\[ \\rho^A = \\text{tr}_B\\left(\\rho^{AB}\\right) \\] <p>If a global state is pure, then the reduced state is not necessarily pure. i.e. consider \\(\\rho_{A B}=\\left|\\psi^{00} \\right&gt;\\left&lt; \\psi^{00}\\right|_{A B}\\). Taking partial trace over subsystem \\(B\\) we get \\(\\rho^A = \\mathbb{I}_A/2\\), which is maximally mixed.</p>"},{"location":"qip1/ch6.html#63-purification-subsystem-rightarrow-system","title":"6.3. Purification: subsystem \\(\\rightarrow\\) system:","text":"<p>Consider somewhat opposite task of finding a global state \\(\\left|\\psi^{AB}\\right&gt;\\) given a reduced state \\(\\rho^A\\), s.t. \\(\\text{tr}_B\\left(\\left|\\psi^{AB}\\right&gt;\\left&lt;\\psi^{AB}\\right|\\right) = \\rho^A\\). \\(\\left|\\psi^{AB}\\right&gt;\\) is called purification of \\(\\rho^A\\). This means that any mixed state can be seen as pure state on a larger system, which is nice result. This means that things don't stop being quantum, but simply they start to entangle with all the enviornment. </p>"},{"location":"qip1/ch6.html#64-quantum-operations-evolution-and-allowed-operations-on-the-open-quantum-system","title":"6.4. Quantum Operations: Evolution and allowed operations on the open quantum system:","text":"<p>Given that we defined a more general formalism for the open quantum systems, we should also ponder over the allowed operations on such systems. For closed quantum system living in \\(\\mathcal{H}\\) the allowed operations was set of unitaries \\(\\mathcal{U}\\left(\\mathcal{H}\\right)\\) that maps the set of pure quantum states to itself. By opening up the system we extended the quantum states from hilbert space to the set of density operators \\(\\mathcal{H} \\rightarrow \\mathcal{S}\\left(\\mathcal{H}\\right)\\). We are interested in the most general maps that map this set to itself. Given that we already used up the name 'operator' to describe the operations on the closed system, we will call the operations on the open system 'superoperators', \\(\\mathcal{E}\\). \\(\\mathcal{E}\\) is expected to be: - linear: \\(\\mathcal{E}(p \\rho+q \\sigma)=p \\mathcal{E}(\\rho)+q \\mathcal{E}(\\sigma)\\) - trace preserving: \\(\\text{tr}\\left(\\mathcal{E}(\\rho)\\right) = \\text{tr}(\\rho)\\) - positive: \\(\\mathcal{E}(\\rho) \\geq 0\\) for all \\(\\rho \\geq 0\\) - this means that the eigenvalues of \\(\\mathcal{E}(\\rho)\\) are non-negative. - completely positive: We also would like for \\(\\mathcal{E}_A \\otimes \\mathcal{I}_B\\left(\\rho_{A B}\\right) \\geq 0\\) for all \\(\\rho_{A B} \\geq 0\\).</p> <p>To know that an superoperator is valid we somehow need to understand the overall global system.</p>"},{"location":"qip1/ch6.html#65-the-stinespring-dilation-theorem-purification-of-superoperators","title":"6.5. The Stinespring dilation theorem: Purification of superoperators:","text":"<p>For any completely positive trace preserving(cptp) map there exists a hilber space \\(\\mathcal{H}_B\\) and a pure state \\(\\left|\\phi_N\\right&gt; \\in \\mathcal{H}_B\\) together with a unitary \\(\\mathcal{U}_{AB}\\) s.t. </p> \\[ \\mathcal{E}\\left(\\rho^A\\right) = \\text{tr}_B\\left(\\mathcal{U}_{AB}\\left(\\rho^A \\otimes \\left|\\phi\\right&gt;\\left&lt;\\phi\\right|\\right)\\mathcal{U}_{AB}^{\\dagger}\\right) \\] <p>for all \\(\\rho^A \\in \\mathcal{S}\\left(\\mathcal{H}^A\\right)\\).</p>"},{"location":"qip1/ch6.html#66-operator-sum-representation","title":"6.6. Operator-sum representation:","text":"\\[ \\mathcal{E}\\left(\\rho^A\\right) = \\text{tr}_B\\left(\\mathcal{U}_{AB}\\left(\\rho^A \\otimes \\left|\\phi\\right&gt;\\left&lt;\\phi\\right|\\right)\\mathcal{U}_{AB}^{\\dagger}\\right) \\] <p>Then if we consider orthonormal basis of \\(\\mathcal{H}_B\\) to be \\(\\{ \\left|\\phi_i\\right&gt;\\}_i^{dim \\mathcal{H}_B}\\) and we rotate the basis in a way that the purification is \\(\\left|\\phi\\right&gt; = \\left|\\phi_1\\right&gt;\\) we get:</p> \\[ \\mathcal{E}\\left(\\rho^A\\right) = \\sum_i \\mathbb{I}_A \\otimes \\left&lt;\\phi_i\\right|_B \\left(\\mathcal{U}_{AB}\\left(\\rho^A \\otimes \\left|\\phi_1\\right&gt;\\left&lt;\\phi_1\\right|\\right)\\mathcal{U}_{AB}^{\\dagger}\\right) \\mathbb{I}_A \\otimes \\left|\\phi_i\\right&gt;_B = \\sum_i \\left( \\left&lt;\\phi_i\\right|\\mathcal{U}_{AB} \\left|\\phi_1\\right&gt; \\right)\\rho^A \\left(\\left&lt;\\phi_1\\right|\\mathcal{U}_{AB}^{\\dagger}\\left|\\phi_i\\right&gt;\\right) \\] <p>Defining Krauss Operator: \\(E_k = \\left&lt;\\phi_k\\right|\\mathcal{U}_{AB} \\left|\\phi_1\\right&gt;\\) we can write any quantum operation as</p> \\[ \\mathcal{E}\\left(\\rho^A\\right) = \\sum_k E_k \\rho^A E_k^{\\dagger} \\] <p>Notice that \\(\\sum_k E_k^{\\dagger} E_k = \\mathbb{I}\\).</p>"},{"location":"qip1/organisation.html","title":"Organisation","text":""},{"location":"qip1/organisation.html#group-chat","title":"Group Chat:","text":""},{"location":"random_walk/classical_optics/aberations/aberations_propagator.html","title":"Aberations as a function of Amplitude and Phase Mask:","text":""},{"location":"random_walk/classical_optics/aberations/aberations_propagator.html#0-introduction","title":"0. Introduction","text":"<ul> <li>In optical systems, aberrations are deviations from the ideal behavior of light propagation through lenses or other optical elements. These aberrations depend on various factors, including the position and angle at which a beam enters an optical component.</li> <li>Traditionally, we consider how the position and angle of incidence affect aberrations in a single lens, however in the context of holography it is insightfull to rephrase the problem in terms of phase and amplitude field just before the lens and ask how those affect the abberation map. </li> </ul>"},{"location":"random_walk/classical_optics/aberations/aberations_propagator.html#1-single-surface-lens","title":"1. Single Surface Lens:","text":"<p>To gain intuition about aberrations, lets follow the analysis from the Physics III notes by Jonathan Home @ ETH Zurich. Consider a collimated beam hitting a single-surface lens perpendicularly to the lens normal.</p> <p> </p> <p>The total optical path taken for the ray starting at hieght h is:</p> \\[ n_1 g(h)+n_2\\left(h^2+(f-g(h))^2\\right)^{1 / 2} \\] <p>To ensure constructive interference for all rays (regardless of h), we need to find the stationary points of the optical path length with repsect to h. </p> \\[ n_1 g^{\\prime}(h)+\\frac{n_2\\left(2 h-2(f-g(h)) g^{\\prime}(h)\\right)}{2\\left(h^2+(f-g(h))^2\\right)^{1 / 2}}=0 \\] <p>Solutions to this equations are not simple, and as a result it is very tricky to manufacture perfect shape. Therefore, we often use spherical lenses, which are easier to produce but introduce imperfections.</p> <p>For a spherical lens, the surface profile is:</p> \\[ g(h)=R-\\sqrt{\\left(R^2-h^2\\right)} \\approx \\frac{h^2}{2 R}+O\\left[h^4\\right] \\] <p>The focal length \\(f\\) for this lens is:</p> \\[ f=\\frac{R}{\\left(1-\\frac{n_1}{n_2}\\right)} \\] <p>However, spherical lenses introduce spherical aberration because the optical path difference is not perfectly corrected. The extra phase acquired by a beam entering at height \\(h\\) is approximately:</p> \\[ \\frac{n_2+\\frac{2 n_2^2}{n_1-n_2}+\\frac{\\left(n_1-n_2\\right)\\left(n_2-n_1\\right)^3}{n_2^2}}{8} \\frac{h^3}{f^3} h \\] <p>This analysis assumes a plane wave entering with a flat phase front. To understand the imperfections introduced when the phase front isn't flat, we would need to perform a similar analysis for each possible phase mask \u2014 a complex and challenging problem.</p>"},{"location":"random_walk/classical_optics/aberations/aberations_propagator.html#2-the-wave-equation-and-concept-of-propagators","title":"2. The Wave Equation and concept of propagators:","text":"<p>Electromagnetic field can be modelled as a complex field \\(U(x, y, z)\\) that follows Helmholz equation \\(\\nabla^2 U(\\boldsymbol{r})=-\\frac{\\omega^2}{v^2} U(\\boldsymbol{r})\\).</p> <p>We can transform \\(U\\) into Fourier space:</p> \\[ \\begin{aligned} \\tilde{U}\\left(k_x, k_y ; z\\right) &amp; =\\frac{1}{2 \\pi} \\int_{-\\infty}^{\\infty} \\int_{-\\infty}^{\\infty} U(x, y, z) \\exp \\left[-\\mathrm{i}\\left(k_x x+k_y y\\right)\\right] \\mathrm{d} x \\mathrm{~d} y  \\end{aligned} \\] <p>, where the Helmholz equation would takes form</p> \\[ \\frac{d^2 \\tilde{U}}{d z^2}+\\left(k^2-k_x^2-k_y^2\\right) \\tilde{U}\\left(k_x, k_y ; z\\right)=0 \\] <p>The solution is:</p> \\[ \\tilde{U}\\left(k_x, k_y ; z\\right)=\\tilde{U}\\left(k_x, k_y ; 0\\right) \\exp \\left(\\mathrm{i} \\sqrt{k^2-k_x^2-k_y^2} z\\right)=\\tilde{U}\\left(k_x, k_y ; 0\\right) \\mathcal{H}\\left(k_x, k_y, z\\right) \\] <p>, where \\(\\mathcal{H}\\left(k_x, k_y, z\\right)\\) is a Helmholz propagator.</p> <p>Propagators:</p> <p>Using Green's theorem and the Fresnel-Kirchhoff diffraction formula, we can relate the field at any plane \\(z=z_0\\) to a field at \\(z=0\\) thrugh a propagator \\(\\tau(x,y,z_0,x',y',0)\\). Then we can write that </p> \\[U(x, y, z_0) = \\int\\int dx' dy' \\left(\\tau(x,y,z_0,x',y',0) U(x, y, 0) \\right) \\] <p>In free space, it's advantageous to work in Fourier space due to the linearity of the equations, which reduces computational complexity.</p> <p>When introducing a phase mask, multiplication in real space corresponds to convolution in Fourier space. This means the operation is linear in real space but becomes more intricate in Fourier space.</p> <p>In general, the transformation can be expressed using the propagator \\(\\tau(x,y,z,x',y',z')\\). </p>"},{"location":"random_walk/classical_optics/aberations/aberations_propagator.html#3-representing-field-as-a-matrix","title":"3. Representing field as a matrix:","text":"<p>To facilitate numerical computations, we can discretize the field and represent it as a matrix. The field becomes a rank-2 tensor \\(U_{nm}\\), and the propagator becomes a rank-4 tensor \\(\\tau_{klnm}\\). The relationship between the fields at different planes is:</p> \\[ U_{kl} = \\tau_{klnm} U_{nm} \\] <p>We can define aberrations \\(\\tau^{\\Delta}_{klnm}\\), as a difference in the actual propagator, \\(\\tau_{klnm}\\), and the ideal (aberation-free) propagator, \\(\\tau^0_{klnm}\\).</p> \\[ \\tau^{\\Delta}_{klnm} = \\tau_{klnm} - \\tau^0_{klnm} \\]"},{"location":"random_walk/classical_optics/aberations/aberations_propagator.html#4-can-we-do-not-wavefront-calibration-but-rather-propagator-calibration","title":"4. Can we do not wavefront calibration, but rather propagator calibration?","text":"<p>Why was I thinking about this in the first place is my interest in the paper 'Rapid stochastic spatial light modulator calibration and pixel crosstalk optimisation'. I was wondering whether instead of learning the wavefront mask, we could learn the whole propagator. </p>"},{"location":"random_walk/classical_optics/aberations/aberations_propagator.html#reversible-neural-network","title":"Reversible Neural Network","text":""},{"location":"random_walk/quantum_optics/rabi_frequencies.html","title":"Light-Matter Interaction","text":""},{"location":"random_walk/quantum_optics/rabi_frequencies.html#rabi-frequencies","title":"Rabi Frequencies","text":"<p>Rabi Frequency is the fundamental quantity regarding interaction of an atom with light. It tells us about how much coupling do we get between two eigenstates of our atom in the presence of the oscilating electric field.</p> <p>Given the complexities and the confusion surrounding the derivations of dipole and quadrupole Rabi frequencies, a re-derivation is presented here. In this derivation we stay in a single gauge throughout. This derivation draws from Weissbluth book.</p>"},{"location":"random_walk/quantum_optics/rabi_frequencies.html#minimum-coupling-hamiltonian","title":"Minimum Coupling Hamiltonian","text":"<p>Consider an arbitrary electromagnetic vector field, \\(\\mathbf{A}(\\mathbf{r},t)\\), within the Coulomb gauge (\\(\\nabla \\cdot \\mathbf{A}(\\mathbf{r}) = 0\\)) in vacuum (\\(\\phi(\\mathbf{r}, t)=0\\)). Throughout the derivation we will assume that the field is small enough so that we can treat it as a perturbation.</p> <p>The minimum-coupling Hamiltonian in Coulomb's gauge is expressed as:</p> \\[  H=\\sum_\\alpha\\left(\\frac{\\left[\\mathbf{p}^{(\\alpha)}-q^{(\\alpha)} \\mathbf{A}\\left(\\mathbf{x}^{(\\alpha)}, t\\right)\\right]^2}{2 m^{(\\alpha)}}\\right)+H_F+V_{\\text{Coul}}  +\\frac{e \\hbar}{2 m c} \\boldsymbol{\\sigma} \\cdot \\boldsymbol{\\nabla} \\times \\mathbf{A} \\] <p>where \\(H_F\\) represents the free field energy (\\(H_F=\\frac{1}{2} \\int \\mathrm{d}^3 r\\left(\\epsilon_0 \\mathbf{E}^2(\\mathbf{r}, t)+\\frac{1}{\\mu_0} \\mathbf{B}^2(\\mathbf{r}, t)\\right)\\)) and \\(V_{\\text{Coul}}\\) contains terms defining the atomic state, including Coulomb interactions and spin-orbit coupling.</p> <p>Focusing on electron dynamics rather than absolute energy levels allows us to neglect constant energy terms \\(H_F\\) and \\(\\varepsilon_{\\text{Coul}}^\\alpha\\), keeping only the terms that depend on \\(\\mathbf{x}_\\alpha\\) or \\(\\mathbf{p}_\\alpha\\). Coulomb's Gauge \\(\\nabla \\cdot \\mathbf{A}(\\mathbf{r}) = 0\\) ensures that \\(\\mathbf{p}_\\alpha\\) and \\(\\mathbf{A}(\\mathbf{x}_\\alpha, t)\\) commute, so we can rewrite \\({H}\\) as:</p> \\[ \\begin{aligned} H &amp;=\\sum_\\alpha\\left(\\frac{\\left[\\mathbf{p}^{(\\alpha)}-q^{(\\alpha)} \\mathbf{A}\\left(\\mathbf{x}^{(\\alpha)}, t\\right)\\right]^2}{2 m^{(\\alpha)}}\\right)+V_{\\text {Coul }} + \\frac{e \\hbar}{2 m c} \\boldsymbol{\\sigma} \\cdot \\boldsymbol{\\nabla} \\times \\mathbf{A} \\\\&amp;=\\sum_\\alpha \\frac{\\mathbf{p^{(\\alpha)}}^2}{2 m^{(\\alpha)}}+V_{\\text {Coul }}+\\sum_\\alpha\\left(-\\frac{q^{(\\alpha)} \\mathbf{p}^{(\\alpha)} \\cdot \\mathbf{A}\\left(\\mathbf{x}^{(\\alpha)}, t\\right)}{m^{(\\alpha)}}+\\frac{{q^{(\\alpha)}}^2\\mathbf{A}\\left(\\mathbf{x}^{(\\alpha)}, t\\right)^2}{2 m^{(\\alpha)}}\\right) +  \\frac{e \\hbar}{2 m c} \\boldsymbol{\\sigma} \\cdot \\boldsymbol{\\nabla} \\times \\mathbf{A} \\end{aligned} \\] <p>Neglecting less dominant terms of the interaction Hamiltonian \\(\\frac{q_\\alpha^2\\mathbf{A}\\left(\\mathbf{x}_\\alpha, t\\right)^2}{2 m_\\alpha}\\) and \\(\\frac{e \\hbar}{2 m c} \\boldsymbol{\\sigma} \\cdot \\boldsymbol{\\nabla} \\times \\mathbf{A}\\), and grouping them together we get:</p> \\[  \\begin{aligned} &amp;H = H_0 + H_I \\\\ &amp;H_0 = \\sum_\\alpha \\frac{\\mathbf{p^{(\\alpha)}}^2}{2 m^{(\\alpha)}}+V_{\\text {Coul }} = \\sum_i \\mathcal{E}_i\\left|i\\right&gt;\\left&lt; i\\right| \\\\ &amp;H_I = \\sum_\\alpha-q^{(\\alpha)} \\mathbf{\\dot{x}}^{(\\alpha)} \\cdot \\mathbf{A}\\left(\\mathbf{x}^{(\\alpha)}, t\\right) \\end{aligned} \\] <p>\\(\\mathbf{x} = \\mathbf{R} + \\mathbf{r}\\), where \\(\\mathbf{R}\\) is a postion of the nucleus and \\(\\mathbf{r}\\) is position of an electron relative to the nucleus. Using Born-Oppenheimer approximation we can write \\(\\mathbf{\\dot{x}} = \\mathbf{\\dot{r}}\\) neglecting \\(\\mathbf{\\dot{R}}\\).</p> \\[ H_I = \\sum_\\alpha-q_\\alpha \\mathbf{\\dot{r}}_\\alpha \\cdot \\mathbf{A}\\left(\\mathbf{R}+\\mathbf{r}_\\alpha, t\\right) \\]"},{"location":"random_walk/quantum_optics/rabi_frequencies.html#multipole-expansion","title":"Multipole expansion","text":"<p>Taylor expanding \\(\\mathbf{A}(\\mathbf{R}+\\mathbf{r}_\\alpha, t)\\), we get:</p> \\[ H_I = \\sum_\\alpha-q_\\alpha \\dot{r}^{(\\alpha)}_{\\mu} \\left(A^\\mu\\left(\\mathbf{R}, t\\right) + \\partial^\\nu A^\\mu\\left(\\mathbf{R}, t\\right)r^{(\\alpha)}_{\\nu} \\right) \\] <p>From now on, Lets define \\(A^\\mu = A^\\mu(\\mathbf{R}, t)\\) </p> \\[ \\begin{aligned} H_I &amp;= \\sum_{\\alpha, i, j} |i\\rangle\\left\\langle i\\left|e \\dot{r}^{(\\alpha)}_{\\mu} \\left(A^\\mu + \\partial^\\nu A^\\mu r^{(\\alpha)}_{\\nu} + ...\\right) \\right| j\\right\\rangle\\langle j| \\\\ &amp;= \\sum_{\\alpha, i, j} \\left( |i\\rangle\\left\\langle i\\left|e \\dot{r}^{(\\alpha)}_{\\mu} A^\\mu\\right| j\\right\\rangle\\langle j| + |i\\rangle\\left\\langle i\\left|e \\dot{r}^{(\\alpha)}_{\\mu} \\partial^\\nu A^\\mu r^{(\\alpha)}_{\\nu} \\right| j\\right\\rangle\\langle j| + ... \\right) \\\\ &amp;= \\sum_{\\alpha, i, j} \\left( e A^\\mu|i\\rangle\\left\\langle i\\left| \\dot{r}^{(\\alpha)}_{\\mu} \\right| j\\right\\rangle\\langle j| + e\\partial^\\nu A^\\mu |i\\rangle\\left\\langle i\\left| \\dot{r}^{(\\alpha)}_{\\mu}  r^{(\\alpha)}_{\\nu} \\right| j\\right\\rangle\\langle j| + ... \\right) \\end{aligned} \\] <p>As in the end we would like to see how the light field interacts with consecutive terms of the multipole expansion formed by the atom, we need to get rid of \\(\\dot{r}_\\mu^{(\\alpha)}\\).</p> <p>As \\(\\left[ r_\\mu, p^2 \\right] = 2i \\hbar p_\\mu\\), then \\(i \\hbar \\dot{r}_\\mu=\\left[r_\\mu, H_0\\right]\\)</p> <p>Lets then solve consecutive terms of the Taylor expansion</p>"},{"location":"random_walk/quantum_optics/rabi_frequencies.html#0th-order-term","title":"0th Order term:","text":"\\[ \\begin{aligned} \\left\\langle i\\left| \\dot{r}^{(\\alpha)}_{\\mu} \\right| j\\right\\rangle &amp;= -\\frac{i}{\\hbar} \\left\\langle i\\left| [r^{(\\alpha)}_{\\mu}, H_0] \\right| j\\right\\rangle   \\\\&amp;= -\\frac{i}{\\hbar} \\left\\langle i\\left|r^{(\\alpha)}_{\\mu} H_0 - H_0 r^{(\\alpha)}_{\\mu} \\right| j\\right\\rangle  \\\\&amp;= -i \\left\\langle i\\left|r^{(\\alpha)}_{\\mu} \\omega_j - \\omega_i r^{(\\alpha)}_{\\mu} \\right| j\\right\\rangle  \\\\&amp;= i \\omega_{0} \\left\\langle i\\left| r^{(\\alpha)}_{\\mu} \\right| j\\right\\rangle \\end{aligned} \\] <p>, where \\(\\omega_{0} = \\omega_i-\\omega_j\\)</p>"},{"location":"random_walk/quantum_optics/rabi_frequencies.html#1st-order-term","title":"1st Order term:","text":"\\[ \\begin{aligned} \\left\\langle i\\left| \\dot{r}^{(\\alpha)}_{\\mu}  r^{(\\alpha)}_{\\nu} \\right| j\\right\\rangle  &amp;= -\\frac{i}{\\hbar}\\left\\langle i\\left| [r^{(\\alpha)}_{\\mu}, H_0]  r^{(\\alpha)}_{\\nu} \\right| j\\right\\rangle  \\\\&amp;=-\\frac{i}{\\hbar}\\left\\langle i\\left| r^{(\\alpha)}_{\\mu}H_0r_\\nu^{(\\alpha)} - H_0r^{(\\alpha)}_{\\mu}  r^{(\\alpha)}_{\\nu} \\right| j\\right\\rangle \\end{aligned} \\] <p>This is more tricky, because now we need to to commute \\(H_0\\) with \\(r_\\nu^{(\\alpha)}\\) which as a result would give us \\(\\dot{r}^{(\\alpha)}_{\\mu}\\) again. Instead what we can do we can split the problem into symmetric and anti-symmetric part hoping it will get easier. </p> \\[ \\left\\langle i\\left| \\dot{r}^{(\\alpha)}_{\\mu}  r^{(\\alpha)}_{\\nu} \\right| j\\right\\rangle = \\frac{1}{2}\\left\\langle i\\left| \\dot{r}^{(\\alpha)}_{\\mu}  r^{(\\alpha)}_{\\nu} +   r^{(\\alpha)}_{\\nu} \\dot{r}^{(\\alpha)}_{\\mu} \\right| j\\right\\rangle + \\frac{1}{2}\\left\\langle i\\left| \\dot{r}^{(\\alpha)}_{\\mu}  r^{(\\alpha)}_{\\nu} -   r^{(\\alpha)}_{\\nu} \\dot{r}^{(\\alpha)}_{\\mu} \\right| j\\right\\rangle \\] <p>Lets solve the symmetric and antisymmetric part separately:</p> <p>Symmetric part:</p> \\[ \\begin{aligned} \\frac{1}{2}\\left\\langle i\\left| \\dot{r}^{(\\alpha)}_{\\mu}  r^{(\\alpha)}_{\\nu} +   r^{(\\alpha)}_{\\nu} \\dot{r}^{(\\alpha)}_{\\mu} \\right| j\\right\\rangle &amp;=  \\frac{-i}{2\\hbar}\\left\\langle i\\left| [r^{(\\alpha)}_{\\mu}, H_0]  r^{(\\alpha)}_{\\nu} +   r^{(\\alpha)}_{\\nu} [r^{(\\alpha)}_{\\mu}, H_0] \\right| j\\right\\rangle \\\\&amp;=  \\frac{-i}{2\\hbar}\\left\\langle i\\left| -H_0r^{(\\alpha)}_{\\mu}  r^{(\\alpha)}_{\\nu} +   r^{(\\alpha)}_{\\nu} r^{(\\alpha)}_{\\mu}H_0 \\right| j\\right\\rangle \\\\&amp;=  \\frac{1}{2}i\\omega_{0}\\left\\langle i\\left| r^{(\\alpha)}_{\\mu}  r^{(\\alpha)}_{\\nu}  \\right| j\\right\\rangle \\end{aligned} \\] <p>Anti-symmetric part:</p> \\[ \\begin{aligned} \\frac{1}{2} \\partial^\\nu A^\\mu \\left\\langle i\\left| \\dot{r}^{(\\alpha)}_{\\mu}  r^{(\\alpha)}_{\\nu} -   r^{(\\alpha)}_{\\nu} \\dot{r}^{(\\alpha)}_{\\mu} \\right| j\\right\\rangle &amp;= \\frac{1}{2} \\varepsilon^{i \\mu \\nu}\\varepsilon_{i}^{j k} \\partial_j A_k \\left\\langle i\\left| \\dot{r}^{(\\alpha)}_{\\mu}  r^{(\\alpha)}_{\\nu} \\right| j\\right\\rangle \\\\&amp;=  \\frac{1}{2} \\varepsilon_{i}^{j k} \\partial_j A_k \\left\\langle i\\left| \\varepsilon^{i \\mu \\nu}\\dot{r}^{(\\alpha)}_{\\mu}  r^{(\\alpha)}_{\\nu} \\right| j\\right\\rangle \\\\&amp;=  \\frac{1}{2} \\hbar \\varepsilon_{i}^{j k} \\partial_j A_k \\left\\langle i\\left| L^i \\right| j\\right\\rangle \\end{aligned} \\] <p>Therefore one can re-write 1st Order term as:</p> \\[ \\begin{aligned} e \\partial^\\nu A^\\mu\\left\\langle i\\left| \\dot{r}^{(\\alpha)}_{\\mu}  r^{(\\alpha)}_{\\nu} \\right| j\\right\\rangle = \\frac{1}{2} ie\\omega_0 \\partial^\\nu A^\\mu \\left\\langle i\\left| r^{(\\alpha)}_{\\mu}  r^{(\\alpha)}_{\\nu}  \\right| j\\right\\rangle + \\frac{1}{2} \\hbar e \\varepsilon_{i}^{j k} \\partial_j A_k \\left\\langle i\\left| L^i \\right| j\\right\\rangle \\end{aligned} \\] <p>, where the first term corresponds to the electric quadrupole coupling and the second term corresponds to magnetic dipole coupling</p> <p>Collecting all the terms up to the 1st Order of Taylor expansion of \\(A_\\mu\\), we get:</p> \\[ H_I =  \\sum_{\\alpha, i, j} |i\\rangle\\left( \\underbrace{i e \\omega_{0} A^\\mu\\left\\langle i\\left| r^{(\\alpha)}_{\\mu} \\right| j\\right\\rangle }_\\text{Electric Dipole} +  \\underbrace{\\frac{1}{2} ie\\omega_0 \\partial^\\nu A^\\mu \\left\\langle i\\left| r^{(\\alpha)}_{\\mu}  r^{(\\alpha)}_{\\nu}  \\right| j\\right\\rangle}_\\text{Electric Quadrupole} + \\underbrace{\\frac{1}{2} \\hbar e \\varepsilon_{i}^{j k} \\partial_j A_k \\left\\langle i\\left| L^i \\right| j\\right\\rangle}_\\text{Magnetic Dipole} + ... \\right) \\langle j| \\]"},{"location":"random_walk/quantum_optics/rabi_frequencies.html#constraining-a-vector-field","title":"Constraining A-vector field:","text":"<p>Let's constrain our choice of \\(\\mathbf{A}\\) vector-field. In the end what we are interested in is an electric field \\(\\mathbf{E}\\) oscilating at single frequency \\(\\omega\\). As the electric field is an observable, it must be real, and so \\(\\tilde{E}(\\mathbf{x}, -\\omega)\\) =  \\(\\tilde{E}^\\dagger(\\mathbf{x}, \\omega)\\), and so it can be written as: \\(\\mathbf{E}=\\frac{1}{2}\\left(\\mathbf{E}(\\mathbf{x})e^{-i\\omega_lt}+\\mathbf{E}^{\\dagger}(\\mathbf{x})e^{i\\omega_lt}\\right)\\). </p> <p>Working in vacuum in Coulombs gauge we can write \\(\\mathbf{E} = -\\frac{\\partial \\mathbf{A}}{\\partial t}\\), hence</p> \\[ \\mathbf{A} =\\frac{1}{2}\\left(\\left(\\frac{1}{i\\omega_l}\\mathbf{E}(\\mathbf{x})\\right)e^{-i\\omega_lt} + \\left(\\frac{1}{i\\omega_l}\\mathbf{E}(\\mathbf{x})\\right)^{\\dagger}e^{i\\omega_lt}\\right) = \\frac{1}{2}\\left(\\mathbf{A}(\\mathbf{x})e^{-i\\omega_lt} + \\mathbf{A}^{\\dagger}(\\mathbf{x})e^{i\\omega_lt}\\right) \\] <p>The interaction then can be written as:</p> \\[ \\begin{aligned} H_I &amp;= \\sum_{\\alpha, i, j} \\left|i\\right&gt; \\left&lt; i\\left|e \\mathbf{\\dot{r}}^{(\\alpha)} \\mathbf{A} \\right| j\\right&gt; \\left&lt; j\\right| \\\\ &amp;= \\sum_{\\alpha, i, j} \\left|i\\right&gt; \\frac{1}{2} \\left( \\left&lt; i\\left|e \\mathbf{\\dot{r}}^{(\\alpha)} \\mathbf{A}(\\mathbf{x}) \\right| j\\right&gt; e^{-i\\omega_lt} + \\left&lt; i\\left|e \\mathbf{\\dot{r}}^{(\\alpha)} \\mathbf{A}^{\\dagger}(\\mathbf{x}) \\right| j\\right&gt; e^{i\\omega_lt} \\right) \\left&lt; j \\right| \\\\ &amp;= \\sum_{\\alpha, i, j} \\left|i\\right&gt; \\frac{\\hbar}{2} \\left(\\Omega_{ij} e^{-i\\omega_lt} + \\Omega^\\dagger_{ij} e^{i\\omega_lt} \\right) \\left&lt; j\\right|  \\end{aligned} \\] <p>, where Rabi Frequency is defined as follows:</p> \\[ \\hbar\\Omega_{i j}= \\left&lt; i\\left|e \\mathbf{\\dot{r}}^{(\\alpha)} \\mathbf{A}(\\mathbf{x}) \\right| j\\right&gt; \\] <p>As we saw, we can decompose it through the Taylor expansion into the consecutive terms corresponding to different nature of the transition. Usually only one of the coupling types is dominant and the other can be neglected. The dominant type depends on the nature of the transition and the electric field structure.</p> <p>\\(\\Omega_{i j}= \\begin{cases} \\frac{e\\omega_{0}}{\\hbar\\omega_l}E^\\mu\\left\\langle i\\left| r^{(\\alpha)}_{\\mu} \\right| j\\right\\rangle &amp; (\\mathrm{E1}) \\\\  \\frac{e\\omega_0}{2\\hbar\\omega_l} \\partial^\\nu E^\\mu \\left\\langle i\\left| r^{(\\alpha)}_{\\mu}  r^{(\\alpha)}_{\\nu}  \\right| j\\right\\rangle &amp; (\\mathrm{E2})\\\\ \\frac{1}{2} e \\varepsilon_{\\theta}^{\\beta \\gamma} \\partial_\\beta A_\\gamma \\left\\langle i\\left| L^\\theta \\right| j\\right\\rangle &amp; (\\mathrm{M1})\\\\ \\end{cases}\\)</p>"},{"location":"random_walk/quantum_optics/rabi_frequencies.html#final-remarks","title":"Final Remarks:","text":"<p>This is the final expression of the Rabi-frequencies. As far as we are interested in only electric multipole expansion we took all required terms from the dirac equation. We worked in vacuum and in Coulomb gauge. Not switching the gauge allowed us to not to make any mistakes that arise from working in multiple gauges. </p> <p>Other common derivation is using PZW Gauge, which naturally has a form of multipole expansion. I, however, prefered not to work in it, as from what I have seen it wasn't a popular choice of understanding the problem. Coulomb's gauge was a preffered choice, however for many they missed a step to split the first Taylor expansion term into symmetric and antisymmetric part, which forced them to fudge a factor of 1/2. </p> <p>It is important to note that the above derivation is valid for the cases when the interaction is weak, and so the perturbation theory is applicable. This is because \\(i \\hbar \\dot{r}_\\mu=\\left[r_\\mu, H_0\\right]\\) uses this assumption. </p>"}]}